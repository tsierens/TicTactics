{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import connect_four_speedboost as cccc\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def board_to_cache(board):\n",
    "    #convert a tic tac toe board to a cache-able string\n",
    "    one_to_ex_d = {1:\"X\",0:\"_\",-1:\"O\"}\n",
    "    one_to_ex_f = lambda x: one_to_ex_d[x]\n",
    "    return ''.join(map(one_to_ex_f,list(board.astype(int).reshape(42))))\n",
    "\n",
    "def cache_to_board(s):\n",
    "    ex_to_one_d = {'X':1,'_':0,'O':-1}\n",
    "    ex_to_one_f = lambda x: ex_to_one_d[x]\n",
    "    return np.array(map(ex_to_one_f,list(s))).reshape((6,7))\n",
    "\n",
    "def board_to_paint(board):\n",
    "    plt.matshow(board)\n",
    "    plt.show\n",
    "    \n",
    "def board_to_plot(ax,board):\n",
    "    ax.matshow(board,vmin=-1,vmax=1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TREE_CACHE = {}\n",
    "initializations = 0\n",
    "class MCTS_node():\n",
    "    def __init__(self,agent,board,player,leaf_branch = 40,policy = \"uniform\",net = \"none\", cache = {}):\n",
    "#         global TREE_CACHE\n",
    "        global initializations\n",
    "        initializations +=1\n",
    "        self.cache = cache\n",
    "        self.game = agent(board,player)\n",
    "        self.board = board\n",
    "        self.player = player\n",
    "        cache[board_to_cache(board)] = self\n",
    "        self.children = {}\n",
    "        self.parents = {}\n",
    "        self.net=net\n",
    "        self.leaf_branch = leaf_branch\n",
    "        self.actions = self.game.legal_moves()\n",
    "        self.terminal = self.game.over\n",
    "        self.weakly_solved = (0.5,0)\n",
    "        self.strongly_solved = (0.5,0,0)\n",
    "        self.winner = self.game.winner\n",
    "        if net == 'none':\n",
    "            self.net_eval = 0\n",
    "        else:\n",
    "            if self.terminal:\n",
    "                self.net_eval = self.winner\n",
    "            else:\n",
    "                self.net_eval = self.player * net.predict(self.player * self.board.reshape((1,6,7)))[0,0]\n",
    "        if self.actions:\n",
    "            if policy == 'uniform':\n",
    "                #connect-four specific uniform policy\n",
    "                self.priors = softmax(np.ones(len(self.actions)))\n",
    "            else:\n",
    "                self.priors = policy(self.game)\n",
    "        #number and value of rollouts\n",
    "        self.N = {action : 0 for action in self.actions}\n",
    "        self.Vr = {action : 0 for action in self.actions}\n",
    "        self.Vn = {action : 0 for action in self.actions}\n",
    "        self.R = {action : (0.5,0) for action in self.actions}\n",
    "        \n",
    "        #check to see if any children are already expanded, and if so, add them to the children dictionary\n",
    "        xgame = agent(np.copy(board),player)\n",
    "        for action in self.actions:\n",
    "            xgame.update_move(action)\n",
    "            if board_to_cache(xgame.board) in cache:\n",
    "                child = cache[board_to_cache(xgame.board)]\n",
    "                self.children[action] = child\n",
    "                child.parents[action] = self\n",
    "                if child.weakly_solved[0] != 0.5:\n",
    "                    propagate_result(self,action,-child.weakly_solved[0],abs(child.weakly_solved[1])+1)\n",
    "                \n",
    "            xgame.erase_move(action)\n",
    "\n",
    "                    \n",
    "    def is_leaf(self):\n",
    "        return self.children == {}\n",
    "\n",
    "    \n",
    "    \n",
    "def tree_policy(node,game,agent,mode = \"puct\",policy = 'uniform',net='none',leaf_branch=40,mix = 0.5):\n",
    "    global EPSILON\n",
    "    #global TREE_CACHE\n",
    "    cache = node.cache\n",
    "    current_node = node\n",
    "    nodes_visited = [node]\n",
    "    log = []\n",
    "    simulation = agent(np.copy(game.board),game.player)\n",
    "    #tree policy\n",
    "    while(True):\n",
    "        #epsilon greedy\n",
    "        if mode == \"epsilon\":\n",
    "            if np.random.random() < EPSILON:\n",
    "                move = random.choice(simulation.legal_moves())\n",
    "            else:\n",
    "                move = max([(score , key) for key,score in node_score(current_node,mix).items()])[1]      \n",
    "        if mode == \"puct\":\n",
    "            if max(current_node.Vn.values()) == -np.inf:\n",
    "                log.append('weakly solved')\n",
    "                return simulation,nodes_visited,log\n",
    "            #untested\n",
    "            puct_constant = 3\n",
    "            if net == 'none':\n",
    "                q = np.array([node_score(current_node,mix)[move] for move in current_node.actions])*2\n",
    "            else:\n",
    "                q = np.array([node_score(current_node,mix)[move] for move in current_node.actions])\n",
    "            u = puct_constant * current_node.priors * np.sqrt(np.sum(current_node.N.values())+1) / (\n",
    "                        1 + np.array([current_node.N[move] for move in current_node.actions]))\n",
    "            move = current_node.actions[np.argmax(q+u)]\n",
    "            \n",
    "            \n",
    "#         print q+u,move\n",
    "#         sys.exit()\n",
    "        try:\n",
    "            simulation.update_move(move)\n",
    "        except:\n",
    "            sys.exit((simulation.board,current_node.board,current_node.actions))\n",
    "        log.append(move)\n",
    "        \n",
    "        if simulation.over:\n",
    "            if simulation.result != 0:\n",
    "                propagate_result(current_node,move,1,1)\n",
    "            if simulation.result == 0:\n",
    "                propagate_result(current_node,move,0,1)\n",
    "            \n",
    "        if move in current_node.children:\n",
    "            current_node = current_node.children[move]\n",
    "        #expansion\n",
    "        elif current_node.N[move] >= current_node.leaf_branch:\n",
    "            cache_b = board_to_cache(simulation.board)\n",
    "            if cache_b in cache:\n",
    "                current_node.children[move] = cache[cache_b]\n",
    "                cache[cache_b].parents[move] = current_node\n",
    "                if cache[cache_b].weakly_solved[0] != 0.5:\n",
    "                    propagate_result(current_node,move,-cache[cache_b].weakly_solved[0],abs(cache[cache_b].weakly_solved[1])+1)\n",
    "                current_node = cache[cache_b]\n",
    "            else:\n",
    "                new_node = MCTS_node(agent,np.copy(simulation.board),simulation.player,policy = policy,net=net,leaf_branch=leaf_branch,cache = cache)\n",
    "                cache[board_to_cache(simulation.board)] = new_node\n",
    "                current_node.children[move] = new_node\n",
    "                new_node.parents[move] = current_node\n",
    "                if new_node.weakly_solved[0]!=0.5:\n",
    "                    propagate_result(current_node,move,-new_node.weakly_solved[0],abs(new_node.weakly_solved[1])+1)\n",
    "                current_node = new_node\n",
    "        else:\n",
    "            return simulation, nodes_visited , log\n",
    "        if current_node.weakly_solved == (0.5,0):\n",
    "            nodes_visited.append(current_node)\n",
    "            continue\n",
    "        else:\n",
    "            log.append(\"solved\")\n",
    "            return simulation, nodes_visited , log\n",
    "\n",
    "def reverse_solved(result,depth):\n",
    "    if result == 1:\n",
    "        return -1,-depth + 1\n",
    "    if result == -1:\n",
    "        return 1 , -depth - 1\n",
    "    if result == 0:\n",
    "        return 0,0\n",
    "    if result == 0.5:\n",
    "        return result,depth\n",
    "\n",
    "def propagate_result(node,move,result,depth):\n",
    "#     degugging\n",
    "#     print node.R,result,-depth*result\n",
    "    node.R[move] = (result,-depth*result)\n",
    "    node.N[move] += 1\n",
    "    node.Vr[move] = -np.inf\n",
    "    node.Vn[move] = -np.inf\n",
    "    if max(node.R.values()) != node.weakly_solved:\n",
    "        node.weakly_solved = max(node.R.values())\n",
    "            \n",
    "        for last_move,parent in node.parents.items():\n",
    "            propagate_result(parent , last_move,-node.weakly_solved[0],abs(node.weakly_solved[1])+1)\n",
    "            \n",
    "\n",
    "\n",
    "def rollout(simulation,policy = 'uniform'):\n",
    "\n",
    "    while(not simulation.over):\n",
    "        if policy == 'uniform':\n",
    "            move = random.choice(simulation.legal_moves())\n",
    "        else:\n",
    "            #put policy rollout stuff here\n",
    "            move = policy_to_index(policy(simulation))\n",
    "        simulation.update_move(move)  \n",
    "\n",
    "    return simulation.result\n",
    "\n",
    "def backprop(nodes , log , result, net_eval):\n",
    "    for node,move in zip(nodes,log):\n",
    "        node.N[move] += 1\n",
    "        node.Vr[move] += result * node.player\n",
    "        node.Vn[move] += net_eval * node.player\n",
    "        \n",
    "def MCTS(node,game,agent, dur = 5,policy = \"uniform\",net=\"none\",rollout_policy = 'uniform',leaf_branch=40,mix = 0.5):\n",
    "    t0 = time.clock()\n",
    "    # debugging stuff\n",
    "    t00=0\n",
    "    global t1\n",
    "    global t2\n",
    "    global t3\n",
    "    if node.weakly_solved[0] != 0.5:\n",
    "        return node\n",
    "    while(time.clock()-t0 < dur):\n",
    "        #tree policy\n",
    "        t00 = time.clock()\n",
    "        if rollout == 'none':\n",
    "            mix = 0\n",
    "        simulation , nodes_visited , log = tree_policy(node,\n",
    "                                                       game,\n",
    "                                                       agent,\n",
    "                                                       mode = 'puct',\n",
    "                                                       policy = policy,\n",
    "                                                       net=net,\n",
    "                                                       leaf_branch=leaf_branch,\n",
    "                                                       mix = mix)\n",
    "        \n",
    "        if log[-1] == \"solved\":\n",
    "            continue\n",
    "        if log[-1] == \"weakly solved\":\n",
    "            #should try to find strong solution\n",
    "            break\n",
    "        else:\n",
    "            t1 += time.clock()-t00\n",
    "\n",
    "            leaf = nodes_visited[-1]\n",
    "\n",
    "            #need to query if terminal\n",
    "            net_eval = leaf.net_eval\n",
    "\n",
    "            #rollout\n",
    "            t00 = time.clock()\n",
    "            if rollout_policy == 'none':\n",
    "                result = 0\n",
    "            else:\n",
    "                result = rollout(simulation,rollout_policy)\n",
    "        t2 += time.clock()-t00\n",
    "        #backprop\n",
    "        t00=time.clock()\n",
    "        backprop(nodes_visited,log,result,net_eval)\n",
    "        t3 += time.clock()-t00\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "def robust_score(node):\n",
    "    action_values = []\n",
    "    for key in node.N.keys():\n",
    "        action_values.append((node.R[key][0],node.R[key][1],node.N[key],key))\n",
    "    robust_action = max(action_values)\n",
    "    if node.game.over:\n",
    "        return node.game.result\n",
    "    if robust_action[2]==0 and robust_action[0] == 0.5:\n",
    "        return 0\n",
    "    \n",
    "    if robust_action[0] == 0.5:\n",
    "        return float(node.Vr[robust_action[3]])/robust_action[2],float(node.Vn[robust_action[3]])/robust_action[2]\n",
    "    else:\n",
    "        if robust_action[0] == 1:\n",
    "            return \"win in {}\".format(-robust_action[1])\n",
    "        if robust_action[0] == 0:\n",
    "            return \"draw\"\n",
    "        if robust_action[0] == -1:\n",
    "            return \"lose in {}\".format(robust_action[1])\n",
    "        sys.exit('bad value somewhere')\n",
    "def node_score(node,mix = 0.5):\n",
    "\n",
    "    return {key : float(mix*node.Vr[key]+(1-mix)*node.Vn[key]) / float(node.N[key]) if node.N[key]>0 else 0 for key in node.actions}\n",
    "\n",
    "def principal(node,mix=0.5):\n",
    "    win_d = {1:'win',0:'tie',-1:'loss'}\n",
    "    action_values = []\n",
    "    for key in node.N.keys():\n",
    "        action_values.append((node.R[key][0]if node.R[key][0] != 0.5 else -node.R[key][0],node.R[key][1],node.N[key],key))\n",
    "    robust_action = max(action_values)\n",
    "    move = robust_action[3]\n",
    "    if move in node.children and not node.children[move].game.over:\n",
    "        if robust_action[0] == -0.5:\n",
    "            return [(move,node.Vr[move],node.N[move],node_score(node,mix)[move]*node.player)] + principal(node.children[move],mix)\n",
    "        else:\n",
    "            return [(move, '{} in {}'.format(win_d[robust_action[0]],(abs(robust_action[1])+1)/2),\n",
    "                     0,win_d[robust_action[0]])] + principal(node.children[move],mix)\n",
    "    else:\n",
    "        if robust_action[0] == -0.5:\n",
    "            return [(move,node.Vr[move],node.N[move],node_score(node,mix)[move]*node.player)]\n",
    "        else:\n",
    "            return [(move, '{} in {}'.format(win_d[robust_action[0]],(abs(robust_action[1])+1)/2),\n",
    "                     0,win_d[robust_action[0]])]\n",
    "    \n",
    "def softmax(ar,temp=1):\n",
    "    temp = float(temp)\n",
    "    ar = np.copy(ar)\n",
    "    if temp == 0:\n",
    "        argmax = np.argmax(ar)\n",
    "        cand = np.ones(ar.shape) * (ar == np.max(ar))\n",
    "        return cand / np.sum(cand)\n",
    "    ar = ar - np.max(ar)\n",
    "    return np.exp(ar / temp) / np.sum(np.exp(ar/temp))\n",
    "\n",
    "def get_principal(node):\n",
    "    if len(node.children)==0:\n",
    "        return ''\n",
    "    move = max(((node.R[key][0],node.R[key][1],node.N[key],key) for key in node.children.keys()))[3]\n",
    "    if move in node.children.keys():\n",
    "        return str(move) + get_principal(node.children[move])\n",
    "    else:\n",
    "        return str(move)\n",
    "    \n",
    "from colorama import Fore, Back, Style,init\n",
    "\n",
    "def alternate_red_blue(s,start):\n",
    "    colour_d = {1:Fore.RED,-1:Fore.BLUE}\n",
    "    new_s = colour_d[start]\n",
    "    start *= -1\n",
    "    for letter in s:\n",
    "        new_s += letter + colour_d[start]\n",
    "        start *= -1\n",
    "        \n",
    "    return new_s+Fore.BLACK\n",
    "        \n",
    "        \n",
    "    \n",
    "def print_eval(node):\n",
    "    win_d = {1:' win',0:' tie',-1:'loss'} \n",
    "    moves = node.actions    \n",
    "    evals = {move:'{:+1.7f}'.format(node_score(node,mix=1)[move]) if node.R[move][0]==0.5\n",
    "             else '{} in {:2d}'.format(win_d[node.R[move][0]], (abs(node.R[move][1])+1)/2) for move in moves}\n",
    "    runs = {move:'{:5d}'.format(node.N[move]) for move in node.N.keys()}\n",
    "    principals = {move:alternate_red_blue(str(move),node.player) if not move in node.children.keys() else alternate_red_blue(str(move)\n",
    "                                                + get_principal(node.children[move]),node.player) for move in moves}\n",
    "    _,_,_,order = zip(*sorted(((node.R[move][0],node.R[move][1],node.N[move],move) for move in moves),reverse=True))\n",
    "    strings = []\n",
    "    for move in order:\n",
    "        strings.append(\"move {}: eval: {} runs: {} principal branch: \".format(move,evals[move],runs[move]) + principals[move])\n",
    "    s = '\\r'\n",
    "    for phrase in strings:\n",
    "        s = s + phrase+'\\n'\n",
    "#     print \"moves\",moves\n",
    "#     print 'evals',evals\n",
    "#     print 'principal',principals\n",
    "#     print 'order',order\n",
    "    return s\n",
    "\n",
    "def reduce_effect_recursive(by = 0.5):\n",
    "    for node in TREE_CACHE.values():\n",
    "        for move in node.N:\n",
    "            node.N[move] *= by\n",
    "            node.V[move] *= by\n",
    "            \n",
    "def net_to_policy(net,game,temp = 1):\n",
    "    board = game.board * game.player\n",
    "    game = cccc.Board(np.copy(board),1)\n",
    "    actions = game.legal_moves()\n",
    "    #convnet\n",
    "    values = []\n",
    "    for move in actions:\n",
    "        game.update_move(move)\n",
    "        # first minus because it is the other player's point of view, second minus to get it to that point of view\n",
    "        if game.game_over():\n",
    "            values.append(game.winner())\n",
    "        else:\n",
    "            values.append(- net.predict( - game.board.reshape(1,6,7,1))[0,0])\n",
    "        game.erase_move(move)\n",
    "    values = np.array(values)\n",
    "    return softmax(values, temp)\n",
    "\n",
    "def policy_to_index(policy):\n",
    "    return np.random.choice(np.arange(policy.size),p=policy)\n",
    "\n",
    "\n",
    "def alpha_beta(game, depth=0, alpha=(-np.inf,0), beta=(np.inf,0), evaluation = 'none',cache = {},dur = np.inf):\n",
    "    if board_to_cache(game.board) in cache.keys():\n",
    "        return cache[board_to_cache(game.board)]\n",
    "    # this copies the game to not affect the main line. maybe this is slow\n",
    "#     print \"start\",depth,alpha,beta\n",
    "    if dur < 0:\n",
    "        return \"quit\"\n",
    "    t0 = time.clock()\n",
    "    if evaluation == 'none':\n",
    "        evaluation = lambda x: 0\n",
    "        \n",
    "    if depth == 0:        \n",
    "        return (random.choice(game.legal_moves()),(0,0))\n",
    "    player = game.player\n",
    "    moves = game.legal_moves()\n",
    "    random.shuffle(moves)\n",
    "    \n",
    "    move_score = (None,(-np.inf,0))\n",
    "    current = (None,(-np.inf,0))\n",
    "    for move in moves:\n",
    "        game.update_move(move)\n",
    "        if game.over:\n",
    "            current = (move,(game.result * player,-1))\n",
    "        else:\n",
    "            go_deeper = alpha_beta(game,depth = depth - 1, alpha = (-beta[0],-beta[1]),beta = (-alpha[0],-alpha[1]),\n",
    "                                   evaluation=evaluation,cache=cache,dur = dur - (time.clock()-t0))\n",
    "            if go_deeper == 'quit':\n",
    "                game.erase_move(move)\n",
    "                return 'quit'\n",
    "            if go_deeper[1] != (0,0):\n",
    "                cache[board_to_cache(game.board)] = go_deeper\n",
    "            prop = (-go_deeper[1][0],-np.sign(go_deeper[1][1])*(np.abs(go_deeper[1][1])+1))\n",
    "            current = (move,prop)\n",
    "        if current[1] > move_score[1]:\n",
    "            move_score = (move,current[1])\n",
    "        if move_score[1] > alpha:\n",
    "            alpha = move_score[1]\n",
    "        game.erase_move(move)\n",
    "        if alpha>=beta:\n",
    "#             print \"yay\"\n",
    "            break\n",
    "#     print \"end\",depth,alpha,beta\n",
    "    return move_score\n",
    "\n",
    "def alpha_beta_descend(game,max_depth=np.inf,evaluation = 'none',cache = {},dur = np.inf):\n",
    "    if board_to_cache(game.board) in cache.keys():\n",
    "        return cache[board_to_cache(game.board)],0\n",
    "    t0 = time.clock()\n",
    "    move_score = (None,-np.inf)\n",
    "    depth = 0\n",
    "    while True:\n",
    "        \n",
    "        if depth > max_depth:\n",
    "            break\n",
    "        move_score_cand = alpha_beta(game,depth,dur = dur - (time.clock() - t0),cache = cache)\n",
    "        if move_score_cand == 'quit':\n",
    "            break\n",
    "        move_score = move_score_cand\n",
    "        if move_score[1]!=(0,0):\n",
    "            break\n",
    "        depth +=1\n",
    "    return move_score,depth\n",
    "\n",
    "def alpha_beta_rollout(depth,cache):\n",
    "    def func(game):\n",
    "        move=alpha_beta(game,depth = depth,cache=cache)[0]\n",
    "#         print move\n",
    "#         print game.legal_moves()\n",
    "#         print np.array([i==move for i in range(7)]).astype(int)\n",
    "        return np.array([i==move for i in range(7)]).astype(int)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connect_four_speedboost.py:9: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if board == None:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-58236b9b5339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mTREE_CACHE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'error'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMCTS_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoard\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mEPSILON\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpass_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnet_to_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-6424da07a9ef>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, agent, board, player, leaf_branch, policy, net, cache)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;31m#number and value of rollouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "game = cccc.Board()\n",
    "TREE_CACHE = {}\n",
    "t0 = 'error'\n",
    "tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,40,{})\n",
    "EPSILON = 0.1\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "for _ in range(60):\n",
    "    print _ , max(node_score(tree).values())\n",
    "    MCTS(tree,game,cccc.Board,dur = 60,policy = pass_policy)\n",
    "\n",
    "\n",
    "scores = node_score(tree)\n",
    "print 'current move\\n'\n",
    "for move in tree.actions:\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(move,tree.Vr[move],tree.N[move],scores[move])\n",
    "\n",
    "print '\\nprincipal variation\\n'\n",
    "for move in principal(tree):\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(*move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "game = cccc.Board()\n",
    "TREE_CACHE = {}\n",
    "t0 = 'error'\n",
    "tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,40,{})\n",
    "EPSILON = 0.1\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 1)\n",
    "for _ in range(20):\n",
    "    print _ , max(node_score(tree).values())\n",
    "    MCTS(tree,game,cccc.Board,dur = 5,policy = 'uniform')\n",
    "\n",
    "\n",
    "scores = node_score(tree)\n",
    "print 'current move\\n'\n",
    "for move in tree.actions:\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(move,tree.Vr[move],tree.N[move],scores[move])\n",
    "\n",
    "print '\\nprincipal variation\\n'\n",
    "for move in principal(tree):\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(*move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make initial training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " games played: 1000, positions grabbed: 778\r",
      " games played: 2000, positions grabbed: 1505"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-267e5b926b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Neural Network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mmove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0msimulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-267e5b926b1c>\u001b[0m in \u001b[0;36mpolicy1\u001b[1;34m(game, net)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpolicy_to_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_to_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpass_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnet_to_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3c989fa33ff3>\u001b[0m in \u001b[0;36mnet_to_policy\u001b[1;34m(net, board, temp)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merase_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-fe3addbc593a>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# Os\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# blanks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Z_cache = []\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "#unique\n",
    "#Z_cache=set()\n",
    "TREE_CACHE = {}\n",
    "games_played = 0\n",
    "\n",
    "\n",
    "def policy1(game,net):\n",
    "    board = game.board * game.player\n",
    "    actions = game.legal_moves()\n",
    "    return actions[policy_to_index(net_to_policy(net,board,0.25))]\n",
    "\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "\n",
    "while len(Z_cache) < 30000:\n",
    "    games_played +=1\n",
    "    boards = []\n",
    "    simulation = cccc.Board()\n",
    "    tree = MCTS_node(cccc.Board,simulation.board,simulation.player,net=net, policy = pass_policy,leaf_branch = 5,cache = TREE_CACHE)\n",
    "    while not simulation.game_over():\n",
    "        boards.append(np.copy(simulation.board))\n",
    "        # random\n",
    "        #move = random.choice(simulation.legal_moves())\n",
    "        \n",
    "        # Neural Network\n",
    "        move = policy1(simulation,net)\n",
    "        \n",
    "        simulation.update_move(move)        \n",
    "    #unique\n",
    "    board = random.choice(boards)\n",
    "    cache = board_to_cache(board)\n",
    "    if not cache in Z_cache:\n",
    "        Z_cache.append(board_to_cache(random.choice(boards)))\n",
    "        \n",
    "    if games_played%1==0:\n",
    "        sys.stdout.write('\\r games played: {}, positions grabbed: {}'.format(games_played,len(Z_cache)))\n",
    "Z = map(cache_to_board,Z_cache)\n",
    "sys.stdout.write('\\r games played: {}, positions grabbed: {}'.format(games_played,len(Z_cache)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MCTS rollout scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE_CACHE = {}\n",
    "import time\n",
    "\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "\n",
    "for i,board in enumerate(Z):\n",
    "    player = 1 if np.sum(board) == 0 else -1\n",
    "    game = cccc.Board(np.copy(board) , player)\n",
    "    tree = MCTS_node(cccc.Board,game.board,game.player,net=net, policy = pass_policy,leaf_branch = 5,cache = TREE_CACHE)\n",
    "    MCTS(tree,game,cccc.Board,dur = 2.5,policy = pass_policy,leaf_branch=5,net=net)\n",
    "    sys.stdout.write('\\r'+str(i)+' '+str(sum(tree.N.values())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "for board in Z:\n",
    "    cache = board_to_cache(board)\n",
    "    node = TREE_CACHE[cache]\n",
    "    # if it is player two, then the board AND the result need to be reversed\n",
    "    if node.player == 1:\n",
    "        y.append(sum(robust_score(node))*0.5)\n",
    "        X.append(board)\n",
    "    else:\n",
    "        y.append(sum(robust_score(node))*0.5)\n",
    "        X.append(-1 * board)\n",
    "#     if y[-1]==0.5:#some bugfixing \n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE_CACHE = {}\n",
    "import time\n",
    "\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.5)\n",
    "def roll_policy(board):\n",
    "    player = 1 if np.sum(board)==0 else -1\n",
    "    board = board*player\n",
    "    game = cccc.Board(board,1)\n",
    "    actions = game.legal_moves()\n",
    "    net_eval = pol_net.predict(board.reshape(1,6,7,1)).reshape(7)\n",
    "    net_eval = [net_eval[i] if i in actions else -np.inf for i in range(7)]\n",
    "    return softmax(net_eval,0.2)  \n",
    "y = []\n",
    "y_pol = []\n",
    "X = []\n",
    "for i,board in enumerate(Z):\n",
    "    player = 1 if np.sum(board) == 0 else -1\n",
    "    game = cccc.Board(np.copy(board) , player)\n",
    "    tree = MCTS_node(cccc.Board,game.board,game.player,net=net, policy = pass_policy,leaf_branch = 5)\n",
    "    MCTS(tree,game,cccc.Board,dur = 1,policy = pass_policy,leaf_branch=5,net=net)\n",
    "    sys.stdout.write('\\r'+str(i)+' '+str(sum(tree.N.values())))\n",
    "\n",
    "    cache = board_to_cache(board)\n",
    "    # if it is player two, then the board AND the result need to be reversed\n",
    "    if tree.player == 1:\n",
    "        y_pol.append(node_score(tree))\n",
    "        y.append(sum(robust_score(tree))*0.5)\n",
    "        X.append(board)\n",
    "    else:\n",
    "        y_pol.append(node_score(tree))\n",
    "        y.append(sum(robust_score(tree))*0.5)\n",
    "        X.append(-1 * board)\n",
    "#     if y[-1]==0.5:#some bugfixing \n",
    "#         break\n",
    "z = []\n",
    "for d in y_pol:\n",
    "    a = -np.ones(7)\n",
    "    for i in range(7):\n",
    "        if i in d.keys():\n",
    "            a[i]=d[i]\n",
    "    z.append(a)\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " games played: 2817601, positions grabbed: 1000000\n",
      "127881.013158\n"
     ]
    }
   ],
   "source": [
    "Z_cache = set()\n",
    "X=[]\n",
    "y=[]\n",
    "pol_y=[]\n",
    "#unique\n",
    "Z_cache=set()\n",
    "games_played = 0\n",
    "\n",
    "\n",
    "def policy1(game,net):\n",
    "    board = game.board * game.player\n",
    "    actions = game.legal_moves()\n",
    "    return actions[policy_to_index(net_to_policy(net,board,0.25))]\n",
    "t0 = time.clock()\n",
    "while len(Z_cache) < 1000000:\n",
    "    games_played +=1\n",
    "    boards = []\n",
    "    simulation = cccc.Board()\n",
    "    while not simulation.game_over():\n",
    "        boards.append(np.copy(simulation.board))\n",
    "        move = policy1(simulation,net)\n",
    "        simulation.update_move(move)       \n",
    "        \n",
    "    board = random.choice(boards)\n",
    "    player = 1 if np.sum(board) == 0 else -1\n",
    "    cache = board_to_cache(board)\n",
    "    if not cache in Z_cache:\n",
    "        Z_cache.add(board_to_cache(random.choice(boards)))\n",
    "        X.append(board*player)\n",
    "        y.append(simulation.winner()*player)\n",
    "    if games_played%1000==0:\n",
    "        sys.stdout.write('\\r games played: {}, positions grabbed: {}'.format(games_played,len(Z_cache)))\n",
    "Z = map(cache_to_board,Z_cache)\n",
    "sys.stdout.write('\\r games played: {}, positions grabbed: {}'.format(games_played,len(Z_cache)))\n",
    "print ''\n",
    "print time.clock()-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#million\n",
    "with open('training_set_mill2.pkl','wb') as file_:\n",
    "    pickle.dump((X,y),file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'training_set_mill2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-14c8663f3420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_set_mill2.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'training_set_mill2.pkl'"
     ]
    }
   ],
   "source": [
    "with open('training_set_mill.pkl','rb') as file_:\n",
    "    X,y = pickle.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = []\n",
    "for d in y_pol:\n",
    "    a = -np.ones(7)\n",
    "    for i in range(7):\n",
    "        if i in d.keys():\n",
    "            a[i]=d[i]\n",
    "    z.append(a)\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tree.N\n",
    "print tree.Vn\n",
    "print tree.Vr\n",
    "print node_score(tree)\n",
    "print robust_score(tree)\n",
    "print tree.priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print TREE_CACHE[board_to_cache(-X[3758])].N\n",
    "print TREE_CACHE[board_to_cache(-X[3758])].Vr\n",
    "print TREE_CACHE[board_to_cache(-X[3758])].Vn\n",
    "print TREE_CACHE[board_to_cache(-X[3758])].net_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('cache.pkl','wb') as file_:\n",
    "#     pickle.dump(TREE_CACHE,file_)\n",
    "    \n",
    "with open('training_set_gen7.pkl','wb') as file_:\n",
    "    pickle.dump((X,y,z),file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('cache.pkl','rb') as file_:\n",
    "#     TREE_CACHE = pickle.load(file_)\n",
    "with open('training_set_gen7.pkl','rb') as file_:\n",
    "    X,y,z = pickle.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle\n",
    "cut = 25000\n",
    "zipped = zip(X,y,z)\n",
    "random.shuffle(zipped)\n",
    "X,y,x = zip(*zipped)\n",
    "\n",
    "#split\n",
    "X_train,X_val = np.array(X[:cut]).reshape(-1,42),np.array(X[cut:]).reshape(-1,42)\n",
    "y_train,y_val = np.array(y[:cut]).reshape(-1),np.array(y[cut:]).reshape(-1)\n",
    "z_train,z_val = np.array(z[:cut]).reshape(-1,7),np.array(z[cut:]).reshape(-1,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Regressor, Convolution,Layer\n",
    "net = Regressor( layers = [Convolution(\"Rectifier\", channels = 36 , kernel_shape = (4,4)),\n",
    "                           #Convolution(\"Rectifier\", channels = 4 , kernel_shape = (3,3)),\n",
    "                           Layer(\"Rectifier\", units = 256,dropout=0.2),\n",
    "                           Layer(\"Rectifier\", units = 256,dropout=0.2),\n",
    "                           Layer(\"Rectifier\", units = 64,dropout=0.2),\n",
    "                           Layer(\"Rectifier\", units = 64,dropout=0.2),\n",
    "                           Layer(\"Rectifier\", units = 64,dropout=0.2),\n",
    "                           #Layer(\"Rectifier\", units = 21,dropout=0.2),\n",
    "                           Layer(\"Tanh\", units = 1)],\n",
    "                batch_size = 32,\n",
    "                learning_rate = 0.00001,\n",
    "                learning_rule = 'nesterov',\n",
    "                #weight_decay=0.000001,           \n",
    "                n_iter = 1)\n",
    "\n",
    "\n",
    "# def net_policy(board):\n",
    "    \n",
    "#     game = cccc.Board(np.copy(board),1)\n",
    "#     actions = game.legal_moves()\n",
    "#     values = np.zeros(len(actions))\n",
    "#     for i,move in enumerate(actions):\n",
    "#         game.update_move(move)\n",
    "#         values[i] = net.predict(game.board.reshape(-1,42))[0,0]\n",
    "#         game.erase_move(move)\n",
    "#     return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Regressor, Convolution,Layer\n",
    "pol_net = Regressor( layers = [Convolution(\"Rectifier\", channels = 8 , kernel_shape = (4,4)),\n",
    "                           #Convolution(\"Rectifier\", channels = 4 , kernel_shape = (3,3)),\n",
    "                            \n",
    "                           Layer(\"Rectifier\", units = 50,dropout=0.2),\n",
    "#                            Layer(\"Rectifier\", units = 50,dropout=0.2),\n",
    "#                            Layer(\"Rectifier\", units = 25,dropout=0.2),\n",
    "#                            Layer(\"Rectifier\", units = 128,dropout=0.2),\n",
    "#                            Layer(\"Rectifier\", units = 64,dropout=0.2),\n",
    "#                            Layer(\"Rectifier\", units = 21,dropout=0.2),\n",
    "                           #Layer(\"Rectifier\", units = 25,dropout=0.1),\n",
    "                           Layer(\"Tanh\", units = 7)],\n",
    "                batch_size = 32,\n",
    "                learning_rate = 0.0001,\n",
    "                learning_rule = 'nesterov',\n",
    "                #weight_decay=0.000001,           \n",
    "                n_iter = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Regressor( layers = [#Convolution(\"Rectifier\", channels = 12 , kernel_shape = (4,4)),\n",
    "                           #Convolution(\"Rectifier\", channels = 4 , kernel_shape = (3,3)),\n",
    "                           Layer(\"Rectifier\", units = ),\n",
    "                           #Layer(\"Rectifier\", units = 20),\n",
    "                           #Layer(\"Rectifier\", units = 50),\n",
    "                           Layer(\"Tanh\", units = 1)],\n",
    "                batch_size = 16,\n",
    "                learning_rate = 0.0001,\n",
    "                learning_rule = 'nesterov',\n",
    "                weight_decay=0.0001, \n",
    "                n_iter = 1)\n",
    "\n",
    "with open('c4_shallow_net.pkl','rb') as file_:\n",
    "    net2_params = pickle.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.set_parameters(net2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.fit(np.zeros((8,42)),np.zeros((8,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000L, 1L, 6L, 7L)\n",
      "(5000L, 1L, 6L, 7L)\n",
      "(25000L,)\n",
      "(5000L,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1,1,6,7))\n",
    "X_val = X_val.reshape((-1,1,6,7))\n",
    "\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print y_train.shape\n",
    "print y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1,42))\n",
    "X_val = X_val.reshape((-1,42))\n",
    "\n",
    "print X_train.shape\n",
    "print X_val.shape\n",
    "print y_train.shape\n",
    "print y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1290080b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74589340988998643, 0.74868364060142678)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-24525a125043>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             log.error(\"\\n{}{}{}\\n\\n{}\\n\".format(\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.pyc\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mis_best_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m             \u001b[0mavg_train_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mavg_train_error\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_train_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\backend\\lasagne\\mlp.pyc\u001b[0m in \u001b[0;36m_train_impl\u001b[1;34m(self, X, y, w)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_valid_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\backend\\lasagne\\mlp.pyc\u001b[0m in \u001b[0;36m_batch_impl\u001b[1;34m(self, X, y, w, processor, mode, output, shuffle)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\tensor\\blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   1821\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m             \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m             \u001b[1;31m# The error raised by numpy has no shape information, we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1290080b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newgraph = True\n",
    "if newgraph:\n",
    "    mse = []\n",
    "if not 'mse' in globals():\n",
    "    mse = []\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "for epoch in range(2000):\n",
    "    net.fit(X_train,y_train)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        mse.append((np.mean(np.abs(net.predict(X_train.reshape((-1,6,7,1))).reshape(-1) - y_train)**2),np.mean(\n",
    "            np.abs(net.predict(X_val.reshape((-1,6,7,1))).reshape(-1) - y_val)**2)))\n",
    "        display.clear_output(wait=True)\n",
    "        plt.clf()\n",
    "        plt.plot(mse)\n",
    "        ax = plt.gca()\n",
    "        ax.set_color_cycle(['blue','red'])\n",
    "        display.display(plt.gcf())\n",
    "        print mse[-1]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-d23b37d8a82e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mmsep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\display.pyc\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(*objs, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_get_formatter_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2178\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2180\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2181\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\backends\\backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\backends\\backend_agg.pyc\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0mRendererAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\figure.pyc\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[0mdsu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2323\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzorder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdsu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2324\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2326\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbefore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mafter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axis.pyc\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m   1108\u001b[0m                                                                 renderer)\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axis.pyc\u001b[0m in \u001b[0;36m_update_ticks\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[0minterval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         \u001b[0mtick_tups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_smart_bounds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[1;31m# handle inverted limits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axis.pyc\u001b[0m in \u001b[0;36miter_ticks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m    892\u001b[0m         \u001b[0mmajorLocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m         \u001b[0mmajorTicks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajorLocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m         majorLabels = [self.major.formatter(val, i)\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axis.pyc\u001b[0m in \u001b[0;36mget_major_ticks\u001b[1;34m(self, numticks)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gridOnMajor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m                     \u001b[0mtick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridOn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copy_tick_props\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotoTick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lastNumMajorTicks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\axis.pyc\u001b[0m in \u001b[0;36m_copy_tick_props\u001b[1;34m(self, src, dest)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[0mdest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick1line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick1line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m         \u001b[0mdest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick2line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick2line\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m         \u001b[0mdest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\lines.pyc\u001b[0m in \u001b[0;36mupdate_from\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linestyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linestyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m         self._marker = MarkerStyle(other._marker.get_marker(),\n\u001b[1;32m-> 1231\u001b[1;33m                                    other._marker.get_fillstyle())\n\u001b[0m\u001b[0;32m   1232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drawstyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drawstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\markers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, marker, fillstyle)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fillstyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfillstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_marker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_fillstyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfillstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\markers.pyc\u001b[0m in \u001b[0;36mset_fillstyle\u001b[1;34m(self, fillstyle)\u001b[0m\n\u001b[0;32m    220\u001b[0m                              % ' '.join(self.fillstyles))\n\u001b[0;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fillstyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfillstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_joinstyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\markers.pyc\u001b[0m in \u001b[0;36m_recache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIdentityTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alt_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\path.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vertices, codes, _interpolation_steps, closed, readonly)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpolation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_interpolation_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\matplotlib\\path.pyc\u001b[0m in \u001b[0;36m_update_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m         self._should_simplify = (\n\u001b[0;32m    214\u001b[0m             \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path.simplify'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m             (len(self._vertices) >= 128 and\n\u001b[0m\u001b[0;32m    216\u001b[0m              (self._codes is None or np.all(self._codes <= Path.LINETO)))\n\u001b[0;32m    217\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDEGgP8HW+MOjygvpi8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d70780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newgraph = True\n",
    "if newgraph:\n",
    "    msep = []\n",
    "if not 'msep' in globals():\n",
    "    msep = []\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "for epoch in range(10000):\n",
    "    pol_net.fit(X_train,z_train)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        msep.append((np.mean(np.sum(np.abs(pol_net.predict(X_train.reshape((-1,6,7,1))).reshape(-1,7) - z_train)**2,axis=1)),np.mean(\n",
    "            np.sum(np.abs(pol_net.predict(X_val.reshape((-1,6,7,1))).reshape(-1,7) - z_val)**2,axis=1))))\n",
    "        display.clear_output(wait=True)\n",
    "        plt.clf()\n",
    "        plt.plot(msep)\n",
    "        ax = plt.gca()\n",
    "        ax.set_color_cycle(['blue','red'])\n",
    "        display.display(plt.gcf())\n",
    "        print msep[-1]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mill2_convdrop.pkl', 'wb') as file_:\n",
    "    pickle.dump(net,file_)\n",
    "with open('mill2_convdropstate.pkl','wb') as file_:\n",
    "    pickle.dump(net.__getstate__()['weights'],file_)\n",
    "# with open('gen5_policyconvdrop.pkl', 'wb') as file_:\n",
    "#     pickle.dump(pol_net,file_)\n",
    "# with open('gen5_policyconvdropstate.pkl','wb') as file_:\n",
    "#     pickle.dump(pol_net.__getstate__()['weights'],file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('gen5_convdrop.pkl', 'rb') as file_:\n",
    "    net = pickle.load(file_)\n",
    "with open('gen5_policyconvdrop.pkl','rb') as file_:\n",
    "    pol_net = pickle.load(file_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sknn\n",
    "with open('gen5_convdropstate.pkl','rb') as file_:\n",
    "    net_state = pickle.load(file_)\n",
    "net.fit(np.zeros((1,1,6,7)),np.zeros(1))\n",
    "net.set_parameters(net_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gen1_policyconvdropstate.pkl','rb') as file_:\n",
    "    pol_net_state = pickle.load(file_)\n",
    "pol_net.fit(np.zeros((1,1,6,7)),np.array([1,-1,0,1,0,-1,-1]).reshape(1,7))\n",
    "pol_net.set_parameters(pol_net_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "igen = iter(range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "i=next(igen)\n",
    "print i\n",
    "board_to_paint(X_val[i].reshape((6,7)))\n",
    "print 'target:', y_val[i]\n",
    "print 'prediction', net.predict(X_val[i])[0,0]\n",
    "print 'target policy: ',z_val[i]\n",
    "print 'predicted policy: ', pol_net.predict(X_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test\n",
    "np.sum(test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(net.predict(X_val.reshape((-1,6,7,1))).reshape(-1) - y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 4400\n",
    "board = X_val[index].reshape(6,7)\n",
    "board_to_paint(board)\n",
    "print y_val[index]\n",
    "print net.predict(board.reshape(1,6,7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE_CACHE[board_to_cache(X[58])].Vr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.__getstate__()['weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import pickle\n",
    "with open('gen1_100_tanh.pkl', 'wb') as file_:\n",
    "    pickle.dump(net,file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gen1_convdrop.pkl', 'wb') as file_:\n",
    "    pickle.dump(net,file_)\n",
    "with open('gen1_convdropstate.pkl','wb') as file_:\n",
    "    pickle.dump(net.__getstate__()['weights'],file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gen1_convdrop.pkl','rb') as file_:\n",
    "    net = pickle.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = node_score(tree)\n",
    "print 'current move\\n'\n",
    "for move in tree.actions:\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(move,tree.Vr[move],tree.N[move],scores[move])\n",
    "\n",
    "print '\\nprincipal variation\\n'\n",
    "for move in principal(tree):\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(*move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip(map(lambda x: x.reshape((6,7)),X_train),y_train)[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game = cccc.Board()\n",
    "tree = MCTS_node(cccc.Board,game.board,game.player)\n",
    "board = tree.children[3].board\n",
    "cache = board_to_cache(board)\n",
    "node = TREE_CACHE[cache]\n",
    "# if it is player two, then the board AND the result need to be reversed\n",
    "if node.player == 1:\n",
    "    print (max(node_score(node).values()))\n",
    "    print (board)\n",
    "else:\n",
    "    print(-min(node_score(node).values()))\n",
    "    print(-1 * board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_score(tree.children[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game = cccc.Board()\n",
    "def policy1(game,net):\n",
    "    board = game.board * game.player\n",
    "    actions = game.legal_moves()\n",
    "    return actions[policy_to_index(net_to_policy(net,board,0.2))]\n",
    "    \n",
    "\n",
    "def policy2(game):\n",
    "    actions = game.legal_moves()\n",
    "    return actions[policy_to_index(softmax(np.ones(len(game.legal_moves()))))]\n",
    "\n",
    "    \n",
    "score = 0\n",
    "games = 0\n",
    "longest = []\n",
    "for i in range(1000):\n",
    "    game = cccc.Board()\n",
    "    while not game.game_over():\n",
    "        if game.player == 1:\n",
    "            game.update_move(policy1(game,net))\n",
    "        else:\n",
    "            game.update_move(policy2(game))\n",
    "    score += game.winner()\n",
    "    games +=1\n",
    "    if len(game.log) > len(longest):\n",
    "        longest = game.log\n",
    "    if games%25==0:\n",
    "        sys.stdout.write('\\r{} , {}'.format(float(score)/games , games))\n",
    "    \n",
    "print \"\\n\",score,games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MTCS policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500-0-500, games played: 1000\n",
      "0 1000\n",
      "time: 87.435249894\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqbH/BTlbs8dE2Xm9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1365ba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "score = 0\n",
    "wins = 0\n",
    "ties = 0\n",
    "losses = 0\n",
    "games = 0\n",
    "logs = []\n",
    "longest = []\n",
    "game = cccc.Board()\n",
    "print_board = False\n",
    "\n",
    "import time\n",
    "\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "\n",
    "def roll_policy(board):\n",
    "    player = 1 if np.sum(board)==0 else -1\n",
    "    board = board*player\n",
    "    game = cccc.Board(board,1)\n",
    "    actions = game.legal_moves()\n",
    "    net_eval = pol_net.predict(board.reshape(1,6,7,1)).reshape(7)\n",
    "    net_eval = [net_eval[i] if i in actions else -np.inf for i in range(7)]\n",
    "    return softmax(net_eval,0.1)  \n",
    "    \n",
    "    \n",
    "node = MCTS_node(cccc.Board,game.board,game.player,policy=pass_policy,net=net,cache={})\n",
    "\n",
    "\n",
    "#MCTS\n",
    "p1_cache = {}\n",
    "p4_cache = {}\n",
    "bp_cache = {}\n",
    "\n",
    "\n",
    "def policy1(game,net,time = 5,mix = 0.5,rollout = 'uniform'):\n",
    "    global node\n",
    "    TREE_CACHE = {}\n",
    "    tree = MCTS_node(cccc.Board,game.board,game.player,policy = pass_policy,net=net,cache = p1_cache)\n",
    "    node = tree\n",
    "    MCTS(tree,game,cccc.Board,dur = time,policy = pass_policy,net=net,leaf_branch=5,mix=mix,rollout_policy = rollout)\n",
    "    \n",
    "    return max(tree.N.items() , key = lambda x: x[1])[0]  #robust\n",
    "    \n",
    "    #return max(node_score(tree).items(), key = lambda x: x[1])[0] \n",
    "\n",
    "#RANDOM    \n",
    "ones = [np.ones(i) for i in range(1,8)]\n",
    "def policy2(game):\n",
    "    actions = game.legal_moves()\n",
    "    \n",
    "    return actions[policy_to_index(softmax(ones[len(actions)-1]))]\n",
    "\n",
    "#PURE NET\n",
    "\n",
    "def policy3(game,net):\n",
    "    board = game.board * game.player\n",
    "    actions = game.legal_moves()\n",
    "    try:\n",
    "        return actions[policy_to_index(net_to_policy(net,board,0.5))]\n",
    "    except:\n",
    "        print net_to_policy(net,board)\n",
    "        sys.exit()\n",
    "#RANDOM MCTS\n",
    "\n",
    "def policy4(game,time = 5):\n",
    "    global TREE_CACHE\n",
    "    global node\n",
    "    TREE_CACHE = {}\n",
    "    tree = MCTS_node(cccc.Board,game.board,game.player,leaf_branch=5,mix = 0.9999,cache = p4_cache)\n",
    "    node = tree\n",
    "    MCTS(tree,game,cccc.Board,dur = time)\n",
    "    \n",
    "    # return max(tree.N.items() , key = lambda x: x[1])[0]  #robust\n",
    "    \n",
    "    return max(node_score(tree).items(), key = lambda x: x[1])[0] \n",
    "\n",
    "def polpol(game,pol_net,temp = 0):\n",
    "    board = game.board*game.player\n",
    "    actions = game.legal_moves()\n",
    "    net_eval = pol_net.predict(board.reshape(1,6,7,1)).reshape(7)\n",
    "    net_eval = np.array([net_eval[i] for i in range(7) if i in actions])\n",
    "    return actions[policy_to_index(softmax(net_eval,temp=temp))]\n",
    "\n",
    "def bothpol(game,net,pol_net,mix=0.5,time = 5):\n",
    "    global TREE_CACHE\n",
    "    global node\n",
    "    TREE_CACHE = {}\n",
    "    tree = MCTS_node(cccc.Board,game.board,game.player,policy = pass_policy,net=net,cache = bpcache)\n",
    "    node = tree\n",
    "    MCTS(tree,game,cccc.Board,dur = time,policy = pass_policy,net=net,leaf_branch=5,mix=mix,rollout_policy = roll_policy)\n",
    "    \n",
    "    return max(tree.N.items() , key = lambda x: x[1])[0]\n",
    "\n",
    "t0 = time.clock()\n",
    "ax = plt.gca()\n",
    "for _ in range(1000):\n",
    "    game = cccc.Board()\n",
    "    while not game.over:\n",
    "        t1,t2,t3=0,0,0\n",
    "        if game.player == 1:\n",
    "            game.update_move(policy3(game,net2))\n",
    "        else:\n",
    "            game.update_move(policy3(game,net))\n",
    "        if print_board:\n",
    "            display.clear_output(wait=True)\n",
    "            ax = board_to_plot(ax,game.board)\n",
    "            display.display(plt.gcf())\n",
    "            sys.stdout.write('\\r{}-{}-{}, games played: {}'.format(wins,ties,losses,games))\n",
    "            print ''\n",
    "            print 'tree: {:1.2f}, rollout: {:1.2f}, backprob: {:1.2f}'.format(t1,t2,t3)\n",
    "            for j,item in enumerate(principal(node)):\n",
    "                if node.net == 'none':\n",
    "                    print item[0],game.player*item[3]*(-1)**(j+1)*2\n",
    "                else:\n",
    "                    print item[0],game.player*item[3]*(-1)**(j+1)\n",
    "            \n",
    "    logs.append(game.log)\n",
    "    score += game.winner()\n",
    "    if game.result==1:\n",
    "        wins+=1\n",
    "    if game.result==0:\n",
    "        ties+=1\n",
    "    if game.result==-1:\n",
    "        losses+=1\n",
    "    games +=1\n",
    "    if len(game.log) > len(longest):\n",
    "        longest = game.log\n",
    "    if games%10==0:\n",
    "        sys.stdout.write('\\r{}-{}-{}, games played: {}'.format(wins,ties,losses,games))\n",
    "    \n",
    "print \"\\n\",score,games\n",
    "print \"time: {}\".format(time.clock()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 0, 2, 2, 0, 4, 4, 1, 5, 3]\n",
      "[4, 5, 5, 1, 6, 3, 0, 1, 6, 6, 5, 4, 6, 4, 4, 3, 6, 1, 4, 5, 6, 2]\n",
      "[4, 5, 3, 0, 5, 3, 6, 0, 0, 5, 3, 3, 0, 2, 0, 0, 4, 3, 6, 2, 1, 6, 1, 4, 4, 5]\n",
      "[1, 1, 5, 3, 4, 2, 1, 5, 2, 4, 3, 1, 6, 6, 6, 0, 3, 6, 3, 6, 3]\n",
      "[2, 1, 5, 4, 1, 0, 3, 6, 2, 5, 2, 5, 0, 4, 2]\n",
      "[2, 4, 2, 1, 5, 0, 3, 3, 0, 6, 1, 2, 5, 3, 2, 4, 2, 5, 4, 4, 3]\n",
      "[4, 2, 2, 4, 0, 0, 6, 1, 3, 5, 2, 4, 3, 4, 6, 4]\n",
      "[5, 6, 1, 6, 6, 3, 4, 4, 3, 6, 2, 6, 1, 6, 2, 2, 3, 0, 2, 3, 0]\n",
      "[3, 5, 2, 5, 6, 1, 0, 0, 0, 2, 5, 3, 3, 5, 5, 2, 5, 0, 6, 1]\n",
      "[4, 5, 5, 1, 2, 2, 3, 1, 2, 1, 0, 1]\n",
      "[1, 2, 2, 1, 6, 4, 2, 3, 6, 2, 0, 5]\n",
      "[0, 4, 6, 3, 3, 3, 5, 3, 2, 2, 6, 0, 0, 2, 0, 3, 6, 6, 2, 1, 0, 0, 5, 4, 4, 4]\n",
      "[2, 6, 4, 0, 0, 2, 3, 1, 5]\n",
      "[0, 5, 6, 6, 0, 5, 4, 3, 4, 2, 3, 1, 2, 1, 2, 3, 0, 0, 4, 6, 2, 4, 4, 5, 3, 2, 4, 0, 0, 5]\n",
      "[0, 0, 1, 6, 0, 4, 1, 6, 1, 1, 4, 4, 5, 2, 0, 2, 5, 6, 4, 4, 6, 3, 3, 6, 3, 4, 2]\n",
      "[6, 5, 0, 1, 1, 2, 4, 0, 0, 4, 3, 6, 3, 1, 3, 3, 3, 6, 2, 2, 2, 6, 4, 6]\n",
      "[4, 1, 2, 2, 0, 4, 2, 2, 5, 3, 2, 5, 3, 0, 0, 5, 4, 3, 5]\n",
      "[2, 3, 3, 0, 5, 6, 2, 0, 3, 6, 3, 4, 2, 5, 6, 3, 2]\n",
      "[0, 2, 0, 3, 5, 4, 5, 6, 4, 4, 1, 4, 3, 6, 2]\n",
      "[4, 5, 4, 4, 6, 1, 5, 5, 6, 5, 5, 2, 6, 6, 5, 2, 1, 6, 0, 2, 2, 0, 4, 2, 6, 4, 0, 1, 1, 1, 0, 3, 3]\n",
      "[1, 0, 0, 0, 5, 5, 1, 5, 4, 4, 4, 6, 3, 0, 2]\n",
      "[6, 4, 0, 2, 0, 5, 2, 3]\n",
      "[4, 3, 0, 0, 6, 0, 6, 6, 6, 2, 4, 2, 6, 5, 4, 2, 0, 4, 3, 5, 5, 5, 0, 1, 5, 4, 0, 4, 2, 3]\n",
      "[3, 1, 1, 5, 0, 2, 1, 6, 1, 1, 2, 4, 0, 0, 1, 4, 6, 3, 6, 5, 0]\n",
      "[1, 1, 0, 6, 3, 5, 2]\n",
      "[0, 5, 1, 1, 0, 0, 1, 1, 0, 6, 2, 5, 3]\n",
      "[1, 4, 6, 2, 5, 2, 2, 1, 4, 1, 5, 4, 3, 2, 0, 3, 5, 5]\n",
      "[4, 1, 4, 1, 0, 0, 6, 1, 3, 5, 2, 0, 1, 5, 0, 4, 5, 6, 6, 1, 6]\n",
      "[3, 6, 6, 5, 2, 3, 2, 6, 4, 1, 3, 5, 1, 5, 5, 4, 6, 4, 5, 4, 5, 3]\n",
      "[1, 5, 6, 1, 0, 1, 4, 3, 1, 3, 3, 1, 6, 6, 1, 5, 6, 4, 6, 2, 3, 2]\n",
      "[0, 3, 3, 5, 5, 5, 0, 2, 4, 1, 6, 6, 5, 4, 4, 3, 2, 3, 1]\n",
      "[4, 2, 4, 6, 0, 0, 6, 1, 6, 1, 1, 6, 2, 2, 1, 6, 4, 1, 4]\n",
      "[2, 5, 5, 6, 0, 4, 2, 5, 3, 1, 2, 5, 1, 5, 5, 6, 2]\n",
      "[1, 4, 6, 2, 5, 5, 2, 0, 4, 6, 6, 3, 5, 4, 6, 2, 4, 1, 4, 5, 1, 1, 1, 6, 3, 3, 0, 3]\n",
      "[1, 4, 4, 2, 1, 2, 0, 6, 0, 3, 2, 5]\n",
      "[5, 4, 3, 1, 0, 2, 3, 2, 2, 4, 5, 1, 2, 5, 4, 4, 2, 1, 2]\n",
      "[2, 4, 2, 5, 1, 5, 5, 0, 3, 1, 1, 6, 1, 0, 3, 6, 1, 1, 5, 0, 2, 0]\n",
      "[2, 3, 5, 0, 3, 0, 3, 0, 4, 6, 2, 2, 2, 4, 0, 3, 2, 0, 3, 2, 4, 6, 4, 1, 3, 1]\n",
      "[1, 0, 5, 5, 5, 0, 0, 3, 3, 3, 6, 3, 5, 2, 3, 0, 0, 5, 2, 4, 0, 6, 4, 5, 3, 2, 1]\n",
      "[1, 3, 5, 5, 1, 3, 6, 6, 0, 3, 3, 5, 0, 2, 0, 0, 6, 1, 3, 1, 3, 0, 0, 6, 2, 2]\n",
      "[0, 0, 5, 3, 4, 4, 5, 2, 5, 5, 0, 0, 3, 3, 4, 4, 1, 6, 3, 1, 0, 6, 4, 4, 0, 6, 2, 6]\n",
      "[6, 0, 5, 3, 4, 6, 6, 3, 0, 2, 3, 1]\n",
      "[4, 4, 3, 4, 3, 3, 6, 5, 6, 5, 0, 2, 1, 5, 6, 6, 0, 1, 0, 5]\n",
      "[2, 2, 1, 3, 1, 2, 0, 4, 5, 4, 3, 2, 3, 2]\n",
      "[1, 4, 4, 3, 6, 6, 3, 6, 1, 0, 1, 1, 1, 5, 2, 0, 6, 6, 6, 0, 2]\n",
      "[5, 0, 0, 2, 3, 4, 0, 5, 2, 1, 4, 3, 0, 0, 5, 1, 1]\n",
      "[4, 3, 6, 4, 1, 6, 4, 6, 5, 2, 0, 0, 5, 3, 1, 5, 0, 0, 0, 6]\n",
      "[6, 4, 0, 0, 1, 0, 0, 3, 3, 6, 1, 2, 3, 1, 3, 3, 3, 6, 4, 2, 5, 2, 0, 2]\n",
      "[1, 2, 0, 5, 1, 2, 5, 4, 5, 3]\n",
      "[4, 4, 5, 4, 3, 0, 1, 6, 3, 2, 5, 0, 2, 3, 2, 3, 4, 6, 3, 6, 0, 1, 5, 6]\n",
      "[5, 2, 0, 1, 6, 3, 0, 4]\n",
      "[3, 2, 6, 6, 6, 0, 6, 6, 6, 3, 4, 1, 5]\n",
      "[2, 0, 2, 1, 3, 4, 2, 2, 0, 0, 5, 2, 5, 3, 5, 5, 6, 4, 3, 4, 6, 0, 5, 4]\n",
      "[5, 3, 3, 0, 2, 3, 4, 0, 0, 6, 6, 1, 3, 1, 6, 6, 4, 5, 5, 5, 6, 0, 0, 6, 0, 5, 4, 4]\n",
      "[0, 1, 4, 4, 5, 1, 5, 6, 1, 5, 4, 2, 2, 3, 6, 1, 1, 3, 6, 2, 5, 6]\n",
      "[0, 6, 1, 5, 5, 4, 1, 0, 4, 2, 3, 0, 2, 5, 1, 5, 1]\n",
      "[0, 6, 0, 3, 1, 5, 4, 6, 1, 5, 3, 0, 5, 5, 4, 3, 1, 1, 0, 3, 1, 3, 3, 5, 6, 0, 1, 2, 4, 4, 0, 2]\n",
      "[5, 0, 5, 3, 5, 5, 3, 3, 3, 5, 2, 6, 3, 1, 5, 2, 4, 4, 1, 2, 1, 0, 1, 1, 2, 3, 4, 2, 0, 4]\n",
      "[0, 2, 3, 4, 0, 3, 2, 0, 0, 3, 1, 6, 2, 6, 3, 1, 4, 1, 4, 1, 1, 1, 4, 3, 5, 4, 2, 2, 5, 3]\n",
      "[6, 0, 0, 0, 1, 3, 3, 3, 5, 6, 2, 4, 6, 2, 5, 1, 0, 1, 3, 0, 2, 6, 4, 4, 5, 5, 2, 1, 6, 3, 2, 2, 6, 1]\n",
      "[3, 1, 5, 5, 5, 1, 1, 6, 0, 6, 2, 4, 3, 3, 5, 4, 5, 4, 5]\n",
      "[5, 4, 4, 3, 4, 0, 4, 4, 3, 4, 3, 5, 2, 1, 3, 5, 5]\n",
      "[1, 3, 1, 4, 6, 0, 1, 1, 4, 2, 2, 3, 2, 0, 3, 0, 4]\n",
      "[1, 6, 5, 5, 2, 1, 0, 3, 3, 0, 2, 0, 3, 1, 0, 3, 6, 1, 1, 1, 3, 3, 6, 2, 4, 5, 0, 5, 4, 2, 2]\n",
      "[4, 0, 5, 4, 1, 4, 4, 6, 4, 0, 0, 6, 6, 3, 1, 0, 5, 4, 2, 5, 1, 2, 1]\n",
      "[6, 2, 4, 6, 3, 2, 2, 4, 1, 5, 6, 5, 0, 0, 5, 3]\n",
      "[5, 6, 3, 4, 1, 0, 0, 2, 2, 6, 3, 5, 1]\n",
      "[4, 3, 5, 1, 5, 1, 5, 5, 1, 6, 6, 1, 3, 4, 6, 6, 2, 6, 3, 4, 3, 3, 1, 5, 1, 5, 3, 6, 4, 2, 2, 4]\n",
      "[5, 0, 5, 6, 5, 2, 5]\n",
      "[2, 4, 3, 4, 4, 2, 5, 4, 4, 1, 4, 2, 5, 2, 0, 0, 6, 6, 5, 2]\n",
      "[2, 4, 2, 0, 2, 6, 2]\n",
      "[4, 6, 4, 3, 4, 2, 5, 4, 3, 3, 5, 2, 6]\n",
      "[3, 6, 5, 3, 0, 2, 3, 2, 6, 3, 2, 1, 2, 2, 5, 3, 1, 5, 1, 5, 2, 6, 0, 0, 4, 4, 4]\n",
      "[3, 1, 2, 5, 0, 4, 3, 0, 5, 2, 5, 1, 4, 4, 4, 1, 0, 1]\n",
      "[6, 0, 6, 4, 1, 4, 5, 1, 1, 1, 6, 6, 0, 1, 4, 4, 2, 2, 5, 5, 5, 6, 6, 5, 5, 2, 0, 0, 2, 4, 2, 0, 3, 2, 3]\n",
      "[4, 2, 4, 0, 0, 2, 1, 4, 4, 1, 6, 5, 3, 2, 2, 3, 3, 3]\n",
      "[0, 2, 5, 6, 4, 0, 1, 6, 4, 1, 0, 2, 6, 6, 3, 3]\n",
      "[0, 1, 0, 4, 0, 0, 5, 3, 0, 4, 1, 2]\n",
      "[2, 6, 4, 2, 2, 2, 0, 0, 0, 3, 2, 5, 5, 4, 4, 2, 0, 5, 5, 3, 5, 5, 1, 4, 1, 3]\n",
      "[3, 6, 3, 2, 2, 1, 1, 0, 1, 3, 3, 0, 1, 2, 3, 3, 2, 5, 1]\n",
      "[0, 3, 6, 3, 4, 3, 2, 3]\n",
      "[3, 0, 1, 5, 2, 4, 1, 6, 2, 2, 5, 4, 3, 0, 0, 5, 3, 3, 4, 1, 5]\n",
      "[2, 5, 5, 0, 0, 2, 4, 6, 4, 3, 0, 1, 2, 0, 2, 1, 0, 4, 1, 6, 3, 3, 1]\n",
      "[1, 3, 2, 4, 6, 0, 2, 3, 6, 0, 6, 3, 3, 5, 6]\n",
      "[2, 1, 1, 5, 4, 5, 1, 1, 3, 2, 5, 1, 4, 3, 6, 5, 2, 2, 1, 4, 4, 5, 3, 0, 0, 5, 3, 4, 4, 0, 3, 6, 2, 2, 0, 3, 0, 6]\n",
      "[6, 5, 5, 5, 6, 3, 4, 5, 3, 4, 5, 2, 5, 0, 1, 4, 1, 4, 1, 1, 6, 6]\n",
      "[1, 2, 4, 1, 6, 4, 5, 1, 3]\n",
      "[1, 1, 0, 6, 5, 1, 1, 1, 0, 3, 2, 5, 3, 5, 2, 4, 4, 2, 6, 4, 0, 0, 2, 3]\n",
      "[1, 2, 1, 3, 0, 5, 5, 5, 5, 4]\n",
      "[4, 4, 3, 0, 3, 1, 1, 1, 4, 3, 3, 6, 3, 6, 1, 4, 1, 1, 4, 2, 2, 2, 0]\n",
      "[5, 5, 2, 0, 2, 3, 3, 4, 4, 2, 2, 3, 4, 3, 2, 5, 5]\n",
      "[2, 6, 3, 0, 4, 1, 5]\n",
      "[4, 0, 6, 2, 0, 5, 6, 3, 1, 5, 4, 6, 4, 6, 6, 5, 4]\n",
      "[4, 3, 0, 6, 0, 5, 2, 3, 0, 0, 4, 3, 1, 3]\n",
      "[2, 4, 4, 6, 6, 6, 2, 6, 5, 5, 2, 2, 3, 5, 6, 4, 3, 0, 3, 3]\n",
      "[3, 1, 3, 3, 1, 5, 1, 5, 2, 5, 2, 1, 6, 5]\n",
      "[0, 2, 6, 6, 2, 4, 3, 1, 6, 5, 0, 3, 2, 4, 3, 4, 1, 4]\n",
      "[2, 4, 6, 1, 3, 2, 6, 4, 1, 0, 0, 0, 4, 4, 4, 0, 2, 1, 5, 4, 1, 2, 1, 0, 2, 6, 3, 0]\n",
      "[3, 6, 1, 5, 6, 4, 1, 0, 0, 4, 3, 2, 4, 2, 4, 1, 1, 3, 1, 4, 2, 2]\n",
      "[2, 2, 6, 4, 6, 2, 2, 1, 0, 6, 3, 1, 3, 5, 3, 4, 1, 3, 1, 2, 0, 3, 4, 3, 2, 0, 0, 0, 5, 5, 4, 5, 0, 4]\n",
      "[4, 5, 3, 5, 3, 5, 0, 5]\n",
      "[2, 6, 0, 1, 4, 6, 4, 0, 1, 6, 2, 6]\n",
      "[0, 4, 4, 6, 3, 4, 1, 2, 2, 0, 3, 4, 4, 1, 4, 3, 6, 6, 5, 5, 3, 6, 2, 6, 0, 5]\n",
      "[3, 5, 0, 6, 4, 4, 6, 6, 4, 4, 6, 6, 6, 5, 4, 0, 3, 3, 3, 5, 0, 1, 2, 5]\n",
      "[1, 3, 4, 0, 1, 3, 2, 1, 0, 2, 6, 4, 5, 3, 5, 3]\n",
      "[1, 1, 1, 5, 0, 5, 3, 6, 2]\n",
      "[5, 4, 2, 5, 4, 4, 0, 1, 0, 2, 4, 1, 6, 3, 2, 2, 6, 1, 1, 1, 4, 6, 2, 4, 2, 1, 6, 3, 6, 6, 3, 5, 3, 3]\n",
      "[6, 6, 4, 6, 3, 3, 5]\n",
      "[2, 2, 0, 1, 0, 0, 4, 2, 0, 5, 2, 0, 0, 2, 4, 1, 1, 2, 1, 5, 3, 6, 5, 6, 3, 1, 3, 5, 5, 4, 1, 3]\n",
      "[5, 0, 2, 6, 6, 0, 4, 6, 3]\n",
      "[1, 3, 4, 0, 3, 4, 3, 5, 5, 3, 6, 4, 3, 4, 1, 0, 0, 4]\n",
      "[5, 5, 5, 4, 1, 3, 4, 5, 2, 2, 3, 3, 1, 3, 2, 0, 5, 3, 2, 1, 0, 1, 5, 1, 6, 1]\n",
      "[6, 5, 5, 2, 2, 4, 3, 3, 3, 2, 3, 4, 3, 3, 5, 2, 2, 4, 2, 4]\n",
      "[4, 1, 3, 4, 4, 4, 3, 0, 3, 3, 3, 4, 0, 6, 3, 5, 4, 6, 5, 6, 5, 2, 0, 6]\n",
      "[6, 4, 2, 0, 4, 0, 0, 2, 0, 6, 6, 5, 0, 0, 5, 5, 5, 6, 1, 6, 6, 5, 1, 5, 1, 4, 3, 1, 1, 2, 4, 2, 1, 4, 2, 4, 3, 3]\n",
      "[5, 6, 1, 1, 4, 3, 1, 4, 0, 1, 5, 0, 2, 3, 3, 2]\n",
      "[6, 5, 3, 5, 4, 4, 4, 2, 3, 1, 3, 5, 5, 3, 3, 5, 0, 1, 0, 5, 1, 4, 4, 0, 4, 0, 0, 1, 3, 0, 1, 6, 6]\n",
      "[4, 2, 2, 6, 4, 3, 4, 2, 6, 4, 6, 0, 0, 0, 6, 6, 2, 1]\n",
      "[5, 6, 0, 3, 3, 2, 2, 1, 0, 1, 5, 2, 4, 4, 4, 1, 1, 4, 6, 3, 3, 2, 2]\n",
      "[0, 6, 2, 2, 3, 5, 1]\n",
      "[4, 2, 1, 2, 3, 4, 2, 4, 2, 4, 6, 5, 0, 4]\n",
      "[3, 0, 0, 5, 6, 5, 5, 5, 3, 1, 1, 6, 5, 2, 6, 4, 5, 2, 4, 6, 4, 2, 4, 3, 6, 4, 1, 2]\n",
      "[0, 0, 2, 5, 0, 0, 0, 2, 0, 3, 3, 4, 1, 6]\n",
      "[2, 1, 0, 3, 1, 3, 2, 4, 6, 6, 3, 5, 3, 2, 2, 4, 6, 4, 3, 3, 4, 2, 1, 0, 1]\n",
      "[5, 4, 4, 3, 5, 0, 2, 2, 4, 4, 1, 2, 3, 2, 4, 2]\n",
      "[2, 0, 1, 6, 3, 2, 4]\n",
      "[3, 6, 5, 5, 2, 4, 2, 2, 6, 4, 4, 0, 0, 4, 0, 2, 2, 3, 0, 0, 3, 3, 0, 4, 4, 3, 5, 6, 1, 1]\n",
      "[5, 2, 5, 5, 1, 1, 5, 6, 5, 2, 6, 3, 5, 0, 4, 0, 4, 3]\n",
      "[4, 0, 0, 1, 4, 5, 3, 6, 3, 0, 5, 6, 3, 4, 0, 5, 6, 6, 0, 1, 1, 2, 3]\n",
      "[2, 0, 5, 1, 5, 3, 3, 0, 2, 1, 6, 2, 5, 5, 6, 5, 5, 0, 1, 6, 0, 1, 1, 4, 6, 6, 2, 4, 2, 6, 3, 1, 3, 4, 3]\n",
      "[3, 4, 1, 5, 1, 1, 1, 0, 6, 4, 0, 4, 1, 3, 6, 2, 5, 5, 3, 3, 4, 5]\n",
      "[3, 2, 5, 4, 5, 4, 3, 4, 5, 4]\n",
      "[1, 0, 4, 3, 5, 6, 3, 0, 0, 1, 4, 0, 4, 4, 3, 3, 1, 2, 6, 3, 5]\n",
      "[2, 2, 0, 6, 2, 1, 0, 2, 5, 4, 0, 0, 1, 6, 0, 5, 1, 6, 5, 2, 1, 1, 1, 6]\n",
      "[1, 6, 0, 3, 5, 5, 0, 6, 1, 3, 4, 1, 1, 6, 6, 3, 3, 0, 6, 1, 4, 4, 2, 2, 0, 2]\n",
      "[2, 0, 5, 0, 4, 2, 3]\n",
      "[0, 3, 3, 4, 2, 3, 4, 5, 4, 0, 6, 3, 5, 6, 2]\n",
      "[4, 3, 5, 2, 5, 1, 4, 0]\n",
      "[2, 3, 2, 4, 2, 2, 3, 4, 3, 4, 3, 3, 2, 4]\n",
      "[1, 5, 1, 2, 2, 5, 5, 2, 2, 3, 5, 3, 5, 5, 4, 3, 3, 6, 1, 0, 1]\n",
      "[4, 5, 5, 5, 6, 6, 0, 5, 2, 6, 2, 3, 4, 6, 3]\n",
      "[5, 2, 3, 1, 0, 1, 1, 2, 3, 1, 4, 2, 6]\n",
      "[5, 3, 1, 3, 1, 3, 3, 5, 4, 1, 0, 3, 6, 1, 1, 1, 6, 4, 6, 6, 4, 0, 3, 0, 5, 4, 5, 4, 4, 5, 6, 6]\n",
      "[0, 1, 0, 4, 2, 6, 3, 1, 1, 1, 3, 3, 1, 0, 3, 4, 5, 4, 3, 4]\n",
      "[4, 6, 0, 3, 5, 5, 0, 6, 6, 3, 5, 4]\n",
      "[5, 5, 0, 3, 5, 2, 6, 1, 6, 6, 4, 4, 5, 3, 4, 4, 0, 2]\n",
      "[5, 3, 1, 0, 3, 1, 2, 1, 0, 0, 6, 2, 0, 6, 0, 1, 4, 2, 3, 1]\n",
      "[5, 6, 5, 0, 4, 3, 2, 2, 1, 5, 6, 3, 1, 3, 5, 3]\n",
      "[4, 4, 3, 2, 0, 1, 2, 6, 2, 6, 3, 3, 1, 5, 0]\n",
      "[3, 2, 6, 5, 4, 2, 2, 5, 4, 0, 3, 3, 6, 3, 1, 6, 3, 4, 5, 6, 4]\n",
      "[0, 3, 2, 2, 1, 6, 2, 5, 6, 2, 0, 4]\n",
      "[5, 2, 0, 3, 4, 4, 4, 3, 0, 2, 3, 2, 6, 2]\n",
      "[3, 4, 4, 4, 0, 5, 0, 3, 4, 1, 1, 5, 5, 3, 6, 0, 3, 2, 3, 5]\n",
      "[6, 5, 2, 2, 1, 6, 1, 3, 1, 1, 2, 2, 5, 1, 1, 3, 2, 3, 3, 0, 3, 4, 2, 6, 3, 4]\n",
      "[1, 3, 2, 2, 2, 0, 4, 2, 6, 6, 2, 5, 3, 4, 3, 4, 4, 6, 2, 0, 1, 6, 0, 1, 1]\n",
      "[5, 2, 6, 0, 0, 5, 6, 5, 4, 2, 3]\n",
      "[2, 6, 2, 3, 6, 4, 4, 2, 6, 5]\n",
      "[1, 6, 3, 6, 0, 2, 4, 3, 6, 0, 6, 2, 1, 1, 4, 0, 2, 2, 0, 1, 4, 4, 5, 1, 3, 6, 3]\n",
      "[0, 2, 5, 4, 2, 6, 3, 0, 2, 0, 2, 0, 0, 2, 6, 4, 6, 2, 1, 3, 3, 3, 4, 4, 3, 3, 1, 0, 6, 1, 6]\n",
      "[6, 3, 1, 0, 4, 3, 4, 2, 3, 2, 2, 0, 1, 3, 3, 6, 3, 2, 2, 0, 5, 0]\n",
      "[3, 4, 1, 1, 3, 4, 3, 3, 5, 5, 4, 6, 2, 0, 0, 5, 5]\n",
      "[5, 0, 4, 0, 1, 3, 1, 5, 3, 2, 0, 1, 6, 2, 2, 1, 2, 4, 2, 2, 5, 0]\n",
      "[0, 1, 0, 1, 1, 4, 5, 3, 2, 5, 1, 0, 0, 6, 5, 2, 4, 3, 4, 0, 4, 4, 2, 3, 3, 5, 3, 2, 6]\n",
      "[2, 3, 0, 1, 3, 2, 3, 0, 0, 5, 3, 2, 1, 3, 2, 5, 1, 0, 1, 5, 3, 2, 5, 6, 1]\n",
      "[2, 4, 5, 4, 5, 4, 1, 4]\n",
      "[3, 4, 0, 4, 5, 3, 4, 0, 4, 0, 0, 5, 4, 4, 0, 0, 1, 2, 5, 5, 5, 2]\n",
      "[6, 2, 6, 1, 4, 1, 0, 0, 1, 3, 6, 6, 5, 3, 2, 3, 1, 4, 4, 1, 3, 4, 1, 5, 0, 0, 5, 5, 4, 4, 5, 3, 2, 5, 2, 3, 2]\n",
      "[6, 2, 3, 4, 5, 3, 0, 2, 0, 3, 4, 2, 5, 2]\n",
      "[4, 5, 0, 5, 4, 3, 0, 6, 0, 0, 5, 5, 4, 6, 1, 4, 0, 3, 6, 5, 1, 1, 3]\n",
      "[3, 4, 0, 6, 6, 0, 4, 4, 1, 6, 2]\n",
      "[3, 2, 2, 6, 2, 5, 0, 2, 3, 5, 0, 5, 4, 5]\n",
      "[5, 3, 0, 0, 3, 2, 0, 1, 4, 2, 6, 2, 2, 4, 1, 4, 4, 2, 5, 6, 3, 6, 1, 0, 3, 3, 4, 1, 6, 4, 2, 3, 0, 5, 5]\n",
      "[0, 1, 0, 2, 5, 5, 0, 4, 0]\n",
      "[2, 2, 4, 1, 0, 1, 3, 5, 3, 2, 5, 4, 5, 2, 3, 3, 0, 2]\n",
      "[3, 2, 1, 4, 2, 6, 4, 3, 2, 0, 4, 2, 2, 2, 5, 6, 3, 4, 6, 4, 6, 5, 5]\n",
      "[4, 1, 2, 2, 5, 5, 3]\n",
      "[5, 2, 4, 6, 5, 6, 5, 5, 4, 5, 5, 4, 2, 1, 4, 1, 3, 3]\n",
      "[6, 0, 4, 1, 2, 0, 5, 2, 3]\n",
      "[5, 3, 3, 6, 5, 6, 1, 5, 3, 6, 4, 6]\n",
      "[1, 3, 3, 2, 1, 6, 5, 0, 3, 3, 2, 0, 6, 0, 4, 1, 4]\n",
      "[3, 4, 2, 2, 6, 5, 1, 0, 2, 4, 3, 4, 5, 4]\n",
      "[6, 5, 3, 1, 3, 3, 6, 1, 1, 6, 1, 6, 1, 1, 6, 2, 2, 0, 2, 5, 4]\n",
      "[3, 3, 0, 2, 5, 5, 5, 0, 3, 0, 4, 5, 6]\n",
      "[2, 0, 5, 3, 5, 5, 5, 3, 0, 5, 0, 3, 5, 3]\n",
      "[4, 5, 2, 4, 3, 0, 2, 1, 5, 5, 1, 2, 0, 3, 3, 4, 2, 4, 2, 4]\n",
      "[6, 2, 2, 3, 1, 6, 6, 2, 0, 2, 5, 3, 3, 4, 0, 3, 4, 5, 2, 0, 4, 4, 5]\n",
      "[0, 4, 5, 0, 0, 3, 5, 3, 5, 6, 5]\n",
      "[0, 3, 5, 6, 1, 5, 3, 2, 3, 6, 5, 3, 0, 6, 2, 1, 2, 1, 2, 2, 5, 5, 1, 4, 6, 3, 0, 0, 4]\n",
      "[3, 5, 6, 6, 1, 3, 6, 0, 0, 4, 0, 6, 3, 1, 2, 3, 1, 4, 5, 3, 2, 0, 6, 2]\n",
      "[2, 2, 3, 2, 0, 0, 6, 0, 1]\n",
      "[5, 5, 4, 1, 2, 4, 3]\n",
      "[3, 5, 1, 4, 1, 0, 2, 2, 5, 3, 1, 6, 2, 1, 2, 3, 5, 5, 4, 4, 2, 1, 2]\n",
      "[0, 5, 3, 6, 0, 0, 0, 5, 3, 5, 3, 3, 5, 0, 5, 4, 3, 2, 0, 3, 4, 2, 2, 4]\n",
      "[3, 1, 5, 4, 5, 1, 3, 2, 4, 2, 4, 1, 2, 1]\n",
      "[6, 4, 2, 3, 1, 0, 0, 2, 0, 3, 0, 0, 5, 6, 1, 0, 3, 2, 6, 3, 5, 3, 1, 1]\n",
      "[4, 3, 1, 6, 3, 2, 0, 1, 4, 5, 0, 5, 1, 5, 4, 4, 3, 1, 4, 0, 1, 5]\n",
      "[5, 0, 3, 5, 1, 3, 2, 4, 0, 3, 5, 0, 6, 4, 0, 6]\n",
      "[2, 3, 2, 5, 0, 3, 6, 4, 0, 0, 3, 1, 4, 3, 6, 4, 4, 5, 5, 3, 1, 2, 1, 1]\n",
      "[4, 3, 0, 2, 2, 6, 4, 5, 3, 5, 5, 5, 4, 5, 3, 4, 6, 2, 0, 6, 2, 6, 4, 0, 4, 5, 1, 1, 0, 3]\n",
      "[2, 5, 3, 2, 5, 5, 1, 0, 4]\n",
      "[5, 3, 6, 6, 6, 0, 0, 6, 3, 4, 6, 6, 5, 2, 2, 4, 3, 5]\n",
      "[0, 5, 2, 6, 1, 2, 3]\n",
      "[2, 2, 1, 5, 3, 4, 2, 2, 5, 0, 1, 1, 2, 1, 2, 4, 1, 6, 4, 5, 4, 4, 0, 0, 3, 5, 1, 6, 6, 5, 0, 0, 0, 3]\n",
      "[6, 6, 1, 2, 6, 5, 3, 3, 4, 6, 5, 4, 3, 5, 6, 1, 2, 0, 3, 4, 4]\n",
      "[6, 3, 0, 1, 5, 3, 5, 3, 5, 3]\n",
      "[4, 4, 2, 5, 0, 0, 3, 3, 1]\n",
      "[3, 2, 2, 4, 0, 0, 1, 3, 2, 5, 2, 6, 2]\n",
      "[0, 5, 3, 0, 4, 6, 4, 2, 5, 0, 1, 5, 5, 6, 3, 1, 2]\n",
      "[2, 2, 6, 0, 0, 0, 2, 4, 4, 6, 4, 4, 0, 0, 0, 1, 2, 6, 2, 3, 6, 2, 6, 1, 4, 5, 3, 1, 3, 1]\n",
      "[1, 3, 1, 3, 2, 3, 6, 3]\n",
      "[4, 3, 5, 0, 5, 2, 2, 3, 4, 1]\n",
      "[3, 3, 0, 3, 1, 1, 1, 2, 1, 6, 4, 4, 2, 0, 6, 4, 6, 1, 4, 0, 0]\n",
      "[5, 4, 2, 2, 1, 5, 4, 4, 2, 6, 2, 2, 0, 3, 1, 1, 6, 0, 6, 1, 5, 6, 5, 6, 5, 1, 5]\n",
      "[6, 0, 5, 4, 4, 0, 0, 2, 5, 2, 1, 1, 4, 1, 1, 5, 6, 2, 5, 2]\n",
      "[4, 5, 4, 4, 3, 0, 3, 6, 5, 5, 6]\n",
      "[6, 3, 0, 3, 1, 0, 1, 5, 1, 1, 1, 0, 0, 3, 3, 5, 5, 2, 3, 0, 3, 2, 2]\n",
      "[3, 5, 3, 6, 1, 0, 3, 3, 1, 1, 0, 5, 2, 1, 2]\n",
      "[2, 5, 1, 5, 2, 2, 5, 1, 2, 6, 4, 3, 3, 6, 1, 1, 5, 6, 4, 6]\n",
      "[6, 5, 4, 2, 4, 1, 4, 4, 3, 6, 5, 4, 3, 4, 2]\n",
      "[5, 6, 2, 2, 5, 1, 6, 6, 2, 6, 4, 3, 5, 3, 5]\n",
      "[3, 1, 5, 6, 2, 4, 1, 0, 0, 1, 0, 1, 5, 2, 0, 5, 3, 0, 3, 3, 4, 6, 5, 5, 4]\n",
      "[5, 2, 0, 5, 6, 4, 3, 5, 4, 1, 4, 2, 4, 4, 1, 2, 2, 3, 4, 3, 3, 5, 3, 1, 1]\n",
      "[2, 2, 2, 0, 0, 1, 5, 3, 0, 1, 1, 3, 3]\n",
      "[6, 0, 6, 4, 3, 5, 0, 0, 0, 3, 2, 3, 6, 4, 6]\n",
      "[1, 4, 4, 5, 6, 3, 0, 5, 4, 6, 5, 5, 2, 3, 0, 4, 4, 1, 4, 3, 6, 3]\n",
      "[0, 3, 3, 5, 3, 3, 2, 2, 2, 0, 0, 4, 0, 0, 4, 2, 6, 3, 3, 5, 1, 0, 2, 1, 1]\n",
      "[2, 4, 2, 0, 4, 4, 2, 1, 2]\n",
      "[0, 1, 2, 2, 5, 5, 3, 4, 4, 0, 3, 2, 2, 3, 2, 3, 1, 1, 1, 2, 6, 6, 4, 3, 3, 4]\n",
      "[3, 1, 5, 2, 3, 2, 2, 4, 3, 0, 1, 2, 3]\n",
      "[4, 1, 3, 1, 3, 3, 4, 0, 3, 2, 1, 0, 1, 6, 1, 1, 6, 3, 0, 0, 0, 4, 2, 3, 6, 0, 2]\n",
      "[4, 6, 1, 0, 5, 1, 5, 5, 4, 5, 2, 4, 3]\n",
      "[2, 4, 2, 6, 0, 2, 6, 5, 0, 3]\n",
      "[2, 4, 5, 4, 6, 3, 1, 1, 2, 5, 4, 2, 4, 3, 3]\n",
      "[1, 0, 5, 0, 5, 1, 4, 4, 4, 4, 1, 1, 0, 6, 3, 2, 6, 3, 3, 0, 3, 2]\n",
      "[3, 5, 2, 5, 3, 3, 5, 1, 4, 3, 2, 2, 4, 1, 2, 2, 3, 3, 1, 0]\n",
      "[4, 3, 6, 1, 1, 6, 0, 3, 4, 3, 3, 0, 6, 0, 4, 2, 4]\n",
      "[4, 5, 1, 5, 5, 0, 0, 1, 4, 2, 2, 3, 6, 4, 2, 2, 3, 5, 1, 2, 0, 6, 0, 0, 3]\n",
      "[0, 1, 5, 6, 0, 2, 3, 0, 4, 4, 4, 2, 2, 1, 2, 3]\n",
      "[1, 5, 0, 2, 5, 3, 4, 6, 3, 0, 6, 4, 3, 2, 0, 3, 6, 6, 5, 2, 6, 4, 3, 4, 5, 4]\n",
      "[5, 5, 1, 2, 5, 0, 0, 1, 4, 5, 1, 2, 0, 4, 1, 5, 3, 6, 4, 0, 2, 3]\n",
      "[0, 5, 4, 0, 2, 2, 6, 3, 4, 4, 4, 5, 5, 2, 0, 4, 6, 5, 5, 5, 2, 4, 1, 1, 1, 3]\n",
      "[0, 4, 4, 3, 3, 1, 2, 3, 3, 4, 4, 6, 5, 4, 5, 6, 1, 4, 5, 5, 0, 6, 3, 2, 2]\n",
      "[3, 0, 1, 6, 5, 3, 5, 5, 0, 4, 3, 2, 6, 5, 2, 3, 2, 1, 2, 4, 2]\n",
      "[1, 2, 2, 3, 5, 3, 4, 1, 4, 3, 2, 1, 3, 3, 0, 5, 3, 4, 1, 2, 5, 4, 1, 4, 2, 5]\n",
      "[4, 2, 6, 1, 4, 0, 1, 3]\n",
      "[5, 0, 2, 3, 6, 1, 0, 5, 2, 4, 1, 1, 1, 3, 1, 3, 5, 3]\n",
      "[6, 5, 1, 0, 0, 4, 2, 4, 5, 0, 3, 3, 4, 6, 6, 4, 1, 1, 3, 1, 5]\n",
      "[3, 4, 3, 5, 2, 2, 0, 1, 1, 2, 0, 1, 2, 0, 0, 1, 0, 3]\n",
      "[1, 0, 6, 0, 4, 1, 6, 4, 6, 0, 6]\n",
      "[0, 4, 4, 1, 1, 4, 5, 4, 3, 4, 2, 4]\n",
      "[6, 3, 2, 4, 4, 1, 3, 4, 3, 1, 6, 5, 6, 6, 0, 4, 0, 5, 0, 0, 4, 0, 0, 5, 6, 5]\n",
      "[3, 3, 2, 5, 2, 5, 4, 0, 1]\n",
      "[6, 5, 0, 5, 3, 3, 0, 1, 5, 6, 0, 3, 0]\n",
      "[0, 6, 5, 4, 0, 3, 6, 3, 2, 1, 2, 1, 0, 0, 2, 4, 5, 2, 6, 3, 5, 5, 3, 1, 2, 4, 2, 5, 3, 4]\n",
      "[0, 0, 6, 6, 0, 5, 5, 1, 1, 3, 1, 1, 3, 3, 2, 5, 2, 2, 1, 4, 4]\n",
      "[4, 3, 4, 3, 5, 5, 3, 3, 4, 4, 2, 5, 5, 1, 2, 5, 2, 0, 4, 3, 5, 0, 3, 2, 1, 1]\n",
      "[3, 2, 4, 6, 6, 3, 3, 2, 4, 2, 3, 2]\n",
      "[6, 2, 2, 0, 3, 0, 5, 3, 5, 2, 4]\n",
      "[0, 1, 5, 6, 2, 6, 3, 5, 4]\n",
      "[0, 4, 2, 6, 2, 5, 6, 2, 2, 0, 5, 3]\n",
      "[4, 6, 5, 1, 2, 0, 4, 3, 3, 6, 5, 2, 4, 5, 3, 5, 4]\n",
      "[4, 1, 2, 1, 5, 4, 3]\n",
      "[4, 3, 4, 3, 6, 4, 3, 3, 6, 2, 0, 1, 2, 3, 1, 4, 6, 6, 1, 1, 3, 4, 2, 2]\n",
      "[5, 3, 1, 1, 5, 1, 1, 2, 5, 2, 3, 3, 5]\n",
      "[0, 1, 3, 0, 1, 1, 3, 0, 2, 3, 0, 2, 3, 2]\n",
      "[1, 4, 4, 2, 3, 1, 6, 5, 3, 1, 6, 5, 0, 3, 2, 2, 4, 3, 0, 0]\n",
      "[2, 5, 1, 2, 3, 3, 4]\n",
      "[2, 3, 3, 4, 2, 6, 4, 0, 2, 4, 0, 2, 3, 4, 3, 3, 5, 2, 2, 5, 1, 5, 3, 1, 1, 0, 1, 1, 6, 4]\n",
      "[1, 2, 2, 2, 2, 2, 0, 6, 6, 5, 2, 4, 3, 1, 3, 6, 1, 0, 5, 0, 4]\n",
      "[2, 0, 4, 3, 4, 4, 6, 2, 4, 3, 2, 3, 6, 5, 3, 5, 2, 4, 0, 3, 2, 0, 2]\n",
      "[4, 3, 2, 3, 3, 5, 3, 4, 4, 2, 4, 4, 0, 1, 2, 4, 0, 0, 2, 3, 5, 6, 6, 2, 1]\n",
      "[5, 4, 0, 6, 2, 1, 0, 4, 4, 2, 5, 5, 4, 3, 3, 5, 1, 6, 2, 3, 3]\n",
      "[6, 6, 3, 6, 5, 3, 2, 4, 4, 2, 0, 1, 3, 3, 4, 1, 1, 2, 2]\n",
      "[3, 0, 5, 3, 5, 4, 5, 6, 5]\n",
      "[0, 2, 2, 1, 1, 5, 5, 5, 0, 1, 5, 0, 2, 2, 0, 2, 2, 4, 0, 3]\n",
      "[0, 6, 2, 6, 3, 1, 6, 4, 6, 3, 2, 4, 2, 2, 0, 0, 2, 4, 4, 0, 4, 3, 4, 1, 2, 1, 3, 6, 6, 3, 0, 1]\n",
      "[4, 0, 4, 1, 4, 4, 3, 6, 2, 5, 1, 4, 3, 2, 6, 5, 2, 1, 1]\n",
      "[5, 0, 2, 2, 2, 1, 3, 5, 4]\n",
      "[6, 5, 5, 5, 4, 5, 4, 5, 1, 5]\n",
      "[3, 2, 4, 4, 3, 6, 4, 5, 5, 6, 5, 2, 5, 5, 6, 3, 4, 6, 6]\n",
      "[3, 3, 1, 0, 2, 4, 2, 6, 3, 2, 6, 4, 4, 4, 3, 0, 3, 6, 3]\n",
      "[1, 3, 1, 0, 1, 0, 2, 1, 6, 3, 5, 3, 3, 3, 2, 6, 6, 6, 1, 5, 6, 1, 4, 4]\n",
      "[5, 3, 1, 5, 5, 3, 6, 3, 6, 2, 1, 0, 4, 3]\n",
      "[0, 6, 3, 2, 4, 3, 3, 3, 5, 2, 2, 6, 2, 4, 5, 1, 4, 5, 1, 2, 5, 1, 4, 5, 5, 2, 0, 6, 1, 6]\n",
      "[6, 5, 6, 3, 0, 1, 6, 6, 3, 2, 3, 4]\n",
      "[1, 1, 2, 3, 1, 1, 0, 6, 1, 6, 5, 0, 0, 3, 5, 2]\n",
      "[3, 4, 2, 0, 3, 5, 4, 3, 2, 2, 2, 5, 4, 4, 5, 2, 3, 3, 5]\n",
      "[0, 6, 4, 1, 2, 1, 1, 6, 5, 3, 1, 6, 4, 4, 3, 3, 2, 2, 5]\n",
      "[5, 2, 2, 1, 0, 1, 4, 5, 4, 2, 2, 2, 0, 5, 0, 2, 0]\n",
      "[1, 3, 5, 5, 1, 1, 0, 2, 3, 2, 0, 6, 0, 6, 0]\n",
      "[6, 2, 1, 6, 3, 0, 1, 0, 1, 2, 0, 2, 6, 2]\n",
      "[3, 6, 0, 4, 6, 3, 3, 6, 1, 2, 1, 3, 3, 4, 1, 1, 2, 2]\n",
      "[2, 6, 2, 2, 4, 0, 1, 1, 5, 2, 6, 3, 5, 6, 2, 0, 4, 3, 4, 4, 1, 3, 3]\n",
      "[3, 2, 3, 3, 0, 2, 6, 5, 2, 1, 2, 3, 6, 5, 2, 2, 5, 6, 3, 4, 5, 4, 6, 6, 5, 5, 6, 0, 0, 0, 0, 1, 3, 4, 4]\n",
      "[6, 1, 6, 4, 6, 3, 6]\n",
      "[0, 0, 1, 0, 4, 6, 4, 1, 0, 3, 2, 5, 5, 5, 2, 6, 5, 4, 3]\n",
      "[2, 4, 4, 0, 5, 6, 4, 6, 2, 5, 2, 1, 2]\n",
      "[3, 5, 4, 1, 2, 5, 5, 3, 6, 5, 6, 3, 0, 2, 3, 4]\n",
      "[4, 0, 1, 1, 4, 4, 5, 1, 2, 3, 3, 4, 6, 1, 6, 2, 5]\n",
      "[6, 2, 2, 1, 2, 5, 1, 1, 4, 3, 3, 4, 2, 1, 3, 1, 2]\n",
      "[4, 0, 3, 3, 0, 6, 4, 2, 1, 5, 5, 0, 6, 6, 3, 5, 3, 6, 0, 2, 2, 4, 5, 3, 2, 4, 1, 4, 1, 1, 1]\n",
      "[5, 1, 3, 3, 5, 3, 4, 0, 6]\n",
      "[2, 3, 4, 2, 1, 1, 4, 3, 3, 5, 4, 4, 4, 3, 1, 1, 2]\n",
      "[1, 3, 1, 6, 6, 0, 0, 5, 3, 5, 4, 1, 3, 5, 1, 5]\n",
      "[1, 5, 0, 2, 6, 0, 0, 5, 5, 3, 0, 5, 6, 0, 5, 5, 4, 4, 3, 0, 6, 3, 2, 6, 3, 6, 2, 1, 3, 6, 4, 4, 4, 2]\n",
      "[4, 3, 2, 3, 4, 3, 4, 4, 5, 3]\n",
      "[5, 3, 1, 5, 1, 6, 6, 1, 2, 4, 4, 5, 2, 3, 2, 2, 0, 5, 4, 0, 1, 4, 1, 3, 3]\n",
      "[1, 4, 3, 3, 5, 3, 4, 6, 3, 4, 6, 4, 1, 0, 2, 6, 4, 0, 0, 4, 0, 5, 6, 5]\n",
      "[4, 3, 5, 2, 2, 6, 5, 2, 5, 5, 3, 4, 2, 0, 5, 1]\n",
      "[2, 1, 6, 5, 3, 3, 5, 5, 5, 2, 3, 0, 1, 3, 5, 1, 5, 6, 6, 1, 2, 2, 2, 6, 1, 0, 0, 6, 0, 3]\n",
      "[3, 3, 0, 5, 2, 2, 4, 5, 1]\n",
      "[6, 3, 2, 1, 5, 1, 5, 5, 0, 4, 4, 1, 0, 1]\n",
      "[3, 0, 1, 3, 6, 0, 2, 4, 4, 4, 6, 3, 3, 0, 3, 0]\n",
      "[0, 4, 0, 4, 4, 3, 6, 2, 3, 0, 6, 3, 1, 5]\n",
      "[1, 5, 5, 5, 4, 2, 2, 2, 3, 0, 3, 0, 4]\n",
      "[2, 4, 5, 1, 6, 3, 5, 5, 2, 5, 5, 6, 4, 4, 3]\n",
      "[0, 3, 6, 6, 5, 5, 3, 3, 5, 1, 4, 2, 0, 3, 5, 3, 3, 0, 5, 2, 5]\n",
      "[0, 1, 4, 4, 3, 3, 4, 4, 3, 2, 6, 5, 0, 3, 5, 2, 4, 0, 0, 3, 2, 5, 1, 1, 2, 5, 3, 2, 0, 0, 4, 6]\n",
      "[4, 3, 0, 2, 5, 5, 0, 0, 6, 5, 4, 5, 6, 3, 6, 6, 3, 4]\n",
      "[6, 1, 4, 4, 4, 0, 0, 3, 0, 2]\n",
      "[5, 2, 3, 1, 6, 2, 4]\n",
      "[2, 0, 2, 3, 3, 0, 2, 1, 2]\n",
      "[2, 1, 1, 0, 5, 4, 6, 0, 4, 2, 1, 0, 3, 4, 2, 4, 0, 0, 4, 5, 0, 4, 5, 5, 5, 2, 1, 6, 1]\n",
      "[6, 1, 6, 2, 1, 3, 0, 4]\n",
      "[1, 6, 2, 4, 6, 1, 2, 3, 5, 4, 6, 4, 3, 4]\n",
      "[5, 3, 2, 5, 5, 2, 6, 5, 1, 6, 2, 5, 1, 4, 0, 6, 2, 1, 6, 4, 3, 1, 6, 1, 2, 2, 6, 1]\n",
      "[1, 2, 5, 0, 1, 2, 2, 5, 2, 0, 1, 1, 1, 0, 6, 6, 2, 4, 4, 2, 0, 1, 3, 4, 3, 3, 3, 3, 6, 5, 3, 4]\n",
      "[4, 0, 6, 2, 3, 0, 0, 3, 0, 5, 3, 2, 6, 3, 2, 2, 6, 5, 6]\n",
      "[1, 4, 0, 0, 3, 2, 4, 2, 3, 1, 5, 2, 1, 2]\n",
      "[5, 3, 1, 3, 4, 6, 3, 0, 3, 2, 3, 5, 3]\n",
      "[3, 0, 4, 4, 3, 2, 3, 3, 5, 2, 6]\n",
      "[4, 5, 2, 2, 4, 3, 5, 0, 5, 5, 3, 1, 2, 6, 6]\n",
      "[5, 1, 1, 6, 3, 2, 2, 5, 3, 0, 2, 6, 0]\n",
      "[0, 1, 5, 0, 6, 3, 6, 3, 1, 2, 3, 6, 0, 4]\n",
      "[3, 3, 1, 3, 2, 1, 0]\n",
      "[2, 0, 6, 3, 1, 4, 3, 1, 6, 2, 1, 6, 2, 2, 0, 2, 2, 6, 3, 5, 4, 0, 4]\n",
      "[1, 2, 1, 5, 0, 2, 3, 1, 3, 2, 5, 2]\n",
      "[3, 5, 3, 3, 2, 0, 2, 1, 5, 5, 6, 5, 3, 2, 1, 1, 0]\n",
      "[4, 6, 1, 2, 3, 3, 1, 6, 4, 3, 4, 6, 1, 4, 1]\n",
      "[2, 6, 6, 1, 4, 0, 2, 6, 6, 0, 3, 0, 5]\n",
      "[4, 1, 2, 5, 6, 4, 6, 4, 3, 5, 3, 6, 3, 2, 3]\n",
      "[6, 2, 0, 3, 3, 1, 4, 4, 0, 2, 0, 3, 0]\n",
      "[3, 2, 6, 2, 1, 0, 4, 2, 2, 2, 5]\n",
      "[5, 1, 5, 6, 5, 6, 5]\n",
      "[1, 0, 1, 2, 4, 6, 5, 6, 3, 1, 5, 2, 3, 5, 2, 1, 1, 2, 5, 5, 2, 3, 3, 0, 3, 0, 6, 0]\n",
      "[2, 4, 4, 3, 4, 6, 4, 4, 4, 3, 3, 5]\n",
      "[1, 4, 1, 1, 6, 1, 4, 1, 6, 1]\n",
      "[3, 3, 3, 2, 4, 5, 6, 4, 2, 6, 5, 6, 3, 4, 6, 4, 6, 5, 6, 0, 0, 5]\n",
      "[5, 1, 4, 3, 0, 2, 4, 3, 5, 3, 3, 0, 2, 2, 6, 4, 6, 3, 1, 4, 4, 2, 3, 5]\n",
      "[6, 1, 2, 3, 2, 5, 5, 5, 6, 2, 0, 2, 2, 2, 3, 4, 5, 4, 0, 1, 5, 4, 6, 6]\n",
      "[1, 2, 5, 2, 1, 3, 2, 1, 2, 2, 6, 4, 1, 5, 2, 4, 6, 3]\n",
      "[2, 0, 2, 0, 4, 1, 5, 3, 2, 3, 2]\n",
      "[3, 1, 1, 5, 5, 0, 4, 0, 1, 4, 1, 0, 1]\n",
      "[4, 1, 4, 6, 5, 2, 2, 6, 4, 3, 5, 3, 4]\n",
      "[1, 1, 3, 0, 2, 4, 0, 4, 5, 3, 6, 4, 4, 1, 1, 6, 1, 5]\n",
      "[1, 1, 5, 5, 4, 1, 5, 2, 1, 5, 5, 6, 4, 1, 4, 3, 3, 4, 6, 5, 3, 4, 0, 6, 6, 1, 3, 3, 2, 2, 3, 4, 2]\n",
      "[6, 3, 5, 1, 4, 4, 5, 4, 1, 3, 3, 5, 1, 5, 2, 6, 5, 4, 5, 4]\n",
      "[4, 2, 3, 2, 6, 1, 5]\n",
      "[6, 6, 4, 6, 0, 6, 2, 6]\n",
      "[3, 1, 5, 3, 2, 4, 6, 3, 1, 3, 5, 2, 1, 4, 2, 3]\n",
      "[1, 3, 6, 5, 6, 3, 3, 6, 3, 1, 5, 1, 3, 5, 1, 5, 3]\n",
      "[1, 5, 2, 2, 2, 1, 0, 3, 1, 3, 2, 2, 2, 1, 6, 1, 6, 1, 3, 6, 0, 0, 0, 3, 3]\n",
      "[0, 0, 6, 6, 1, 1, 0, 2, 3, 1, 3, 4, 6, 5, 1, 5, 4, 1, 1, 3, 4, 4, 4, 0, 5, 6, 4, 2, 2, 0, 6, 2, 2, 5, 3]\n",
      "[0, 0, 2, 4, 6, 3, 0, 3, 0, 0, 1, 6, 3, 2, 2, 1]\n",
      "[0, 4, 2, 4, 3, 2, 1]\n",
      "[0, 4, 3, 1, 2, 5, 0, 1, 2, 3, 3, 4, 1, 2, 1, 0, 4, 0, 2, 6, 0, 3, 2, 3, 5, 5, 6, 1, 5, 1, 6, 5, 6, 2, 6]\n",
      "[5, 0, 0, 3, 2, 2, 3, 3, 4, 5, 1, 2, 3, 3, 6, 0, 4, 4, 4, 2, 4, 3, 6, 1, 5, 1]\n",
      "[3, 4, 3, 3, 6, 2, 5, 0, 5, 4, 3, 1, 4]\n",
      "[3, 6, 1, 4, 5, 1, 0, 1, 6, 3, 3, 2, 2, 1, 0, 2]\n",
      "[4, 1, 0, 2, 1, 1, 4, 4, 1, 1, 2, 6, 6, 3, 4, 4, 3]\n",
      "[4, 6, 6, 4, 4, 4, 5, 6, 6, 0, 4, 4, 1, 6, 2, 3, 2, 2, 1, 3, 0, 2, 2, 3, 5, 3]\n",
      "[3, 1, 4, 1, 4, 0, 6, 5, 4, 5, 4]\n",
      "[0, 3, 3, 5, 4, 2, 4, 2, 1, 0, 2, 6, 0, 3, 1, 3, 2, 6, 1, 1, 2, 4, 2]\n",
      "[2, 5, 6, 0, 3, 0, 2, 6, 2, 4, 6, 6, 2]\n",
      "[5, 6, 2, 1, 0, 1, 1, 1, 3, 4, 3, 6, 1, 0, 1, 4, 2, 5, 3, 2, 3]\n",
      "[4, 5, 5, 1, 2, 2, 4, 5, 2, 6, 4, 4, 6, 0, 2, 4, 6, 1, 1, 2, 5, 2, 1, 0, 3, 3]\n",
      "[2, 0, 5, 2, 4, 5, 4, 0, 4, 3, 1, 4, 2, 2, 5, 0, 3, 5, 0, 3, 4, 1, 1, 1, 3, 4, 1, 5]\n",
      "[5, 4, 6, 1, 1, 5, 2, 0, 2, 5, 0, 0, 3, 3, 5, 4, 6, 0, 1, 3, 3, 2, 4, 3, 4, 6, 2]\n",
      "[2, 4, 6, 2, 4, 4, 3, 6, 4, 2, 1, 2, 0]\n",
      "[0, 6, 1, 4, 3, 2, 0, 3, 1, 0, 5, 1, 2, 3, 3, 2]\n",
      "[2, 2, 2, 1, 1, 0, 1, 0, 4, 0, 4, 0]\n",
      "[0, 2, 0, 5, 3, 3, 1, 1, 0, 0, 3, 3, 5, 4, 2, 0, 1, 4, 4, 4, 2]\n",
      "[3, 6, 5, 4, 0, 1, 3, 1, 3, 3, 2, 5, 5, 5, 5, 5, 0, 6, 1, 1, 3, 2, 6, 0, 0, 0, 6, 4, 4]\n",
      "[6, 2, 6, 1, 1, 0, 2, 3]\n",
      "[4, 5, 3, 5, 1, 5, 5, 2, 2, 5, 3, 1, 1, 6, 4, 1, 3, 3, 1, 4]\n",
      "[4, 6, 2, 0, 5, 3, 4, 3, 2, 6, 6, 6, 2, 2, 2, 0, 2, 6, 6, 0, 4, 3, 3, 4, 5]\n",
      "[4, 1, 1, 6, 0, 0, 5, 0, 6, 2, 4, 6, 0, 1, 1, 5, 4, 0, 4]\n",
      "[2, 5, 3, 5, 1, 0, 4]\n",
      "[0, 6, 6, 3, 2, 2, 2, 2, 0, 6, 1, 0, 3, 6, 6, 3, 2, 5, 6, 3, 5, 3, 0, 5, 3, 0, 1, 5, 5, 1, 1, 4]\n",
      "[3, 0, 0, 4, 1, 1, 1, 6, 1, 0, 3, 1, 3, 6, 1, 3, 4, 0, 6, 2, 4, 4, 5, 4, 5, 5, 2]\n",
      "[5, 2, 5, 2, 6, 4, 2, 0, 5, 5, 4, 6, 0, 6, 6, 1, 3]\n",
      "[2, 5, 0, 5, 1, 1, 3]\n",
      "[3, 5, 0, 1, 6, 4, 2, 3, 2, 1, 2, 2, 4, 3, 4, 3, 5, 3]\n",
      "[1, 0, 0, 2, 2, 3, 0, 5, 4, 1, 5, 0, 4, 3, 4, 4, 0, 0, 4, 2, 6, 5, 1, 1, 2, 4, 6, 1, 3, 3]\n",
      "[5, 4, 2, 0, 0, 5, 6, 2, 2, 5, 0, 0, 5, 0, 5, 1, 0, 3, 2, 3, 5, 3, 3, 6, 3, 4]\n",
      "[2, 4, 2, 5, 0, 4, 1, 3, 6, 6, 3, 2, 4, 4, 1, 4, 0]\n",
      "[2, 4, 6, 3, 6, 5, 0, 3, 1, 0, 0, 2, 6, 5, 6]\n",
      "[4, 0, 4, 1, 1, 4, 6, 3, 0, 6, 3, 2]\n",
      "[0, 2, 6, 6, 0, 4, 2, 3, 4, 5]\n",
      "[1, 0, 6, 6, 0, 4, 5, 5, 5, 0, 5, 4, 0, 5, 2, 6, 1, 2, 2, 0, 2, 2, 0, 5, 6, 4, 6, 1, 1, 6, 4, 4, 3, 3]\n",
      "[3, 1, 4, 4, 6, 4, 4, 5, 6, 0, 5, 0, 4, 1, 0, 1, 2, 1]\n",
      "[4, 2, 5, 3, 3, 4, 3, 5, 0, 0, 6, 2, 2, 5, 4, 4, 3, 6, 3]\n",
      "[3, 0, 4, 4, 4, 1, 2, 0, 5]\n",
      "[3, 3, 3, 6, 1, 6, 0, 2, 6, 2, 6, 4, 1, 4, 1, 1, 6, 6, 4, 2]\n",
      "[0, 6, 4, 3, 4, 5, 2, 2, 3, 3, 2, 3, 6, 5, 4, 4, 0, 1]\n",
      "[5, 4, 3, 5, 3, 2, 0, 3, 0, 2, 2, 4, 4, 4, 3, 5, 2, 4, 5, 0, 6, 3, 5, 1]\n",
      "[4, 6, 6, 3, 2, 3, 2, 3, 6, 3]\n",
      "[5, 1, 2, 1, 1, 4, 1, 1, 6, 0, 0, 0, 2, 5, 4, 5, 5, 5, 0, 0, 3]\n",
      "[3, 6, 0, 1, 4, 4, 5, 3, 5, 2, 4, 0, 6, 6, 6, 1, 5, 3, 5]\n",
      "[1, 0, 5, 4, 1, 1, 1, 4, 3, 3, 4, 5, 0, 5, 6, 5, 6, 5]\n",
      "[0, 6, 5, 6, 5, 4, 5, 5, 3, 2, 2, 3, 4, 4]\n",
      "[1, 4, 1, 1, 0, 5, 3, 4, 2]\n",
      "[6, 3, 3, 3, 0, 6, 3, 2, 2, 0, 2, 5, 2, 2, 0, 0, 2, 4]\n",
      "[0, 4, 3, 3, 4, 0, 5, 6, 4, 3, 3, 4, 3, 1, 0, 4, 6, 3, 5, 0, 5, 5, 5, 0, 4, 0, 2, 1, 1, 5, 1, 2]\n",
      "[2, 5, 3, 1, 0, 0, 3, 3, 5, 1, 1, 6, 4, 3, 6, 4, 3, 0, 0, 2, 0, 6, 1, 3, 4, 2, 0, 2]\n",
      "[1, 3, 3, 3, 1, 0, 3, 6, 0, 5, 0, 4]\n",
      "[4, 6, 0, 3, 1, 3, 4, 6, 3, 4, 6, 3, 0, 5, 0, 0, 4, 5]\n",
      "[4, 5, 4, 1, 1, 4, 2, 4, 2, 1, 3, 5, 6, 0, 3]\n",
      "[1, 0, 0, 0, 1, 4, 5, 2, 4, 5, 6, 1, 5, 2, 2, 2, 0, 0, 0, 4, 2, 1, 5, 4, 1, 6, 6, 3, 1, 6, 5, 5, 3, 2, 3, 6, 6, 3]\n",
      "[1, 0, 6, 0, 2, 3, 5, 2, 0, 6, 2, 1, 4, 3]\n",
      "[5, 2, 5, 0, 5, 5, 3, 1, 5, 4, 2, 1, 5, 2, 1, 0, 3, 4, 6, 1, 2, 0, 1, 2, 4, 0]\n",
      "[5, 4, 5, 6, 4, 4, 2, 1, 4, 1, 4, 4, 1, 5, 5, 5, 5, 0, 0, 0, 6, 1, 6, 1, 6, 6, 2, 0, 1, 3, 3]\n",
      "[5, 2, 6, 3, 5, 1, 5, 5, 4, 0]\n",
      "[4, 4, 1, 3, 4, 0, 4, 3, 2, 3, 5, 4, 3, 5, 0, 2]\n",
      "[3, 0, 0, 3, 1, 6, 3, 5, 4, 2, 0, 3, 0, 0, 3, 4, 6, 1, 2, 1, 0, 2]\n",
      "[4, 6, 5, 5, 6, 1, 3, 2, 1, 5, 4, 6, 4, 2, 6, 6, 2, 5, 4]\n",
      "[3, 3, 1, 0, 2, 4, 3, 1, 2, 4, 0, 1, 4, 4, 6, 2, 3, 1]\n",
      "[3, 6, 2, 3, 2, 1, 0, 4, 3, 5, 2, 4, 0, 0, 2]\n",
      "[4, 2, 5, 0, 3, 6, 3, 1, 3, 1, 3]\n",
      "[6, 4, 5, 4, 2, 3, 3, 6, 5, 2, 4, 4, 5, 5, 2, 5, 3]\n",
      "[2, 0, 1, 0, 1, 2, 0, 1, 0, 3, 6, 1, 0, 3, 0]\n",
      "[3, 4, 3, 4, 3, 3, 4, 6, 3, 1, 5, 3, 6, 2, 6, 1, 2, 1, 6, 6, 5, 5, 2, 1]\n",
      "[1, 4, 6, 6, 2, 4, 0, 3, 1, 3, 0, 3, 5, 2, 3, 2, 6, 0, 0, 0, 4, 5]\n",
      "[3, 3, 3, 3, 2, 0, 5, 4, 2, 1, 0, 5, 0, 2, 6, 3, 2, 4, 0, 0, 6, 1]\n",
      "[1, 2, 3, 6, 1, 4, 5, 4, 6, 3, 6, 3, 3, 4, 2, 0, 6, 5, 6]\n",
      "[0, 3, 3, 1, 5, 0, 6, 3, 1, 6, 4, 0, 2, 5, 1, 4, 1, 1, 0, 5, 2, 4, 2]\n",
      "[6, 1, 1, 2, 0, 0, 1, 3, 1, 4]\n",
      "[3, 1, 3, 3, 4, 5, 3, 4, 2, 3, 0, 6, 1, 4, 5, 6, 0, 2, 2]\n",
      "[5, 4, 2, 6, 1, 4, 6, 6, 2, 4, 3, 5, 0]\n",
      "[4, 3, 4, 4, 1, 2, 1, 1, 4, 0, 2, 3, 3]\n",
      "[4, 2, 0, 6, 6, 4, 4, 2, 2, 6, 0, 0, 1, 5, 4, 6, 2, 2, 0, 1, 4, 4, 0, 6, 3, 1, 5, 3]\n",
      "[6, 6, 1, 5, 1, 1, 3, 0, 3, 3, 2, 5, 4]\n",
      "[0, 1, 4, 5, 0, 3, 4, 5, 6, 1, 3, 0, 5, 1, 5, 1]\n",
      "[6, 6, 3, 4, 5, 4, 6, 3, 4, 3, 6, 5]\n",
      "[2, 6, 3, 1, 4, 6, 5]\n",
      "[4, 4, 0, 2, 1, 2, 6, 2, 3, 5, 3, 2]\n",
      "[3, 3, 1, 2, 4, 2, 1, 1, 2, 1, 2, 3, 6, 5, 0, 3, 6, 3]\n",
      "[1, 6, 1, 0, 3, 0, 4, 3, 2]\n",
      "[5, 6, 2, 1, 2, 1, 2, 1, 2]\n",
      "[2, 2, 5, 4, 4, 1, 3, 1, 0, 1, 1, 3, 5, 2, 3, 2, 2, 0]\n",
      "[4, 1, 3, 2, 0, 1, 1, 6, 3, 6, 2, 2, 0, 4, 6, 4, 3, 0, 3]\n",
      "[0, 0, 0, 4, 1, 4, 4, 3, 3, 4, 4, 4, 0, 3, 2, 3, 6, 2, 3, 5, 1, 3, 6, 1, 5, 2, 5, 2]\n",
      "[1, 3, 2, 0, 6, 5, 2, 3, 2, 3, 5, 2, 3, 6, 6, 2, 5, 3, 0, 5, 5, 6, 2, 1, 1, 3, 0, 1, 4, 4]\n",
      "[2, 5, 3, 1, 0, 3, 0, 6, 2, 5, 5, 3, 0, 3, 0]\n",
      "[3, 2, 6, 1, 5, 4, 4, 0, 3, 4, 2, 1, 1, 4, 2, 5, 5, 2, 3, 1, 3]\n",
      "[3, 4, 0, 6, 1, 5, 2]\n",
      "[6, 2, 2, 6, 3, 0, 5, 2, 6, 0, 4]\n",
      "[2, 4, 3, 4, 1, 2, 0]\n",
      "[3, 0, 0, 3, 6, 5, 3, 0, 6, 2, 0, 3, 1, 0, 3, 2, 4, 3, 0, 1, 5, 2]\n",
      "[4, 1, 6, 2, 6, 0, 3, 2, 5]\n",
      "[3, 4, 6, 6, 5, 3, 5, 3, 3, 0, 2, 2, 5, 3, 3, 5, 6, 2, 2, 6, 4, 4, 0, 6]\n",
      "[2, 6, 2, 3, 6, 5, 4, 4, 4, 2, 6, 6, 6, 6, 4, 4, 1, 0, 4, 2, 1, 1, 5, 0, 1, 3, 3]\n",
      "[0, 4, 0, 1, 3, 4, 1, 3, 0, 0, 3, 4, 6, 0, 2, 4]\n",
      "[2, 4, 3, 6, 4, 6, 2, 4, 1, 5, 0]\n",
      "[4, 2, 3, 4, 5, 6, 5, 6, 5, 5, 3, 4, 4, 6, 1, 6]\n",
      "[0, 3, 6, 6, 4, 5, 5, 1, 0, 5, 4, 1, 4, 6, 4]\n",
      "[1, 3, 1, 3, 1, 5, 1]\n",
      "[4, 4, 5, 5, 1, 1, 0, 3, 5, 3, 5, 5, 1, 0, 5, 2, 4, 2]\n",
      "[6, 2, 1, 2, 6, 6, 2, 5, 0, 4, 3, 1, 2, 1, 0, 6, 3, 5, 5, 0, 1, 3, 0, 0, 3]\n",
      "[3, 2, 6, 3, 1, 4, 5, 6, 4, 6, 2, 1, 2, 0, 4, 2, 2, 5, 0, 3, 1, 0, 0]\n",
      "[0, 5, 1, 0, 2, 4, 3]\n",
      "[2, 6, 2, 0, 3, 3, 5, 1, 0, 6, 4]\n",
      "[2, 1, 0, 1, 2, 6, 0, 6, 0, 5, 0]\n",
      "[0, 2, 0, 0, 2, 5, 1, 5, 3, 2, 1, 3, 2, 4, 3, 0, 5, 2, 0, 6, 4, 5, 3, 4]\n",
      "[5, 0, 5, 3, 5, 5, 3, 4, 0, 5, 2, 4, 4, 5, 0, 1, 4, 1, 0, 2, 4, 4, 6, 3, 0]\n",
      "[2, 4, 4, 1, 6, 3, 3, 6, 2, 2, 1]\n",
      "[3, 1, 2, 5, 4, 3, 3, 6, 3, 2, 3, 4, 2, 3, 1, 0, 4, 1, 2, 1, 1, 0, 5, 2, 0, 4, 5]\n",
      "[0, 5, 2, 5, 2, 0, 2, 6, 2]\n",
      "[3, 6, 6, 1, 2, 1, 2, 2, 2, 1, 6, 1]\n",
      "[5, 3, 0, 3, 3, 5, 5, 0, 0, 4, 0, 1, 0, 0, 5, 2]\n",
      "[1, 4, 4, 0, 2, 5, 2, 3, 6, 3, 5, 0, 5, 1, 3, 3, 0, 2]\n",
      "[5, 1, 1, 2, 4, 3, 2, 6, 6, 0]\n",
      "[4, 4, 2, 0, 3, 1, 5]\n",
      "[0, 1, 4, 2, 0, 3, 4, 4, 6, 5, 3, 3, 2, 2, 1]\n",
      "[0, 2, 3, 1, 3, 1, 5, 4, 5, 2, 3, 2, 3]\n",
      "[1, 5, 6, 6, 5, 5, 2, 1, 2, 6, 4, 1, 3]\n",
      "[3, 4, 1, 5, 3, 0, 5, 4, 0, 2, 3, 3, 0, 5, 3, 6, 3, 1, 0, 4, 0]\n",
      "[4, 5, 3, 0, 1, 2, 4, 0, 4, 5, 3, 4, 1, 2, 1, 1, 6, 3, 6, 3, 1, 2, 2, 5, 0, 2, 2, 0, 3, 0, 5, 3, 0, 5]\n",
      "[3, 5, 5, 0, 3, 4, 4, 6, 6]\n",
      "[6, 3, 1, 5, 6, 2, 5, 4]\n",
      "[0, 3, 0, 3, 3, 4, 5, 3, 4, 3, 0, 0, 0, 6, 2, 1, 3, 5, 1, 6, 1, 4]\n",
      "[2, 5, 6, 3, 3, 4, 4, 0, 0, 4, 0, 1, 6, 4, 5]\n",
      "[3, 5, 6, 4, 3, 1, 0, 0, 3, 4, 4, 1, 3]\n",
      "[5, 5, 5, 1, 0, 1, 4, 3, 2, 4, 4, 3, 3, 2]\n",
      "[6, 0, 1, 6, 6, 1, 6, 2, 1, 2, 1, 1, 6, 3, 6]\n",
      "[3, 5, 1, 1, 0, 2, 4, 3, 2, 2, 4, 0, 1, 1, 4, 3, 4]\n",
      "[0, 5, 4, 0, 0, 1, 4, 5, 4, 4, 5, 5, 1, 3, 3, 1, 2, 0, 2]\n",
      "[1, 4, 0, 3, 6, 2, 0, 5]\n",
      "[1, 2, 4, 5, 0, 6, 4, 6, 4, 4, 3, 4, 0, 1, 5, 5, 0, 0, 1, 5, 5, 1, 1, 2, 6, 2, 0, 2]\n",
      "[2, 5, 0, 3, 0, 4, 4, 6]\n",
      "[3, 5, 2, 5, 1, 2, 2, 3, 0]\n",
      "[6, 2, 0, 3, 2, 5, 3, 4]\n",
      "[2, 2, 0, 6, 0, 6, 4, 3, 2, 4, 6, 5, 3, 2, 3, 4, 6, 6, 2, 2, 4, 4, 6, 5, 4, 3]\n",
      "[1, 1, 0, 3, 1, 2, 1, 5, 5, 5, 5, 4]\n",
      "[2, 4, 3, 2, 3, 1, 2, 4, 4, 1, 3, 1, 3]\n",
      "[3, 5, 1, 0, 2, 5, 4]\n",
      "[5, 6, 5, 3, 2, 1, 6, 6, 4, 1, 4, 2, 4, 4, 3]\n",
      "[4, 6, 3, 2, 5, 1, 5, 4, 4, 5, 4, 3, 3, 0, 3, 6, 4, 4, 1, 5, 0, 6, 0, 6]\n",
      "[4, 5, 5, 1, 0, 5, 6, 5, 6, 4, 1, 1, 2, 2, 1, 1, 2, 6, 5, 4, 6, 4, 1, 2, 3, 4]\n",
      "[0, 6, 5, 6, 6, 2, 0, 1, 4, 0, 2, 1, 5, 1, 3, 1]\n",
      "[3, 5, 2, 2, 3, 6, 4, 3, 5, 1, 5, 2, 0, 4, 6, 1, 0, 0, 0, 5, 2, 6, 3, 2, 0, 1]\n",
      "[3, 3, 3, 4, 4, 3, 3, 1, 1, 2, 4, 2, 4, 4, 6, 2, 0, 1, 6, 3, 2, 5, 4, 2, 2, 1]\n",
      "[6, 1, 5, 3, 4, 2, 0, 3, 3, 2, 5, 4, 1, 1, 4, 3, 0, 2, 4, 3, 2, 1, 1, 5, 2, 4, 6, 2, 1, 6, 0, 6]\n",
      "[2, 1, 3, 1, 5, 3, 5, 3, 4]\n",
      "[1, 3, 6, 2, 2, 2, 3, 1, 6, 4, 3, 2, 5, 6, 0, 5, 1, 2, 0, 0, 3, 1, 3]\n",
      "[4, 3, 2, 0, 3, 0, 4, 4, 2, 3, 5, 1, 1]\n",
      "[4, 6, 3, 5, 6, 0, 0, 6, 4, 2, 4, 1, 1, 1, 2, 6, 5, 4, 2, 1, 2, 3, 0, 2, 3, 5, 3, 1, 5, 4, 5, 6, 6, 4, 5, 3]\n",
      "[0, 0, 2, 5, 5, 1, 0, 5, 3, 2, 2, 4, 0, 1, 1, 4, 4, 3]\n",
      "[2, 3, 6, 5, 5, 3, 1, 1, 6, 3, 3, 3, 2, 4, 4, 6, 6, 5, 0, 4]\n",
      "[0, 5, 1, 0, 2, 3, 6, 2, 1, 1, 0, 2, 5, 2, 6, 2]\n",
      "[6, 6, 4, 1, 4, 2, 2, 5, 6, 4, 5, 5, 6, 5, 1, 1, 0, 1, 5, 5, 2, 0, 2, 1, 2]\n",
      "[2, 2, 6, 3, 2, 0, 6, 3, 2, 2, 0, 5, 0, 5, 5, 6, 0, 0, 3, 2, 6, 5, 4, 4]\n",
      "[4, 6, 6, 5, 4, 5, 5, 1, 2, 3, 2, 1, 0, 2, 2, 6, 4, 4, 6, 5, 3, 0, 3, 4, 3, 4, 3]\n",
      "[2, 0, 6, 4, 5, 2, 5, 0, 3, 0, 0, 3, 3, 5, 3, 1, 1, 1, 1, 2, 2]\n",
      "[0, 5, 3, 4, 1, 5, 2]\n",
      "[0, 1, 3, 6, 2, 4, 5, 0, 1, 3, 3, 0, 5, 5, 5, 5, 0, 5, 4, 6, 3, 3, 4, 4]\n",
      "[5, 6, 3, 3, 1, 2, 5, 2, 0, 1, 6, 0]\n",
      "[2, 2, 0, 0, 3, 4, 1]\n",
      "[5, 0, 6, 2, 6, 1, 1, 3]\n",
      "[0, 1, 1, 1, 5, 5, 3, 5, 3, 5, 4, 2, 6]\n",
      "[3, 5, 6, 3, 4, 2, 3, 5, 0, 1, 5, 1, 2, 2, 1, 0, 1, 5, 0, 2, 0]\n",
      "[5, 4, 3, 3, 0, 6, 1, 3, 2]\n",
      "[4, 1, 3, 2, 3, 0, 6, 6, 2, 6, 5]\n",
      "[2, 2, 2, 3, 2, 4, 6, 4, 0, 2, 2, 0, 1, 4, 6, 4]\n",
      "[5, 3, 4, 0, 3, 2, 1, 2, 4, 6, 0, 1, 4, 0, 4]\n",
      "[2, 3, 3, 3, 2, 1, 2, 0, 1, 2, 6, 0, 2, 6, 2, 5, 4, 4]\n",
      "[4, 0, 5, 4, 0, 5, 4, 4, 1, 4, 0, 0, 2, 2, 3]\n",
      "[6, 5, 1, 2, 0, 5, 4, 5, 6, 5]\n",
      "[6, 4, 6, 1, 6, 3, 2, 6, 2, 6, 2, 4, 2]\n",
      "[3, 5, 2, 2, 5, 3, 2, 5, 1, 6, 5, 4, 0]\n",
      "[4, 2, 2, 2, 5, 0, 2, 3, 1, 4, 5, 6, 6, 1, 2, 5, 1, 2, 4, 1, 0, 4, 0, 3, 5, 0, 3, 3]\n",
      "[1, 2, 3, 5, 3, 3, 6, 6, 4, 2, 2, 4, 3, 0, 0, 4, 4, 2]\n",
      "[1, 4, 3, 2, 1, 5, 1, 2, 1]\n",
      "[0, 6, 5, 2, 3, 0, 0, 4, 2, 5, 3, 3, 4, 0, 5, 3, 2, 3, 4, 2, 5, 5, 6, 5, 1, 1, 1, 3]\n",
      "[2, 1, 1, 2, 5, 0, 3, 5, 4]\n",
      "[3, 6, 6, 6, 4, 6, 2, 5, 6, 4, 6, 1, 0, 3, 1, 5, 5, 2]\n",
      "[6, 3, 6, 3, 2, 0, 2, 3, 5, 3]\n",
      "[4, 2, 2, 5, 2, 3, 3, 3, 4, 5, 4, 4, 2, 1, 1]\n",
      "[2, 1, 2, 5, 2, 1, 2]\n",
      "[2, 4, 2, 0, 3, 6, 4, 2, 5, 3, 1, 4, 5, 4, 2, 2, 5, 3, 5]\n",
      "[5, 0, 6, 1, 0, 2, 1, 1, 3, 2, 4]\n",
      "[4, 4, 1, 2, 0, 3, 3, 0, 4, 5, 6, 0, 3, 2, 6, 2, 2, 6, 0, 1, 1, 5, 5, 3, 5, 0, 4, 4]\n",
      "[6, 4, 3, 2, 6, 2, 4, 4, 4, 4, 4, 1, 0, 3, 5, 0, 1, 2, 3, 6, 2]\n",
      "[1, 5, 1, 2, 4, 5, 5, 4, 6, 4, 0, 1, 2, 2, 0, 4, 6, 4]\n",
      "[1, 2, 4, 6, 2, 1, 6, 6, 6, 6, 1, 2, 2, 6, 5, 0, 3, 2, 2, 1, 3, 0, 5, 1, 4]\n",
      "[2, 3, 0, 3, 5, 6, 3, 3, 0, 5, 0, 0, 5, 1, 3, 3, 1, 2, 0, 0, 1, 4, 6, 2, 2]\n",
      "[6, 3, 6, 3, 4, 4, 5, 4, 3, 1, 5, 4, 1, 5, 3, 4]\n",
      "[3, 0, 0, 5, 5, 2, 0, 5, 3, 4, 2, 6, 5, 4, 0, 0, 6, 0, 4, 5, 1, 4, 1]\n",
      "[2, 1, 5, 4, 1, 4, 5, 5, 4, 5, 6, 1, 4, 3, 0, 0, 3, 4, 3, 3, 5, 1, 1, 4, 2]\n",
      "[3, 4, 4, 4, 5, 1, 2, 0, 3, 5, 4, 5, 2, 1, 3, 1, 3]\n",
      "[0, 5, 1, 0, 1, 3, 4, 1, 2, 1, 0, 1, 0, 0, 3, 1]\n",
      "[0, 4, 0, 1, 5, 3, 0, 0, 6, 5, 4, 2]\n",
      "[4, 4, 6, 0, 2, 3, 4, 0, 1, 2, 4, 5, 3, 0, 5, 0]\n",
      "[0, 4, 6, 0, 4, 4, 5, 2, 2, 4, 4, 2, 2, 3, 0, 1]\n",
      "[2, 0, 3, 4, 2, 5, 3, 2, 5, 0, 5, 3, 5, 5, 4]\n",
      "[0, 4, 6, 0, 4, 6, 3, 5, 2, 2, 5, 1, 0, 4, 2, 2, 5, 4, 5, 5, 4, 3, 0, 1]\n",
      "[1, 4, 3, 0, 5, 5, 5, 6, 4, 5, 0, 4, 3, 2, 2, 6, 4, 3, 2, 1, 5, 3]\n",
      "[3, 0, 0, 6, 2, 4, 6, 5, 4, 5, 6, 1, 4, 1, 4, 0, 0, 4, 1, 2, 6, 2, 5]\n",
      "[3, 3, 2, 1, 4, 5, 0, 1, 5, 2, 4, 0]\n",
      "[1, 0, 4, 5, 2, 0, 2, 3, 5, 6, 3, 4, 1, 1, 1, 2, 4, 2, 5, 5, 6, 0, 4, 3]\n",
      "[4, 5, 5, 6, 1, 0, 5, 5, 0, 6, 4, 6, 4, 4, 0, 6]\n",
      "[2, 2, 2, 2, 0, 5, 0, 1, 4, 2, 4, 6, 1, 5, 1, 5, 5, 2, 0, 0, 4, 4, 0, 5, 5, 6, 0, 1, 4, 4, 3, 1, 3]\n",
      "[4, 2, 3, 4, 4, 2, 2, 6, 3, 3, 0, 0, 2, 0, 0, 1, 2, 2, 5, 4]\n",
      "[3, 1, 6, 5, 3, 5, 5, 6, 1, 5, 2, 4, 4, 1, 4, 2, 6, 3, 6]\n",
      "[5, 6, 4, 3, 4, 4, 6, 1, 1, 6, 0, 0, 3, 5, 4, 4, 2, 1, 4, 2, 6, 2, 1, 2, 3, 3]\n",
      "[6, 6, 5, 6, 1, 6, 6, 4, 2, 6, 5, 3, 5, 5, 5, 2, 5, 3, 4, 2, 4, 2, 0, 2]\n",
      "[3, 1, 3, 0, 2, 0, 3, 3, 0, 0, 1, 5, 2, 3, 5, 2, 2, 1, 6, 1, 5, 3, 1, 1, 0, 0, 2, 2]\n",
      "[0, 0, 4, 2, 6, 4, 0, 2, 3, 5, 1, 2, 2, 3, 3, 3, 3, 4, 5, 3, 1, 5, 4, 5]\n",
      "[4, 6, 0, 6, 2, 3, 3, 6, 6, 4, 4, 5, 0, 1, 3, 0, 1, 4, 2]\n",
      "[5, 2, 1, 0, 3, 1, 4, 6, 5, 3, 0, 3, 3, 1, 0, 5, 4, 0, 4, 4, 0, 0, 2, 2, 2, 2, 6, 3, 2, 3, 6, 4, 1, 5, 4, 5]\n",
      "[3, 3, 5, 5, 3, 3, 2, 2, 2, 3, 4]\n",
      "[3, 4, 5, 3, 0, 4, 2, 1, 4, 2, 4, 4, 1, 5]\n",
      "[6, 2, 0, 4, 1, 5, 0, 3]\n",
      "[1, 2, 5, 5, 3, 6, 4, 2, 2, 0, 1, 6, 0, 4, 2, 3]\n",
      "[0, 0, 0, 3, 0, 4, 3, 1, 0, 0, 2, 5, 3, 6]\n",
      "[6, 3, 2, 6, 4, 6, 6, 5, 0, 1, 1, 4, 4, 1, 2, 3, 0, 4, 6, 5]\n",
      "[2, 6, 3, 0, 4, 3, 1]\n",
      "[5, 1, 2, 1, 1, 4, 5, 3, 5, 5, 1, 6, 3, 1, 3, 4, 4, 6, 4, 4, 1, 5, 2, 3, 5, 2]\n",
      "[2, 1, 4, 0, 3, 5, 4, 0, 3, 6, 1, 2, 6, 1, 4, 5, 1, 4, 5, 2, 1, 5, 2, 3]\n",
      "[0, 1, 6, 4, 4, 1, 3, 2, 5, 2, 0, 3, 4, 5, 6, 5, 5, 5, 6, 6, 3, 2, 5, 2]\n",
      "[5, 4, 6, 2, 0, 3, 1, 1, 6, 0, 0, 0, 3, 2, 6, 1]\n",
      "[2, 2, 5, 5, 0, 1, 2, 4, 1, 4, 2, 1, 5, 2, 3, 3]\n",
      "[1, 4, 4, 2, 4, 5, 3, 0, 4, 6, 4]\n",
      "[2, 6, 4, 0, 1, 6, 3]\n",
      "[1, 2, 1, 2, 1, 1, 2, 5, 6, 4, 0, 3]\n",
      "[6, 3, 0, 0, 6, 3, 3, 6, 5, 3, 4, 2, 6, 3, 2, 1, 2, 2, 6, 6, 0, 3, 2, 0, 5, 4, 4, 5, 4, 5, 1, 1]\n",
      "[2, 4, 1, 6, 4, 5, 3, 6, 4, 4, 4, 0, 3, 4, 5, 3, 5, 2, 6, 6, 5]\n",
      "[1, 0, 2, 4, 6, 5, 3, 0, 0, 1, 2, 0, 2, 5, 2]\n",
      "[6, 0, 4, 4, 5, 3, 3, 3, 1, 6, 3, 3, 0, 5, 1, 1, 3, 1, 6, 0, 0, 0, 4, 4, 1, 1, 2, 5]\n",
      "[0, 4, 5, 1, 3, 1, 0, 3, 0, 3, 0]\n",
      "[1, 4, 1, 6, 6, 4, 3, 2, 3, 4, 6, 2, 5, 4]\n",
      "[3, 2, 4, 1, 3, 0, 4, 2, 1, 0, 6, 4, 5]\n",
      "[2, 2, 2, 5, 5, 3, 5, 5, 0, 4, 3, 3, 6, 2, 5, 0, 0, 6, 6, 2, 5, 4]\n",
      "[3, 4, 4, 1, 6, 1, 6, 4, 4, 3, 0, 6, 2, 0, 3, 2]\n",
      "[0, 5, 2, 4, 4, 0, 3, 1, 5, 6, 3, 2, 1, 6, 2, 5, 3, 3, 4, 1, 6, 5, 4, 2, 4]\n",
      "[4, 6, 2, 3, 3, 2, 1, 3, 2, 3, 0, 1, 6, 0, 4, 3, 6, 3]\n",
      "[2, 5, 5, 2, 6, 5, 3, 1, 3, 5, 4, 2, 0, 3, 6, 4, 1, 3, 5, 1, 6, 6, 6, 6, 4, 0, 0, 5, 4, 0, 1, 4]\n",
      "[3, 3, 5, 2, 2, 6, 3, 4, 3, 1, 4, 3, 5, 2, 4, 2, 1, 2, 4, 4, 5, 5, 1, 5]\n",
      "[5, 6, 4, 3, 6, 3, 4, 2, 0, 4, 4, 1, 3, 0, 6, 3, 5, 2, 1, 1, 4, 3, 2, 2]\n",
      "[3, 1, 5, 4, 6, 6, 5, 1, 0, 3, 3, 0, 2, 0, 5, 5, 4, 2]\n",
      "[0, 3, 0, 0, 0, 5, 2, 6, 2, 0, 2, 2, 4, 1, 3, 3, 6, 1, 4, 0, 5]\n",
      "[0, 1, 1, 2, 2, 0, 3, 6, 4, 3, 4, 3, 3, 0, 2]\n",
      "[3, 2, 1, 4, 0, 1, 5, 3, 1, 1, 4, 3, 4, 6, 0, 3, 2, 0, 0]\n",
      "[5, 5, 3, 5, 4, 5, 0, 2, 6]\n",
      "[0, 3, 0, 4, 2, 0, 4, 0, 5, 4, 5, 0, 4, 5, 3, 6, 6]\n",
      "[1, 3, 4, 4, 2, 3, 2, 0, 4, 2, 2, 6, 0, 2, 0, 4, 5, 0, 3, 3, 4, 0, 6, 1]\n",
      "[3, 2, 3, 4, 3, 4, 3]\n",
      "[2, 4, 4, 5, 5, 5, 4, 1, 3, 6, 6, 6, 3]\n",
      "[0, 1, 3, 1, 6, 6, 5, 4, 2, 4, 4, 5, 3, 3, 3, 2, 5, 5, 5, 0, 3, 4]\n",
      "[5, 6, 5, 3, 6, 6, 4, 6, 0, 6, 4, 3, 2, 5, 4, 2, 4]\n",
      "[3, 3, 3, 5, 5, 1, 6, 2, 4, 6, 2, 3, 2, 3, 3, 2, 2, 6, 6, 5, 0, 4, 6, 5, 0, 5, 1, 5]\n",
      "[3, 0, 3, 6, 6, 4, 2, 6, 4, 1, 3, 6, 1, 1, 3]\n",
      "[6, 4, 5, 5, 3, 3, 4, 2, 3, 1, 3, 4, 6, 4, 0, 1, 1, 0, 3, 3, 2, 2, 2]\n",
      "[5, 4, 0, 0, 5, 0, 5, 0, 5]\n",
      "[1, 6, 6, 0, 3, 0, 2, 1, 4]\n",
      "[2, 3, 3, 5, 1, 4, 6, 6, 5, 6, 2, 4, 3, 2, 1, 5, 6, 1, 3, 5, 3]\n",
      "[1, 4, 1, 4, 4, 5, 3, 6, 0, 4, 2]\n",
      "[4, 3, 1, 3, 3, 5, 0, 4, 1, 0, 1, 1, 5, 4, 5, 5, 1, 5, 3, 6, 1, 2]\n",
      "[3, 6, 0, 5, 3, 2, 3, 1, 4, 6, 3]\n",
      "[6, 0, 5, 3, 6, 4, 2, 3, 0, 6, 4, 2, 3, 1, 2, 4, 2]\n",
      "[6, 5, 6, 0, 1, 0, 5, 0, 0, 4, 3, 0, 2, 4, 4, 1, 3, 1, 0, 4, 3, 3, 3, 3, 6, 5, 5]\n",
      "[2, 1, 4, 3, 3, 6, 2, 1, 4, 5, 2, 0, 2]\n",
      "[6, 5, 4, 6, 0, 2, 4, 3, 3, 2, 3, 1, 1, 0, 4, 0, 4]\n",
      "[4, 2, 5, 5, 6, 3, 3, 1, 1, 4, 0, 2, 6, 6, 0, 0, 3, 5, 3, 6]\n",
      "[2, 4, 4, 2, 3, 0, 5, 4, 5, 1, 4, 4, 2, 2, 3, 6, 6]\n",
      "[6, 0, 0, 3, 3, 6, 6, 6, 1, 1, 6, 1, 0, 2, 5, 6, 3, 2, 4, 2, 5, 2]\n",
      "[2, 4, 6, 2, 5, 0, 4, 1, 1, 1, 5, 5, 4, 1, 2, 2, 5, 0, 3, 3, 3, 4, 3]\n",
      "[1, 0, 2, 5, 4, 3, 1, 2, 3, 6, 2, 6, 0, 4, 1, 1, 3, 5, 4]\n",
      "[3, 4, 4, 0, 1, 1, 3, 6, 5, 1, 6, 5, 1, 6, 3, 3, 5, 6, 4, 6, 0, 4, 2, 5]\n",
      "[4, 6, 6, 0, 3, 6, 5, 1, 2]\n",
      "[3, 2, 2, 6, 6, 3, 2, 1, 6, 3, 1, 3, 3, 5, 5, 5, 0, 1, 2, 2, 3, 4, 1, 0, 6, 6, 0, 0, 4, 4, 6, 5]\n",
      "[1, 0, 3, 5, 1, 2, 1, 3, 1]\n",
      "[0, 5, 3, 5, 4, 6, 3, 0, 4, 0, 1, 2, 6, 0, 2, 1, 3, 1, 5, 1, 3]\n",
      "[0, 2, 3, 4, 0, 2, 1, 3, 2, 1, 4, 0, 5, 1, 2, 0, 3]\n",
      "[6, 6, 0, 3, 0, 3, 5, 0, 3, 3, 6, 4, 1, 4, 0, 4, 5, 1, 4, 2, 5, 2]\n",
      "[4, 3, 4, 1, 4, 4, 1, 2, 3, 2, 1, 6, 3, 0]\n",
      "[2, 6, 1, 1, 4, 3, 2, 5, 6, 3, 1, 2, 2, 2, 3, 0, 5, 3]\n",
      "[4, 1, 6, 1, 4, 6, 3, 3, 5]\n",
      "[3, 5, 5, 1, 0, 6, 1, 4, 0, 4, 4, 4, 2, 2, 4, 6, 5, 1, 6, 4, 0, 0, 0, 5, 5, 6, 3, 2, 3]\n",
      "[0, 0, 5, 3, 0, 5, 4, 5, 2, 0, 2, 0, 1, 2, 4, 5, 3, 5]\n",
      "[2, 1, 4, 3, 4, 3, 3, 0, 6, 4, 6, 1, 3, 0, 1, 2]\n",
      "[2, 4, 3, 4, 0, 1, 3, 3, 2, 2, 2, 0, 0, 5, 6, 1, 6, 2, 1, 0, 2, 6, 4, 3, 1, 3, 5, 3]\n",
      "[5, 5, 3, 0, 0, 2, 2, 0, 2, 2, 5, 6, 6, 5, 1, 2, 3, 1, 6, 4, 3, 0, 3]\n",
      "[6, 4, 3, 1, 4, 1, 3, 4, 4, 5, 5, 0, 2, 4, 2]\n",
      "[2, 0, 2, 4, 1, 2, 1, 4, 1, 1, 5, 4, 4, 4, 0, 1, 5, 1, 2, 2, 5, 5, 5, 6, 4, 5, 2, 0, 6, 6, 3, 3]\n",
      "[4, 1, 5, 6, 1, 4, 2, 3, 1, 5, 2, 4, 2, 5, 2]\n",
      "[2, 1, 5, 3, 4, 2, 3, 4, 4, 2, 3, 2, 2, 4, 5, 3, 5, 2, 5]\n",
      "[3, 5, 2, 1, 0, 3, 3, 2, 4, 4, 2, 4, 6, 4, 0, 5]\n",
      "[4, 3, 2, 5, 3, 4, 4, 0, 5, 1, 1, 3, 1, 0, 5, 5, 2, 5, 4, 6, 2, 2]\n",
      "[1, 1, 4, 3, 3, 3, 5, 6, 2, 4, 1, 0, 4, 0, 5, 1, 6, 4, 0, 0, 3, 5, 5]\n",
      "[3, 2, 3, 6, 0, 2, 1, 5, 5, 2, 0, 1, 4, 3, 2, 4, 5, 4, 5, 5, 2, 4]\n",
      "[3, 2, 3, 3, 2, 6, 6, 5, 4, 3, 4, 5, 2, 5, 2, 2, 2, 4]\n",
      "[2, 5, 3, 2, 0, 1, 4, 1, 5, 0, 2, 3]\n",
      "[1, 4, 2, 2, 0, 1, 3]\n",
      "[0, 6, 1, 1, 3, 2, 1, 0, 3, 1, 2, 1, 0, 0, 3, 5, 2]\n",
      "[5, 6, 3, 4, 5, 4, 2, 2, 2, 0, 3, 4, 1, 4]\n",
      "[2, 5, 1, 1, 2, 1, 1, 1, 1, 0, 5, 3, 2, 2, 4, 3, 4, 4, 3, 4, 0, 2, 3, 2, 6, 3, 6, 4]\n",
      "[2, 1, 2, 3, 2, 6, 2]\n",
      "[1, 0, 3, 2, 3, 1, 0, 4, 3, 3, 1, 6, 0, 3, 0, 2, 3, 1, 0]\n",
      "[4, 0, 6, 1, 0, 5, 3, 1, 1, 4, 1, 2, 3, 2, 2]\n",
      "[2, 4, 5, 4, 1, 4, 2, 4]\n",
      "[4, 0, 4, 0, 3, 2, 3, 2, 0, 1, 6, 5, 3, 3, 2, 2, 0, 1, 1]\n",
      "[6, 4, 5, 4, 3, 6, 6, 4, 4, 3, 3, 3, 3, 5]\n",
      "[3, 4, 3, 3, 5, 0, 2, 1, 4, 2, 5, 6, 6]\n",
      "[3, 5, 0, 5, 3, 5, 3, 3, 4, 1, 6, 1, 6, 5]\n",
      "[3, 6, 6, 2, 0, 3, 5, 3, 6, 4, 5, 6, 6, 1, 3, 5, 0, 2, 2, 1, 1, 4]\n",
      "[3, 5, 6, 2, 4, 2, 2, 1, 3, 4, 4, 0, 5, 4, 4, 3]\n",
      "[6, 0, 0, 5, 0, 2, 3, 2, 3, 5, 4, 1, 3, 5, 3]\n",
      "[0, 1, 3, 3, 5, 1, 1, 4, 6, 0, 6, 1, 3, 4, 0, 0, 0, 5, 3, 5, 3, 3, 4, 2, 2, 2]\n",
      "[5, 2, 3, 5, 3, 1, 2, 0, 5, 0, 0, 4, 2, 2, 0, 2, 3, 3, 0, 6, 1, 1, 0]\n",
      "[2, 4, 2, 1, 2, 2, 4, 1, 0, 1, 3, 1]\n",
      "[1, 6, 6, 1, 1, 4, 1, 3, 4, 5]\n",
      "[6, 3, 1, 6, 5, 2, 5, 0, 6, 4, 5, 0, 5]\n",
      "[5, 0, 0, 4, 1, 5, 0, 4, 2, 1, 2, 3, 2, 2, 4, 2, 4, 2, 5, 5, 1, 4, 0, 0, 3, 1, 3]\n",
      "[3, 3, 1, 0, 5, 6, 1, 5, 6, 2, 3, 3, 3, 1, 4, 5, 2, 5, 4, 3, 1, 6, 5, 0, 2, 2, 2, 4]\n",
      "[1, 6, 5, 2, 2, 6, 6, 1, 2, 5, 3, 4, 0, 5, 4, 2, 2, 2, 6, 4, 6, 6, 5, 1, 1, 4, 4, 5, 3, 0, 3, 3]\n",
      "[5, 5, 3, 6, 4, 2, 4, 0, 3, 0, 4, 4, 1, 6, 4, 1, 3, 0, 0, 5, 0, 4, 3]\n",
      "[2, 2, 0, 2, 1, 4, 3]\n",
      "[2, 0, 3, 6, 4, 2, 1]\n",
      "[6, 6, 3, 6, 6, 1, 2, 6, 5, 4, 1, 2, 1, 2, 4, 1, 6, 1, 2, 3]\n",
      "[3, 6, 1, 0, 2, 1, 4]\n",
      "[3, 0, 0, 4, 5, 3, 1, 6, 2, 6, 2, 4, 3, 6, 1, 4, 4]\n",
      "[2, 3, 1, 6, 3, 4, 5, 3, 3, 0, 0, 1, 2, 2, 0, 5, 2, 3, 3, 1, 5, 2, 4, 4]\n",
      "[6, 5, 6, 2, 3, 6, 3, 6, 3, 3, 2, 1, 2, 3, 1, 5, 2, 2, 1, 6, 6, 3, 5, 1, 4, 2, 0, 4, 4]\n",
      "[1, 4, 3, 4, 5, 4, 3, 4]\n",
      "[2, 3, 5, 4, 2, 6, 5, 1, 6, 5, 2, 5, 4, 3, 4, 1, 2]\n",
      "[3, 2, 2, 0, 3, 0, 1, 0, 4, 1, 2, 5, 3, 3, 0, 5, 1]\n",
      "[2, 1, 5, 5, 2, 6, 2, 1, 2]\n",
      "[3, 4, 4, 1, 0, 0, 4, 4, 1, 2, 6, 2, 0, 6, 2, 0, 4, 0, 1, 1, 1, 0, 3, 3]\n",
      "[6, 3, 0, 6, 3, 6, 0, 4, 3, 5, 4, 2]\n",
      "[2, 3, 6, 1, 6, 6, 1, 4, 3, 4, 4, 5, 3, 2, 3, 4, 1, 5, 4, 3, 4, 3, 5, 1, 2]\n",
      "[4, 2, 4, 5, 4, 5, 4]\n",
      "[0, 4, 5, 1, 1, 3, 2, 4, 2, 4, 1, 4]\n",
      "[1, 5, 6, 6, 2, 3, 4, 4, 4, 6, 4, 2, 4, 4, 0, 6, 3, 6]\n",
      "[6, 4, 1, 6, 1, 2, 2, 4, 4, 2, 0, 2, 4, 5, 0, 3]\n",
      "[5, 0, 2, 6, 5, 2, 1, 0, 3, 4, 2, 1, 2, 3]\n",
      "[2, 1, 6, 3, 2, 4, 5, 5, 1, 1, 4, 4, 3]\n",
      "[1, 1, 5, 1, 6, 4, 0, 6, 0, 1, 5, 1]\n",
      "[1, 3, 5, 4, 1, 4, 3, 3, 1, 6, 5, 1, 4, 3, 6, 2, 0, 5, 4, 0, 2, 5, 4, 4, 3, 2, 3, 1, 1, 2]\n",
      "[0, 6, 6, 3, 4, 4, 6, 0, 2, 2, 1, 3, 1, 3, 5, 4, 4, 3]\n",
      "[2, 1, 1, 1, 2, 1, 1, 0, 6, 3, 5, 4, 5, 4, 2, 5, 2]\n",
      "[5, 5, 3, 2, 3, 4, 1, 0, 1, 5, 0, 1, 1, 2, 0, 3, 4, 1, 5, 3, 0, 0, 5, 4, 0, 5, 3, 6]\n",
      "[5, 4, 4, 0, 4, 6, 2, 0, 2, 6, 3, 6, 5, 6]\n",
      "[3, 2, 1, 0, 2, 3, 0, 6, 5, 2, 3, 0, 2, 6, 0, 2, 0, 0, 1, 2, 6, 4, 1]\n",
      "[2, 1, 6, 1, 3, 2, 1, 3, 1, 1, 4, 5, 4, 4, 2, 4, 5, 0, 3, 0]\n",
      "[3, 4, 4, 5, 2, 0, 2, 3, 2, 4, 2]\n",
      "[0, 1, 6, 4, 1, 1, 0, 3, 2, 1, 2, 1, 3]\n",
      "[3, 4, 4, 4, 2, 6, 1, 1, 0]\n",
      "[1, 4, 1, 5, 1, 1, 4, 6, 3, 6, 6, 3, 6, 3, 4, 3, 2, 0, 3, 1, 2, 6, 2, 2, 6, 4]\n",
      "[5, 2, 2, 4, 1, 4, 5, 0, 4, 6, 0, 6, 2, 1, 1, 6, 6, 3, 4, 2, 0, 0, 5, 5, 2, 3, 3]\n",
      "[0, 0, 1, 1, 2, 1, 2, 1, 3]\n",
      "[4, 6, 6, 4, 5, 0, 4, 0, 5, 4, 4, 1, 4, 1, 5, 2, 5]\n",
      "[2, 0, 6, 0, 5, 0, 4, 3, 3, 5, 0, 1, 2, 1, 4, 4, 3, 1, 6, 1]\n",
      "[2, 4, 4, 1, 3, 0, 2, 3, 2, 2, 1, 3, 2, 4, 5, 6, 3, 6, 0, 6, 6, 1, 1, 4, 4]\n",
      "[1, 2, 3, 1, 4, 2, 4, 3, 6, 5, 3, 4, 2, 1, 2, 5, 4, 6, 1, 1, 3]\n",
      "[4, 1, 0, 1, 6, 2, 6, 6, 3, 0, 0, 5, 5, 1, 4, 3, 2, 4, 6, 5, 0, 2, 1, 0, 2, 2, 5, 3]\n",
      "[4, 3, 3, 0, 3, 6, 5, 3, 5, 3, 4, 0, 3, 4, 6]\n",
      "[1, 0, 5, 1, 2, 2, 4, 3, 4, 4, 6, 1, 3, 6, 6, 4, 0, 3, 3, 0, 6, 5, 6, 6, 4, 3, 1, 2]\n",
      "[1, 6, 3, 3, 3, 0, 1, 6, 2, 6, 1, 1, 5, 4, 0, 6]\n",
      "[4, 6, 2, 4, 1, 5, 1, 3, 4, 1, 1, 4, 5, 5, 3, 5, 5, 5, 3, 4, 3, 3, 0, 3, 0, 2, 2]\n",
      "[3, 2, 6, 3, 2, 5, 2, 2, 4, 1, 4, 3, 1, 4, 1, 1, 2, 4, 0, 3]\n",
      "[1, 1, 3, 1, 1, 2, 2, 3, 2, 6, 1, 0, 5, 5, 3, 0, 6, 0, 3, 6, 2, 2, 4, 4, 0]\n",
      "[5, 4, 3, 0, 5, 3, 3, 0, 1, 1, 5, 5, 5, 4, 2, 2]\n",
      "[3, 1, 0, 3, 2, 3, 1, 2, 2, 3, 5, 4, 4, 3]\n",
      "[1, 4, 1, 0, 6, 4, 4, 2, 2, 2, 4, 2, 1, 3, 1]\n",
      "[3, 3, 6, 4, 0, 6, 0, 6, 3, 2, 4, 0, 2, 0, 2, 4, 4, 5, 1]\n",
      "[2, 0, 6, 0, 1, 5, 1, 1, 2, 3, 6, 6, 1, 1, 1, 5, 6, 3, 4, 2, 3, 4, 3, 5, 5, 0, 2, 0]\n",
      "[1, 5, 0, 1, 0, 6, 6, 0, 0, 3, 4, 6, 0, 3, 4, 2, 2, 4, 5, 1, 1, 3, 4, 2]\n",
      "[3, 5, 2, 3, 5, 1, 2, 0, 4, 2, 0, 2, 4, 6, 2, 1, 1, 4, 5, 4, 6, 4, 3, 2, 3, 1, 6, 6, 0, 0, 6, 1, 3, 3, 1, 4]\n",
      "[2, 1, 3, 5, 3, 5, 3, 3, 3, 5, 2, 5]\n",
      "[2, 5, 1, 3, 1, 2, 4, 4, 6, 3, 1, 1, 5, 4, 2, 1, 0, 3, 3]\n",
      "[6, 1, 0, 1, 2, 0, 6, 2, 3, 5, 0, 3]\n",
      "[6, 1, 6, 5, 1, 3, 2, 5, 2, 2, 2, 5, 2, 5]\n",
      "[1, 3, 5, 6, 1, 4, 3, 0, 2, 5, 5, 3, 3, 5, 4, 5, 3, 2, 3, 5, 4, 4]\n",
      "[3, 5, 0, 5, 1, 0, 2]\n",
      "[0, 1, 6, 0, 3, 2, 4, 3, 5]\n",
      "[2, 1, 2, 6, 2, 0, 2]\n",
      "[1, 2, 2, 4, 0, 2, 4, 4, 3, 0, 1, 0, 3]\n",
      "[0, 3, 2, 3, 0, 6, 5, 2, 3, 4, 2, 2, 0, 3, 0]\n",
      "[6, 6, 6, 4, 0, 3, 6, 2, 4, 3, 2, 6, 6, 3, 5, 1]\n",
      "[3, 6, 6, 6, 6, 6, 1, 2, 1, 2, 6, 1, 1, 0, 1, 0, 3, 1, 2, 4, 3, 3, 3, 5, 2, 4, 0, 2, 3, 4]\n",
      "[6, 0, 3, 6, 6, 5, 4, 5, 6, 2, 2, 3, 1, 5, 4, 0, 5, 6, 2, 4, 0, 2, 3, 4, 6, 4, 2, 2, 4, 0, 3, 3]\n",
      "[3, 1, 6, 2, 0, 0, 0, 0, 2, 4, 3, 5, 6, 3, 2, 4, 1, 3, 6, 6, 3, 2]\n",
      "[1, 1, 6, 4, 2, 4, 1, 3, 5, 6, 0, 3, 2, 3, 5, 3]\n",
      "[1, 0, 0, 2, 3, 4, 3, 4, 4, 3, 4, 0, 4, 2, 4]\n",
      "[4, 2, 2, 4, 4, 6, 1, 5, 4, 2, 2, 5, 3, 3, 6, 3, 4, 1, 6, 4, 1, 6, 3, 1, 5, 0, 5]\n",
      "[2, 4, 6, 0, 3, 0, 6, 1, 0, 6, 0, 2, 5, 5, 5, 1, 6, 4, 3, 3, 4, 1, 3, 5, 4, 3, 3, 1]\n",
      "[5, 6, 1, 3, 6, 0, 5, 3, 6, 4, 4, 6, 3, 5, 2, 3, 4, 2, 1, 1, 3, 6, 2, 2, 3, 1, 1, 5, 4, 4, 5, 6, 4, 5, 2, 0, 1, 2, 0, 0]\n",
      "[4, 2, 1, 1, 2, 4, 4, 6, 3, 2, 6, 5, 6, 4, 2, 5, 6, 5, 6]\n",
      "[3, 4, 1, 6, 2, 0, 4, 3, 6, 1, 6, 2, 3, 3, 2, 0]\n",
      "[2, 3, 5, 0, 1, 6, 2, 0, 5, 3, 5, 5, 4, 1, 3, 6, 4, 0, 2, 6, 4]\n",
      "[3, 2, 6, 6, 6, 6, 2, 5, 0, 4, 5, 1, 2, 0, 6, 6, 3, 3, 4]\n",
      "[2, 0, 3, 1, 4, 1, 3, 5, 6, 3, 5, 2, 1, 5, 4, 6, 6, 3, 1, 5, 2]\n",
      "[4, 2, 3, 6, 6, 6, 5, 4, 1, 3, 3, 2, 6, 0, 3, 4, 4, 4, 4, 1]\n",
      "[3, 0, 2, 5, 3, 0, 6, 2, 0, 5, 2, 1, 2, 0, 5, 6, 0, 3, 4, 5, 2, 2, 6, 3, 0, 6, 5, 1, 4, 6, 4, 4]\n",
      "[4, 5, 1, 2, 2, 2, 4, 1, 4, 0, 6, 4, 4, 0, 0, 2, 5, 6, 3, 5, 5, 5, 3]\n",
      "[5, 1, 6, 0, 0, 5, 4, 3, 3, 2]\n",
      "[4, 2, 4, 3, 1, 6, 3, 2, 3, 2, 4, 4, 2, 6, 2, 5, 2, 6, 3, 3, 3, 5, 5, 6]\n",
      "[5, 4, 3, 4, 3, 5, 6, 4, 2, 2, 1, 0, 1, 2, 6, 0, 0, 0, 3, 3, 6, 6, 6, 2, 6, 3, 3, 1]\n",
      "[5, 1, 2, 2, 0, 6, 6, 5, 0, 4, 6, 4, 6, 6, 2, 4, 2, 2, 0, 0, 4, 1, 5, 3, 5, 3]\n",
      "[2, 2, 5, 4, 2, 1, 2, 3, 3, 2, 4, 1, 4, 0, 4, 1, 1, 4, 5, 5, 5]\n",
      "[2, 4, 4, 3, 3, 5, 6, 4, 6, 1, 5]\n",
      "[5, 3, 2, 4, 2, 5, 3, 5, 2, 5, 2]\n",
      "[6, 2, 1, 2, 4, 0, 0, 3, 3, 5, 3, 6, 2, 0, 2, 5, 5, 0, 0, 6, 4, 4, 5, 5, 3, 3, 2, 4, 1, 2, 5, 4, 3, 6, 1, 1, 1]\n",
      "[5, 1, 4, 4, 5, 4, 2, 3, 0, 5, 6, 4, 6, 6, 2, 4]\n",
      "[1, 0, 5, 5, 3, 0, 6, 1, 4]\n",
      "[0, 1, 6, 1, 5, 2, 2, 1, 0, 2, 5, 6, 0, 0, 4, 3, 6, 2, 1, 4, 4, 0, 4, 0, 5, 3, 3]\n",
      "[0, 5, 3, 2, 2, 5, 6, 6, 5, 2, 3, 5, 1, 4, 1, 4, 4, 0, 0, 1, 4, 2, 0, 3]\n",
      "[6, 1, 2, 1, 0, 2, 0, 5, 0, 0, 1, 4, 3, 6, 2, 5, 2, 4, 2, 2, 3, 3, 3, 3, 4, 4]\n",
      "[2, 4, 6, 0, 1, 3, 6, 1, 4, 6, 5, 2, 1, 3, 1, 0]\n",
      "[3, 6, 3, 5, 5, 2, 1, 6, 2, 6, 5, 6]\n",
      "[5, 2, 2, 0, 1, 4, 1, 3, 1, 6, 1]\n",
      "[1, 4, 1, 6, 0, 2, 3, 1, 5, 4, 5, 0, 5, 5, 4, 1, 4, 4, 6, 5, 6, 1, 2, 1]\n",
      "[6, 5, 5, 3, 5, 3, 0, 5, 6, 2, 3, 4]\n",
      "[5, 3, 4, 6, 4, 1, 0, 3, 2, 1, 0, 3, 4, 4, 0, 0, 0, 0, 1, 2]\n",
      "[5, 2, 6, 5, 1, 4, 3, 2, 3, 4, 6, 0, 0, 6, 6, 5, 1, 0, 4, 6, 4, 2, 5, 6, 4, 4, 1, 1, 0, 2]\n",
      "[3, 0, 6, 0, 3, 0, 4, 5, 2, 4, 1]\n",
      "[3, 1, 6, 2, 2, 3, 2, 2, 1, 5, 2, 3, 0, 2, 3]\n",
      "[4, 3, 5, 5, 5, 2, 0, 5, 6, 6, 4, 5, 3, 6, 2, 2, 1, 4, 1]\n",
      "[0, 5, 1, 6, 6, 0, 3, 1, 6, 5, 2]\n",
      "[4, 4, 4, 3, 4, 2, 0, 2, 4, 1, 4]\n",
      "[1, 4, 3, 2, 6, 1, 4, 5, 4, 6, 2, 2, 3, 6, 6, 5, 5]\n",
      "[0, 5, 6, 6, 3, 0, 5, 2, 1, 0, 4, 0, 4, 6, 4, 3, 4]\n",
      "[4, 3, 4, 5, 2, 6, 6, 3, 4, 5, 0, 1, 5, 6, 4]\n",
      "[4, 2, 0, 0, 3, 1, 1, 0, 4, 3, 6, 5, 6, 5, 4, 1, 4]\n",
      "[5, 2, 0, 2, 6, 2, 3, 4, 5, 2]\n",
      "[0, 0, 6, 6, 6, 1, 5, 5, 0, 0, 4, 3, 0, 4, 0, 3]\n",
      "[4, 2, 0, 0, 3, 0, 2, 4, 1, 4, 3, 0, 1, 6, 4, 2, 3]\n",
      "[2, 2, 3, 4, 3, 3, 3, 3, 5, 6, 2, 4, 2, 5, 6, 2, 0, 1, 5, 5, 2, 1, 1, 1, 6, 0, 0, 0, 0, 4, 0, 4]\n",
      "[1, 3, 0, 3, 5, 3, 3, 4, 5, 5, 0, 3, 0, 0, 5, 3, 1, 1, 2, 5, 5, 2]\n",
      "[1, 1, 3, 4, 0, 2, 6, 1, 1, 4, 0, 4, 1, 6, 2, 4]\n",
      "[0, 6, 6, 5, 6, 2, 3, 4, 1, 2, 1, 0, 6, 0, 3, 3, 1, 6, 1]\n",
      "[1, 5, 1, 3, 3, 4, 4, 3, 5, 2]\n",
      "[2, 0, 6, 0, 0, 3, 4, 5, 6, 3, 6, 2, 6]\n",
      "[2, 3, 6, 6, 2, 3, 6, 3, 2, 2, 5, 0, 3, 4, 6, 1, 1, 1, 0, 3, 1, 2, 4, 5, 6, 0, 1, 4, 6]\n",
      "[4, 0, 6, 6, 0, 5, 5, 5, 5, 6, 6, 5, 3, 3, 5, 1, 3, 0, 6, 6, 0, 1, 4, 1, 4, 3, 4]\n",
      "[0, 1, 6, 3, 6, 3, 1, 3, 4, 3]\n",
      "[5, 1, 1, 6, 3, 0, 4, 3, 2]\n",
      "[5, 5, 4, 1, 1, 1, 3, 2, 4, 4, 5, 6, 2, 4, 5, 5, 0, 5, 3]\n",
      "[5, 6, 2, 1, 4, 3, 0, 4, 2, 2, 0, 3, 1, 2, 5, 3, 4, 3]\n",
      "[3, 4, 3, 6, 3, 3, 6, 3, 4, 6, 3, 6, 4, 1, 4, 0, 4]\n",
      "[0, 5, 2, 2, 0, 6, 4, 4, 5, 4, 3, 3, 1]\n",
      "[3, 3, 1, 1, 4, 6, 4, 2, 2, 3, 1, 4, 0, 2, 1, 3, 5, 4, 0, 3]\n",
      "[3, 4, 2, 4, 6, 4, 3, 4]\n",
      "[3, 2, 1, 0, 4, 1, 1, 4, 2, 4, 6, 5, 3, 3, 4, 3, 2, 1, 4, 1, 6, 4, 2, 0, 2]\n",
      "[1, 6, 0, 4, 2, 3, 3, 1, 5, 5, 2, 1, 6, 2, 3, 6, 0, 2, 4, 0, 1, 3, 5, 4]\n",
      "[1, 2, 5, 4, 2, 5, 2, 4, 4, 5, 5, 6, 3, 6, 4, 3]\n",
      "[2, 5, 2, 6, 2, 0, 1, 5, 2]\n",
      "[6, 4, 6, 5, 5, 2, 3, 2, 1, 4, 4, 3, 1, 3, 3]\n",
      "[0, 3, 0, 2, 3, 1, 2, 1, 4, 1, 1, 5, 4, 4, 5]\n",
      "[5, 3, 6, 4, 0, 2, 3, 1]\n",
      "[2, 2, 2, 6, 6, 2, 4, 6, 6, 0, 1, 3, 3, 2, 5, 4, 4, 0, 4, 5, 4, 4, 0, 5, 6, 5, 3, 0, 6, 5]\n",
      "[3, 5, 0, 1, 4, 5, 4, 3, 4, 1, 4]\n",
      "[0, 2, 2, 0, 1, 5, 3, 3, 5, 5, 3, 3, 4, 3, 2, 3, 0, 5, 5, 2, 2, 2, 1, 1]\n",
      "[0, 3, 6, 2, 4, 4, 4, 0, 3, 4, 5, 4, 5, 4, 3, 5, 3]\n",
      "[0, 0, 4, 2, 3, 6, 3, 6, 1, 2, 6, 1, 2, 4, 0, 2, 2, 4, 4, 3, 6, 3, 2, 0, 3, 0, 5, 5]\n",
      "[2, 1, 2, 5, 2, 0, 6, 6, 2]\n",
      "[2, 2, 2, 1, 2, 3, 3, 6, 4, 0, 4, 3, 0, 0, 1, 5, 5, 5, 1, 6, 1]\n",
      "[0, 4, 3, 4, 4, 5, 2, 4, 1]\n",
      "[6, 6, 3, 1, 6, 6, 5, 1, 4]\n",
      "[3, 2, 4, 1, 1, 5, 1, 2, 4, 6, 4, 4, 2, 3, 2, 4, 5, 5, 3]\n",
      "[2, 4, 1, 4, 6, 0, 6, 4, 3, 4]\n",
      "[1, 5, 5, 2, 6, 5, 0, 4, 3, 4, 6, 4, 1, 3, 3, 3, 0, 6, 2, 4]\n",
      "[3, 5, 0, 1, 4, 1, 4, 6, 1, 5, 5, 5, 4, 1, 4]\n",
      "[3, 6, 1, 6, 5, 1, 0, 5, 2]\n",
      "[5, 4, 5, 6, 2, 1, 5, 0, 0, 2, 6, 4, 5]\n",
      "[4, 6, 4, 4, 5, 5, 0, 3, 0, 4, 4, 5, 3, 2, 4, 0, 3, 3]\n",
      "[1, 3, 5, 0, 4, 5, 2, 3, 4, 4, 3, 3, 4, 2, 5, 5, 0, 6]\n",
      "[6, 4, 2, 3, 3, 5, 6, 2, 0, 5, 4, 5, 3, 3, 4, 5]\n",
      "[3, 4, 6, 1, 5, 1, 3, 2, 3, 3, 1, 5, 1, 4, 3, 2, 2, 4, 1, 4]\n",
      "[3, 1, 2, 2, 6, 2, 4, 5, 5, 0, 0, 3, 2, 3, 2, 0, 2, 0, 6, 3, 5, 6, 5, 5, 4, 6, 5, 3]\n",
      "[6, 4, 2, 0, 3, 4, 0, 4, 0, 4]\n",
      "[0, 1, 3, 5, 0, 2, 1, 1, 5, 6, 5, 2, 0, 1, 0]\n",
      "[6, 3, 5, 0, 1, 0, 2, 1, 3, 3, 2, 5, 6, 4, 1, 2, 5, 6, 1, 4, 1, 2, 6, 1, 4, 5, 3, 5, 3, 5, 2, 3, 4]\n",
      "[4, 4, 1, 4, 4, 4, 4, 5, 1, 6, 5, 6, 0, 2, 1, 1, 6, 0, 1, 6, 5, 5, 1, 2, 2, 2, 6, 3, 5, 6, 0, 0, 2, 2, 0, 0, 3, 3]\n",
      "[6, 0, 0, 2, 5, 2, 5, 2, 3, 4, 3, 4, 2, 1, 1, 3, 1, 5, 2, 5, 0, 5, 4, 3, 3]\n",
      "[4, 6, 0, 3, 5, 3, 3, 1, 3, 2, 0, 3, 3, 2, 4, 6, 0, 1, 6, 6, 0]\n",
      "[2, 5, 4, 0, 0, 6, 3, 1, 1, 2, 1, 2, 4, 6, 3, 4, 2, 6, 5, 1, 1, 3, 5, 6]\n",
      "[6, 1, 3, 4, 0, 4, 3, 2, 6, 3, 2, 4, 6, 6, 3, 2, 5, 2, 2, 1, 3, 1]\n",
      "[2, 2, 1, 3, 1, 2, 2, 1, 5, 4, 0, 4, 6, 4, 2, 6, 1, 3, 5, 0, 6, 2, 4, 3]\n",
      "[4, 6, 3, 1, 5, 0, 2]\n",
      "[4, 0, 5, 6, 2, 1, 3]\n",
      "[0, 5, 3, 1, 4, 2, 0, 1, 4, 2, 3, 2, 6, 0, 1, 2]\n",
      "[3, 0, 3, 4, 2, 1, 3, 3, 4, 2, 2, 5, 6, 3, 3, 6, 0, 4, 2, 6, 2, 6, 6, 5, 1, 1, 5, 0, 6, 2, 0, 5, 4, 5, 4, 4, 5, 1, 1]\n",
      "[0, 3, 2, 2, 1, 5, 2, 1, 3, 0, 4, 2, 6, 1, 1]\n",
      "[4, 3, 3, 3, 6, 2, 6, 6, 1, 1, 4, 1, 2, 6, 3, 3, 1, 0, 6, 2, 0, 6, 2, 4]\n",
      "[0, 5, 0, 4, 4, 6, 3, 1, 5, 2, 1, 3, 5, 4, 6, 2, 2, 2, 2, 5]\n",
      "[5, 5, 6, 5, 2, 1, 3, 4, 1, 5, 6, 5]\n",
      "[2, 1, 3, 4, 2, 5, 3, 6, 4, 5, 5, 1, 3, 4, 3]\n",
      "[4, 1, 4, 6, 1, 4, 1, 3, 2, 0, 3, 2, 2, 1, 2, 0, 3, 1, 0]\n",
      "[4, 4, 5, 6, 2, 0, 2, 3, 2, 2, 6, 4, 3, 6, 4, 6, 5, 3, 0, 6, 0, 4, 4, 5]\n",
      "[4, 5, 3, 4, 3, 5, 5, 1, 3, 1, 1, 4, 0, 3, 1, 2, 6, 5, 1, 5, 1]\n",
      "[2, 3, 3, 3, 4, 2, 2, 1, 2, 0, 2, 2, 6, 3, 3, 6, 4, 5, 6, 6, 5, 6, 1, 3, 6, 1, 0, 1, 5, 0, 1, 0]\n",
      "[0, 3, 5, 6, 4, 1, 1, 3, 4, 0, 2, 5, 1, 0, 3, 6, 3, 1, 5, 6, 0, 1, 5, 6]\n",
      "[5, 0, 0, 5, 4, 2, 4, 4, 3, 6, 0, 1, 0, 0, 0, 3, 6, 6, 4, 1, 4, 1, 2, 1]\n",
      "[3, 2, 2, 0, 6, 2, 0, 2, 3, 2, 3, 3, 4, 5, 5, 4, 4, 2]\n",
      "[2, 1, 2, 0, 3, 2, 5, 4, 0, 5, 5, 5, 3, 1, 4, 2, 2, 1, 5, 3, 0, 5, 2, 6, 3, 3, 3, 1]\n",
      "[0, 0, 3, 1, 1, 6, 1, 4, 2, 2, 0, 6, 3, 2, 6, 3, 2, 0, 5, 6, 2, 3, 4, 0, 4, 4]\n",
      "[4, 5, 5, 5, 6, 4, 2, 4, 6, 4, 5, 4]\n",
      "[1, 4, 4, 6, 2, 1, 5, 5, 2, 1, 3, 2, 0]\n",
      "[2, 0, 6, 5, 6, 6, 2, 1, 1, 6, 0, 3, 3]\n",
      "[4, 6, 5, 3, 5, 3, 4, 2, 5, 1, 5]\n",
      "[1, 5, 4, 5, 3, 2, 0, 0, 1, 0, 5, 6, 3, 1, 4, 2, 4, 5, 4]\n",
      "[4, 1, 5, 6, 4, 2, 6, 5, 2, 4, 1, 0, 4, 1, 1, 3]\n",
      "[4, 1, 4, 2, 0, 4, 3, 2, 0, 6, 3, 4, 5, 3]\n",
      "[6, 5, 3, 3, 1, 2, 3, 0, 2, 4, 2, 1, 1, 2, 0, 0, 1, 0, 0, 6, 2, 1, 0, 6, 4, 1, 4]\n",
      "[1, 5, 1, 4, 6, 5, 4, 6, 2, 4, 1, 0, 1]\n",
      "[1, 3, 3, 4, 4, 3, 1, 3, 5, 5, 1, 1, 3, 6, 2, 2, 6, 4]\n",
      "[6, 3, 1, 6, 2, 3, 2, 4, 3, 4, 2, 3, 3, 2, 4, 4, 4, 6, 6, 4, 6, 2, 3, 6, 0, 1, 1]\n",
      "[6, 5, 2, 1, 2, 0, 0, 4, 0, 3, 5, 0, 3, 6, 4]\n",
      "[2, 1, 2, 3, 4, 5, 3, 0, 3, 0, 4, 5, 3, 3, 2, 6, 5, 4, 2]\n",
      "[6, 6, 4, 0, 1, 1, 1, 5, 3, 2, 3, 0, 3, 3, 0, 6, 2, 4, 1, 2]\n",
      "[6, 4, 5, 0, 3, 6, 5, 2, 5, 5, 0, 6, 1, 1, 6, 0, 1, 4, 2, 6, 1, 2, 0]\n",
      "[2, 4, 0, 3, 0, 0, 2, 4, 2, 4, 0, 2, 4, 5, 5, 6]\n",
      "[2, 3, 4, 4, 4, 4, 3, 4, 2, 1, 4, 0, 2, 2, 3, 6, 2, 2, 5, 0, 6, 3, 0, 6, 3, 3, 0, 6, 5, 5]\n",
      "[2, 3, 1, 5, 3, 3, 4, 4, 5, 5, 3, 5, 0, 1, 0, 5, 5, 4, 1, 2, 0, 0, 4, 1, 1, 6, 3, 1, 3, 6, 0, 6]\n",
      "[4, 6, 0, 1, 2, 2, 5, 2, 4, 5, 3]\n",
      "[2, 5, 3, 2, 6, 1, 0, 0, 2, 3, 6, 3, 4, 2, 2, 2, 4, 3, 0, 1]\n",
      "[3, 4, 5, 3, 2, 2, 2, 4, 1, 0, 4, 5]\n",
      "[3, 5, 1, 2, 6, 2, 0, 3, 0, 3, 3, 3, 6, 4, 1, 2, 3, 4, 4, 5]\n",
      "[4, 4, 2, 5, 5, 0, 2, 0, 3, 3, 1]\n",
      "[3, 5, 1, 5, 5, 5, 1, 1, 4, 3, 0, 2, 4, 4]\n",
      "[3, 2, 0, 2, 5, 1, 5, 0, 6, 4, 5, 5, 0, 2, 6, 3, 3, 6, 6, 4, 1, 0, 3, 4]\n",
      "[3, 3, 6, 2, 2, 4, 6, 6, 1, 2, 2, 3, 0, 6, 5, 3, 0, 5, 3, 4, 1, 4, 1]\n",
      "[3, 0, 4, 2, 5, 3, 1, 6, 0, 2, 2, 3, 2, 6, 2, 6, 2]\n",
      "[3, 4, 2, 4, 4, 6, 3, 6, 0, 5, 1]\n",
      "[6, 1, 1, 4, 6, 3, 4, 2]\n",
      "[4, 3, 6, 6, 4, 1, 0, 1, 5, 0, 0, 0, 3, 5, 1, 4, 2, 5, 3, 4, 5, 3, 2, 4, 2]\n",
      "[1, 0, 0, 3, 2, 1, 6, 4, 4, 3, 2, 4, 5, 4, 1, 6, 4, 2, 2, 3, 5, 1]\n",
      "[5, 3, 3, 5, 3, 1, 3, 6, 3]\n",
      "[2, 3, 6, 4, 4, 3, 4, 6, 3, 2, 4, 4, 4, 3, 1, 5, 1, 6, 2, 1, 3, 5, 6, 6, 5]\n",
      "[3, 6, 2, 3, 1, 2, 0]\n",
      "[4, 5, 1, 1, 6, 5, 1, 4, 2, 1, 3]\n",
      "[4, 4, 1, 2, 2, 2, 5, 2, 2, 4, 2, 1, 4, 1, 4, 5, 6, 3, 6, 3, 3]\n",
      "[0, 3, 4, 5, 3, 4, 1, 6, 4, 2, 3, 3, 3, 6, 2, 4, 0, 5, 2, 1, 5]\n",
      "[1, 6, 2, 1, 1, 6, 3, 3, 0]\n",
      "[2, 3, 5, 0, 3, 1, 3, 3, 1, 0, 2, 0, 0, 0, 6, 3, 1, 0, 5, 3, 2, 5, 2]\n",
      "[1, 6, 0, 0, 2, 1, 2, 3, 3, 2, 2, 5, 4, 3, 0, 4, 4, 3, 2, 5, 4, 5, 5]\n",
      "[1, 6, 3, 2, 2, 5, 1, 0, 5, 4, 2, 2, 2, 1, 4, 3, 3, 1, 3, 6, 3, 0, 1, 4, 6, 3, 2, 4, 4]\n",
      "[0, 2, 3, 1, 1, 3, 2, 5, 3, 4, 1, 4, 4, 2, 2, 1]\n",
      "[0, 6, 3, 5, 0, 4, 2, 6, 0, 0, 1]\n",
      "[1, 6, 4, 0, 0, 5, 4, 0, 3, 2, 3, 4, 5, 2, 6]\n",
      "[2, 3, 3, 6, 5, 4, 3, 2, 3, 1, 2, 6, 5, 1, 3]\n",
      "[6, 6, 4, 3, 4, 2, 2, 3, 6, 2, 1, 6, 5, 4, 6, 3, 2, 6, 1, 3]\n",
      "[5, 6, 3, 4, 3, 3, 5, 4, 4, 1, 3, 2, 1, 6, 0, 2, 2]\n",
      "[3, 0, 4, 4, 0, 5, 1, 2, 2, 2, 4, 5, 1, 3, 4, 3, 4, 4, 3, 2]\n",
      "[3, 2, 3, 2, 4, 3, 2, 3, 2, 2, 4, 4, 5, 6, 4, 4, 1, 2, 4, 0, 1, 3, 5, 6, 0, 5, 6, 3]\n",
      "[2, 2, 2, 4, 6, 0, 4, 6, 4, 4, 0, 4, 6, 2, 4, 0, 3, 1, 5, 3, 3, 3, 5, 5, 2, 0, 5, 6, 1, 1, 0, 0, 1, 3]\n",
      "[6, 4, 5, 4, 6, 0, 1, 3, 3, 2, 1, 3, 3, 2, 3, 5, 1, 2, 2, 1, 0]\n",
      "[1, 2, 5, 5, 5, 4, 5, 1, 5, 2, 5]\n",
      "[5, 2, 1, 5, 3, 3, 0, 2, 3, 0, 3, 4, 2, 1]\n",
      "[5, 3, 0, 1, 0, 3, 6, 4, 0, 0, 4, 0, 4, 4, 6, 6, 6, 6, 1, 2]\n",
      "[1, 2, 6, 6, 0, 0, 5, 0, 5, 4, 4, 6, 4, 0, 1, 3, 6, 6, 1, 2, 1]\n",
      "[4, 6, 5, 6, 1, 3, 3, 2, 4, 5, 4, 6, 0, 4, 4, 6]\n",
      "[5, 4, 5, 2, 3, 6, 5, 5, 5, 3, 5, 0, 2, 3, 0, 2, 3, 3, 2, 2, 4, 4]\n",
      "[0, 5, 5, 3, 5, 5, 3, 1, 3, 2, 2, 4]\n",
      "[1, 5, 0, 2, 1, 4, 3, 3, 3, 3, 6, 1, 5, 0, 5, 0, 1, 2, 2, 3, 4, 4, 6, 5]\n",
      "[0, 1, 4, 3, 6, 4, 4, 4, 3, 0, 3, 1, 5, 4, 5, 5, 4, 3, 6, 1, 0, 0, 5, 2, 5, 5, 1, 6, 2, 2]\n",
      "[3, 2, 0, 3, 5, 4, 3, 5, 6, 0, 2, 0, 1, 0, 1, 3, 4, 0]\n",
      "[1, 3, 5, 5, 3, 1, 5, 2, 3, 2, 4, 0, 5, 0, 4, 5, 3, 4, 3]\n",
      "[2, 5, 3, 3, 0, 5, 1]\n",
      "[6, 0, 4, 5, 3, 2, 3, 4, 6, 2, 2, 0, 3, 4, 3]\n",
      "[5, 1, 4, 5, 6, 0, 3]\n",
      "[0, 6, 1, 6, 5, 1, 4, 5, 2, 1, 5, 3, 1, 3, 6, 1, 5, 4]\n",
      "[2, 4, 2, 6, 2, 3, 2]\n",
      "[5, 3, 4, 2, 5, 0, 6, 1]\n",
      "[1, 1, 6, 1, 4, 2, 6, 6, 3, 5, 4, 3, 2, 1, 2, 1]\n",
      "[5, 0, 1, 5, 6, 5, 0, 6, 4, 3, 5, 6, 3, 3, 6, 3, 5, 5, 0, 3, 6, 3]\n",
      "[1, 3, 5, 3, 1, 0, 3, 6, 6, 4, 0, 0, 3, 1, 6, 1, 6, 6, 2, 4, 4, 0, 0, 1, 3, 3, 0, 6, 2, 4, 2, 2, 4]\n",
      "[3, 3, 4, 0, 6, 3, 5]\n",
      "[3, 0, 3, 2, 4, 5, 4, 0, 4, 4, 4, 0, 5, 2, 6, 6, 3, 3, 6, 2, 2, 6, 2, 5, 3, 5]\n",
      "[3, 3, 3, 4, 5, 6, 1, 6, 2, 5, 0]\n",
      "[1, 5, 0, 2, 4, 2, 2, 4, 3, 1, 1, 3]\n",
      "[2, 4, 1, 3, 4, 3, 3, 3, 0, 0, 1, 1, 6, 0, 2, 0, 5, 2, 2]\n",
      "[1, 2, 5, 3, 2, 6, 6, 4, 0, 1, 1, 5, 3, 6, 3, 1, 0, 6, 1, 0, 3, 3, 1, 6, 6, 3, 0, 0, 5, 5, 2, 0, 2, 2]\n",
      "[5, 4, 4, 3, 4, 1, 2, 3, 1, 3, 1, 3]\n",
      "[2, 6, 0, 4, 5, 5, 6, 5, 4, 1, 3, 2, 2, 4, 3, 6, 5, 3]\n",
      "[4, 2, 0, 5, 5, 6, 0, 4, 2, 3, 0, 2, 5, 4, 5, 6, 5]\n",
      "[6, 6, 5, 2, 2, 3, 3, 6, 2, 4, 4, 5, 3, 2, 3, 1]\n",
      "[3, 2, 1, 6, 2, 0, 3, 3, 1, 0, 1, 5, 1]\n",
      "[5, 3, 3, 2, 2, 1, 1, 2, 2, 2, 4, 4, 3, 0]\n",
      "[4, 1, 1, 5, 2, 0, 2, 5, 0, 4, 3, 1, 3]\n",
      "[4, 1, 5, 3, 3, 6, 1, 2, 2, 4, 5, 3, 3, 0]\n",
      "[4, 4, 3, 5, 3, 0, 2, 3, 1]\n",
      "[2, 3, 3, 5, 6, 5, 4, 2, 4, 5, 5, 4, 0, 1, 0, 3, 6, 1, 5, 3, 0, 0, 1, 0, 3, 3, 2, 2, 1]\n",
      "[2, 1, 1, 6, 4, 4, 4, 2, 0, 3, 2, 2, 3, 2, 3, 6, 5, 1, 1]\n",
      "[5, 5, 1, 1, 5, 6, 6, 4, 4, 5, 5, 4, 2, 0, 3, 3, 1, 4, 5, 1, 0, 2, 4, 2]\n",
      "[2, 2, 2, 5, 4, 2, 0, 0, 1, 0, 3]\n",
      "[5, 6, 0, 3, 3, 4, 4, 6, 6, 3, 2, 4, 5, 2, 2, 4, 3, 1]\n",
      "[3, 2, 1, 3, 2, 2, 3, 5, 4, 1, 3, 2, 3, 1, 4, 3, 6, 2, 2, 4, 4]\n",
      "[1, 4, 1, 2, 3, 5, 0, 0, 6, 2, 2, 5, 3, 2, 1, 1, 0, 3, 2, 4]\n",
      "[5, 2, 0, 4, 2, 0, 6, 0, 6, 4, 3, 3, 6, 4, 6]\n",
      "[3, 0, 2, 4, 0, 5, 3, 1, 5, 6, 5, 6, 1, 2, 6, 4, 2, 1, 3, 0, 2, 4, 4, 3, 6, 4, 0, 2, 1, 5, 3, 0, 2]\n",
      "[5, 3, 3, 3, 2, 1, 5, 2, 2, 1, 4, 5, 3, 5, 1, 4, 6, 1, 4]\n",
      "[2, 3, 3, 2, 2, 3, 6, 5, 5, 0, 5, 1, 4, 4, 0, 5, 1, 3, 4, 2]\n",
      "[4, 2, 1, 2, 6, 2, 2, 6, 4, 6, 1, 6, 5, 3, 3, 6]\n",
      "[2, 3, 5, 2, 2, 1, 3, 6, 6, 5, 4, 5, 2, 4, 5, 4, 6, 1, 4, 6]\n",
      "[0, 0, 3, 2, 6, 3, 0, 3, 3, 4, 3, 2, 3, 2, 0, 2]\n",
      "[4, 2, 5, 1, 4, 4, 2, 2, 0, 2, 5, 0, 2, 1, 2, 0, 1, 4, 4, 6, 4, 0, 3, 3, 3, 1, 6, 3]\n",
      "[2, 1, 3, 6, 3, 3, 4, 2, 5]\n",
      "[3, 3, 5, 1, 3, 3, 4, 5, 2]\n",
      "[5, 4, 1, 5, 6, 5, 6, 5, 1, 2, 5, 4, 4, 1, 1, 4, 2, 6, 2, 6, 1, 3]\n",
      "[0, 1, 5, 4, 0, 4, 1, 5, 4, 3, 3, 0, 3, 3, 0, 2]\n",
      "[5, 2, 3, 5, 5, 6, 4, 4, 1, 6, 4, 4, 3, 1, 0, 4, 3, 3, 6]\n",
      "[6, 6, 4, 0, 2, 1, 5, 6, 6, 2, 3]\n",
      "[2, 5, 1, 4, 3, 3, 6, 6, 4, 3, 2, 0, 0, 1, 0, 2, 1, 0, 0, 4, 5, 0, 4, 1]\n",
      "[2, 3, 0, 2, 4, 2, 5, 2, 1, 4, 2, 4, 1, 5, 5, 2, 6, 6, 1, 1, 6, 4, 1, 5, 6, 5, 4, 3]\n",
      "[5, 2, 4, 3, 6, 4, 1, 6, 0, 5, 2, 2, 4, 4, 4, 1, 4, 6, 2, 5, 3, 5, 6, 5]\n",
      "[5, 3, 4, 3, 3, 4, 0, 2, 5, 2, 3, 5, 0, 4, 2, 0, 6, 0, 2, 5]\n",
      "[5, 2, 2, 5, 5, 1, 5, 3, 2, 2, 6, 5, 4, 0]\n",
      "[4, 5, 3, 0, 6, 6, 3, 1, 3, 3, 1, 2, 4, 2, 3, 4, 5, 1, 3, 5, 6, 2, 0, 0, 6, 0, 2, 2, 4, 0, 2, 4, 1, 6, 6, 1, 5, 5, 0, 1]\n",
      "[3, 0, 2, 1, 4, 5, 1, 2, 3, 6, 4, 1, 6, 5, 4, 2, 4]\n",
      "[1, 1, 3, 5, 0, 2, 6, 0, 1, 1, 3, 3, 1, 1, 2, 4, 5, 3, 4]\n",
      "[5, 0, 3, 4, 6, 0, 5, 6, 4, 2, 6, 1, 5, 1, 5]\n",
      "[6, 2, 6, 5, 5, 3, 6, 6, 3, 4]\n",
      "[2, 5, 1, 0, 3, 4, 0, 5, 5, 4, 3, 3, 5, 4, 4, 2, 0, 0, 2, 0, 5, 2]\n",
      "[0, 4, 4, 6, 2, 1, 4, 2, 2, 6, 3, 3, 2, 6, 3, 5, 0, 6]\n",
      "[2, 4, 5, 5, 3, 5, 0, 2, 1]\n",
      "[4, 6, 1, 0, 0, 0, 4, 4, 6, 1, 6, 2, 2, 4, 2, 6, 0, 1, 1, 2, 4, 4, 6, 3, 3]\n",
      "[1, 5, 4, 3, 4, 3, 3, 4, 6, 4, 4, 3, 3, 0, 1, 6, 1, 0, 1]\n",
      "[3, 3, 1, 6, 5, 0, 6, 6, 2, 4, 6, 1, 5, 2, 6, 0]\n",
      "[2, 2, 1, 5, 4, 2, 3]\n",
      "[2, 1, 3, 1, 3, 2, 2, 3, 0, 2, 2, 6, 6, 5, 1, 0, 1, 0, 5, 1, 4]\n",
      "[3, 3, 1, 5, 2, 4, 0]\n",
      "[4, 0, 3, 2, 5, 5, 0, 3, 6]\n",
      "[5, 3, 6, 6, 3, 0, 5, 3, 1, 1, 2, 3, 5, 3, 5]\n",
      "[5, 5, 2, 0, 0, 1, 1, 3, 1, 3, 4, 4, 4, 3, 5, 3]\n",
      "[0, 0, 0, 3, 5, 4, 4, 2, 4, 1]\n",
      "[3, 3, 6, 2, 0, 2, 3, 4, 4, 6, 4, 5, 4, 3, 2, 0, 1, 4, 1, 1, 1, 4, 5, 5, 0, 1, 2, 1, 6, 0, 2, 0, 2]\n",
      "[6, 4, 0, 5, 3, 6, 5, 4, 0, 3, 3, 0, 4, 3, 1, 6, 4, 2, 4, 4, 1, 3, 0, 3, 5, 6, 0, 6]\n"
     ]
    }
   ],
   "source": [
    "for item in logs:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.predict(game.board.reshape((6,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game.update_move(next(testgen))\n",
    "print game.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy2(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for move in game.legal_moves():\n",
    "    game.update_move(move)\n",
    "    print move , net.predict(game.board.reshape((1,6,7,1)))[0,0]\n",
    "    game.erase_move(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE_CACHE={}\n",
    "initializations = 0\n",
    "t1,t2,t3 = 0,0,0\n",
    "game = cccc.Board()\n",
    "for move in [3]:\n",
    "    game.update_move(move)\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "tree = MCTS_node(cccc.Board,game.board,game.player,leaf_branch=5,policy=pass_policy,net=net)\n",
    "MCTS(tree,game,cccc.Board,dur = 5,policy=pass_policy,net=net,leaf_branch=5)\n",
    "print sum(tree.N.values())\n",
    "print tree.N\n",
    "print {key : 0 if tree.N[key]==0 else float(tree.Vr[key]) / tree.N[key] for key in tree.N.keys()}\n",
    "print {key : 0 if tree.N[key]==0 else tree.Vn[key] / tree.N[key] for key in tree.N.keys()}\n",
    "print node_score(tree)\n",
    "print \"time spent on tree policy {:1.2f}\".format(t1)\n",
    "print \"time spent on rollout {:1.2f}\".format(t2)\n",
    "print \"time spent on backprop {:1.2f}\".format(t3)\n",
    "print initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.predict(game.board.reshape(1,6,7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE_CACHE={}\n",
    "initializations = 0\n",
    "t1,t2,t3 = 0,0,0\n",
    "game = cccc.Board()\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "tree = MCTS_node(cccc.Board,game.board,game.player)\n",
    "MCTS(tree,game,cccc.Board,dur = 0.1)\n",
    "print sum(tree.N.values())\n",
    "print tree.N\n",
    "print {key : 0 if tree.N[key]==0 else tree.Vr[key] / tree.N[key] for key in tree.N.keys()}\n",
    "print {key : 0 if tree.N[key]==0 else tree.Vn[key] / tree.N[key] for key in tree.N.keys()}\n",
    "print node_score(tree)\n",
    "print \"time spent on tree policy {:1.2f}\".format(t1)\n",
    "print \"time spent on rollout {:1.2f}\".format(t2)\n",
    "print \"time spent on backprop {:1.2f}\".format(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_node = tree\n",
    "puct_constant=3\n",
    "q = np.array([node_score(current_node)[move] for move in current_node.actions])\n",
    "u = puct_constant * current_node.priors * np.sqrt(np.sum(current_node.N.values())+1) / (\n",
    "            1 + np.array([current_node.N[move] for move in current_node.actions]))\n",
    "print q\n",
    "print u\n",
    "print q+u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a few features from a board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n",
      "ERROR:theano.sandbox.cuda:nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n",
      "C:\\Anaconda2\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import lasagne\n",
    "import theano\n",
    "from nolearn.lasagne import NeuralNet as NN,TrainSplit,BatchIterator\n",
    "from lasagne.nonlinearities import tanh,rectify\n",
    "from lasagne.layers import InputLayer,DenseLayer,DropoutLayer,Conv2DLayer as Conv\n",
    "from lasagne.objectives import squared_error\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class BoardExtractor(TransformerMixin):\n",
    "    def transform(self,X):\n",
    "        X = X.reshape(-1,6,7)\n",
    "        bunch = []\n",
    "        for board in X:\n",
    "            board = board.reshape((6,7))\n",
    "            # Xs\n",
    "            x = (board == 1).astype(float)\n",
    "\n",
    "            # Os\n",
    "            o = (board == -1).astype(float)\n",
    "\n",
    "            # blanks\n",
    "            blank = (board == 0).astype(float)\n",
    "\n",
    "            #legal\n",
    "            legal = blank-np.vstack((blank[1:],np.zeros((1,7))))\n",
    "            \n",
    "            \n",
    "            #advanced features\n",
    "            threat_factor = 3\n",
    "            scale_win = 0.05\n",
    "        \n",
    "            xcol = x[0:3,:]+x[1:4,:]+x[2:5,:]+x[3:6,:]\n",
    "            xrow = x[:,0:4]+x[:,1:5]+x[:,2:6]+x[:,3:7]\n",
    "            xdiag = x[0:3,0:4] + x[1:4,1:5]+x[2:5,2:6]+x[3:6,3:7]\n",
    "            xrdiag = x[3:6,0:4]+x[2:5,1:5]+x[1:4,2:6]+x[0:3,3:7]\n",
    "            ocol = o[0:3,:]+o[1:4,:]+o[2:5,:]+o[3:6,:]\n",
    "            orow = o[:,0:4]+o[:,1:5]+o[:,2:6]+o[:,3:7]\n",
    "            odiag = o[0:3,0:4] + o[1:4,1:5]+o[2:5,2:6]+o[3:6,3:7]\n",
    "            ordiag = o[3:6,0:4]+o[2:5,1:5]+o[1:4,2:6]+o[0:3,3:7]\n",
    "            open_xcol = xcol * (np.logical_not(ocol))\n",
    "            open_xrow = xrow * (np.logical_not(orow))\n",
    "            open_xdiag = xdiag * (np.logical_not(odiag))\n",
    "            open_xrdiag = xrdiag * (np.logical_not(ordiag))\n",
    "            open_ocol = ocol * (np.logical_not(xcol))\n",
    "            open_orow = orow * (np.logical_not(xrow))\n",
    "            open_odiag = odiag * (np.logical_not(xdiag))\n",
    "            open_ordiag = ordiag * (np.logical_not(xrdiag))\n",
    "\n",
    "\n",
    "            win_xrow = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_xrow[:,i:i+4] += (open_xrow**threat_factor)[:,:]\n",
    "\n",
    "            win_xcol = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_xcol[i:i+3,:] += (open_xcol**threat_factor)[:,:]\n",
    "\n",
    "            win_xdiag = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_xdiag[i:i+3,i:i+4] += (open_xdiag**threat_factor)[:,:]\n",
    "\n",
    "            win_xrdiag = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_xrdiag[3-i:6-i,i:i+4] += (open_xrdiag**threat_factor)[:,:]\n",
    "\n",
    "            win_orow = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_orow[:,i:i+4] += (open_orow**threat_factor)[:,:]\n",
    "\n",
    "            win_ocol = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_orow[i:i+3,:] += (open_ocol**threat_factor)[:,:]\n",
    "\n",
    "            win_odiag = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_odiag[i:i+3,i:i+4] += (open_odiag**threat_factor)[:,:]\n",
    "\n",
    "            win_ordiag = np.zeros((6,7))\n",
    "            for i in range(4):\n",
    "                win_ordiag[3-i:6-i,i:i+4] += (open_ordiag**threat_factor)[:,:]\n",
    "\n",
    "\n",
    "            win_x = (win_xcol+win_xrow+win_xdiag+win_xrdiag) * (board == 0)*scale_win\n",
    "            win_o = (win_ocol+win_orow+win_odiag+win_ordiag) * (board == 0)*scale_win\n",
    "            \n",
    "    \n",
    "#         bunch.append(np.array((board,x,o,blank,legal)))\n",
    "            bunch.append(np.array((board,x,o,blank,legal,win_x,win_o)))\n",
    "        return np.array(bunch).reshape(-1,7,6,7)\n",
    "    def fit(self,X,y):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = NN(layers = [('in' , InputLayer),\n",
    "                   ('conv'  , Conv),\n",
    "                   ('hid1'   , DenseLayer),\n",
    "                   ('drop1'  , DropoutLayer),\n",
    "                   ('hid2'   , DenseLayer),\n",
    "                   ('drop2'  , DropoutLayer),\n",
    "                   ('hid3'   , DenseLayer),\n",
    "                   ('drop3'  , DropoutLayer),\n",
    "                   ('out'   , DenseLayer)],\n",
    "                  in_shape = (None,7,6,7),\n",
    "                  conv_num_filters = 12, conv_nonlinearity = rectify, conv_filter_size = (4,4),\n",
    "                  hid1_num_units = 75, hid1_nonlinearity = rectify,\n",
    "                  drop1_p = 0.4,\n",
    "                  hid2_num_units = 50, hid2_nonlinearity = rectify,\n",
    "                  drop2_p = 0.4,\n",
    "                  hid3_num_units = 25, hid3_nonlinearity = rectify,\n",
    "                  drop3_p = 0.4,\n",
    "                  out_num_units = 1, out_nonlinearity = tanh,\n",
    "   \n",
    "   regression = True,\n",
    "   max_epochs = 1000,\n",
    "   update = lasagne.updates.nesterov_momentum,\n",
    "   update_learning_rate = 0.0001,\n",
    "   batch_iterator_train = BatchIterator(batch_size=32),\n",
    "   batch_iterator_test = BatchIterator(batch_size=32),\n",
    "   #objective= squared_error,\n",
    "   verbose = 1)\n",
    "\n",
    "nn2 = NN(layers = [('in' , InputLayer),\n",
    "                   ('conv'  , Conv),\n",
    "                   ('hid1'   , DenseLayer),\n",
    "                   ('drop1'  , DropoutLayer),\n",
    "                   ('hid2'   , DenseLayer),\n",
    "                   ('drop2'  , DropoutLayer),\n",
    "                   ('hid3'   , DenseLayer),\n",
    "                   ('drop3'  , DropoutLayer),\n",
    "                   ('out'   , DenseLayer)],\n",
    "                  in_shape = (None,1,6,7),\n",
    "                  conv_num_filters = 12, conv_nonlinearity = rectify, conv_filter_size = (4,4),\n",
    "                  hid1_num_units = 75, hid1_nonlinearity = rectify,\n",
    "                  drop1_p = 0.4,\n",
    "                  hid2_num_units = 50, hid2_nonlinearity = rectify,\n",
    "                  drop2_p = 0.4,\n",
    "                  hid3_num_units = 25, hid3_nonlinearity = rectify,\n",
    "                  drop3_p = 0.4,\n",
    "                  out_num_units = 1, out_nonlinearity = tanh,\n",
    "   \n",
    "   regression = True,\n",
    "   max_epochs = 1000,\n",
    "   update = lasagne.updates.nesterov_momentum,\n",
    "   update_learning_rate = 0.0001,\n",
    "   batch_iterator_train = BatchIterator(batch_size=32),\n",
    "   batch_iterator_test = BatchIterator(batch_size=32),\n",
    "   #objective= squared_error,\n",
    "   verbose = 1)\n",
    "\n",
    "pnn = NN(layers = [('in' , InputLayer),\n",
    "                   ('conv'  , Conv),\n",
    "                   ('hid'   , DenseLayer),\n",
    "                   ('drop'  , DropoutLayer),\n",
    "                   ('out'   , DenseLayer)],\n",
    "                  in_shape = (None,7,6,7),\n",
    "                  conv_num_filters = 12, conv_nonlinearity = rectify, conv_filter_size = (4,4),\n",
    "                  hid_num_units = 50, hid_nonlinearity = rectify,\n",
    "                  drop_p = 0.2,\n",
    "                  out_num_units = 7, out_nonlinearity = tanh,\n",
    "   \n",
    "   regression = True,\n",
    "   max_epochs = 1000,\n",
    "   update = lasagne.updates.nesterov_momentum,\n",
    "   update_learning_rate = 0.0001,\n",
    "   batch_iterator_train = BatchIterator(batch_size=32),\n",
    "   batch_iterator_test = BatchIterator(batch_size=32),\n",
    "   #objective= squared_error,\n",
    "   verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588128L, 1L, 6L, 7L)\n",
      "(1588128L, 1L)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X).reshape((-1,1,6,7))\n",
    "y = np.array(y).reshape((-1,1))\n",
    "#z = np.array(z).reshape((-1,7))\n",
    "print X.shape\n",
    "print y.shape\n",
    "#print z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reshaper(TransformerMixin):\n",
    "    def transform(self,X):\n",
    "        X = X.reshape(-1,1,6,7)\n",
    "        return X\n",
    "    \n",
    "net2 = Pipeline([('reshape',Reshaper()),('net',nn2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Pipeline([('features',BoardExtractor()),('net',nn)])\n",
    "pol_net = Pipeline([('features',BoardExtractor()),('net',pnn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n",
      "# Neural Network with 17332 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name    size\n",
      "---  ------  ------\n",
      "  0  in      7x6x7\n",
      "  1  conv    12x3x4\n",
      "  2  hid1    75\n",
      "  3  drop1   75\n",
      "  4  hid2    50\n",
      "  5  drop2   50\n",
      "  6  hid3    25\n",
      "  7  drop3   25\n",
      "  8  out     1\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -----\n",
      "      1     \u001b[36m0.58200\u001b[0m     \u001b[32m0.31462\u001b[0m    1.84987  0.93s\n",
      "      2     \u001b[36m0.26318\u001b[0m     \u001b[32m0.22994\u001b[0m    1.14454  0.97s\n",
      "      3     \u001b[36m0.23502\u001b[0m     \u001b[32m0.22295\u001b[0m    1.05416  0.92s\n",
      "      4     \u001b[36m0.22864\u001b[0m     \u001b[32m0.21936\u001b[0m    1.04230  1.03s\n",
      "      5     \u001b[36m0.22238\u001b[0m     \u001b[32m0.21374\u001b[0m    1.04043  1.03s\n",
      "      6     \u001b[36m0.20908\u001b[0m     \u001b[32m0.19769\u001b[0m    1.05759  1.04s\n",
      "      7     \u001b[36m0.19475\u001b[0m     \u001b[32m0.18617\u001b[0m    1.04610  1.00s\n",
      "      8     \u001b[36m0.18465\u001b[0m     \u001b[32m0.17810\u001b[0m    1.03682  1.00s\n",
      "      9     \u001b[36m0.17747\u001b[0m     \u001b[32m0.17147\u001b[0m    1.03501  0.99s\n",
      "     10     \u001b[36m0.17391\u001b[0m     \u001b[32m0.16661\u001b[0m    1.04384  0.99s\n",
      "     11     \u001b[36m0.17003\u001b[0m     \u001b[32m0.16282\u001b[0m    1.04430  0.99s\n",
      "     12     \u001b[36m0.16536\u001b[0m     \u001b[32m0.15983\u001b[0m    1.03457  0.98s\n",
      "     13     \u001b[36m0.16393\u001b[0m     \u001b[32m0.15772\u001b[0m    1.03938  1.00s\n",
      "     14     \u001b[36m0.16096\u001b[0m     \u001b[32m0.15679\u001b[0m    1.02660  0.96s\n",
      "     15     \u001b[36m0.16093\u001b[0m     \u001b[32m0.15365\u001b[0m    1.04735  1.02s\n",
      "     16     \u001b[36m0.15916\u001b[0m     \u001b[32m0.15314\u001b[0m    1.03926  1.02s\n",
      "     17     \u001b[36m0.15752\u001b[0m     \u001b[32m0.15103\u001b[0m    1.04299  1.01s\n",
      "     18     0.15795     \u001b[32m0.14876\u001b[0m    1.06181  1.00s\n",
      "     19     \u001b[36m0.15540\u001b[0m     0.14932    1.04076  0.98s\n",
      "     20     \u001b[36m0.15386\u001b[0m     \u001b[32m0.14840\u001b[0m    1.03684  0.97s\n",
      "     21     \u001b[36m0.15175\u001b[0m     \u001b[32m0.14558\u001b[0m    1.04243  0.97s\n",
      "     22     \u001b[36m0.15070\u001b[0m     \u001b[32m0.14376\u001b[0m    1.04829  0.98s\n",
      "     23     \u001b[36m0.15001\u001b[0m     \u001b[32m0.14297\u001b[0m    1.04929  1.00s\n",
      "     24     \u001b[36m0.14884\u001b[0m     \u001b[32m0.14219\u001b[0m    1.04679  0.99s\n",
      "     25     \u001b[36m0.14816\u001b[0m     \u001b[32m0.14212\u001b[0m    1.04248  1.03s\n",
      "     26     \u001b[36m0.14708\u001b[0m     \u001b[32m0.13830\u001b[0m    1.06345  1.03s\n",
      "     27     \u001b[36m0.14526\u001b[0m     0.13834    1.05002  0.98s\n",
      "     28     \u001b[36m0.14457\u001b[0m     \u001b[32m0.13770\u001b[0m    1.04986  0.99s\n",
      "     29     0.14486     \u001b[32m0.13770\u001b[0m    1.05198  0.99s\n",
      "     30     \u001b[36m0.14394\u001b[0m     0.13803    1.04279  1.00s\n",
      "     31     \u001b[36m0.14251\u001b[0m     \u001b[32m0.13472\u001b[0m    1.05782  0.97s\n",
      "     32     \u001b[36m0.14179\u001b[0m     0.13567    1.04510  0.99s\n",
      "     33     \u001b[36m0.14025\u001b[0m     0.13495    1.03928  1.00s\n",
      "     34     \u001b[36m0.13853\u001b[0m     \u001b[32m0.13455\u001b[0m    1.02955  0.99s\n",
      "     35     0.13939     0.13505    1.03212  1.03s\n",
      "     36     \u001b[36m0.13830\u001b[0m     \u001b[32m0.13184\u001b[0m    1.04896  1.00s\n",
      "     37     \u001b[36m0.13752\u001b[0m     \u001b[32m0.13007\u001b[0m    1.05734  1.03s\n",
      "     38     \u001b[36m0.13542\u001b[0m     \u001b[32m0.13006\u001b[0m    1.04120  1.08s\n",
      "     39     \u001b[36m0.13379\u001b[0m     \u001b[32m0.12849\u001b[0m    1.04127  1.13s\n",
      "     40     0.13446     \u001b[32m0.12722\u001b[0m    1.05698  1.01s\n",
      "     41     0.13400     0.12766    1.04966  1.01s\n",
      "     42     0.13463     0.12840    1.04851  0.96s\n",
      "     43     0.13388     \u001b[32m0.12715\u001b[0m    1.05292  1.00s\n",
      "     44     \u001b[36m0.13259\u001b[0m     0.12731    1.04140  0.98s\n",
      "     45     \u001b[36m0.13205\u001b[0m     0.12785    1.03288  1.03s\n",
      "     46     \u001b[36m0.13087\u001b[0m     0.12879    1.01614  0.99s\n",
      "     47     \u001b[36m0.13042\u001b[0m     \u001b[32m0.12642\u001b[0m    1.03168  0.99s\n",
      "     48     \u001b[36m0.12949\u001b[0m     0.12647    1.02393  1.01s\n",
      "     49     0.12955     \u001b[32m0.12478\u001b[0m    1.03823  1.02s\n",
      "     50     0.13041     0.12495    1.04368  1.02s\n",
      "     51     \u001b[36m0.12844\u001b[0m     0.12599    1.01945  0.98s\n",
      "     52     0.12967     \u001b[32m0.12432\u001b[0m    1.04300  0.97s\n",
      "     53     \u001b[36m0.12820\u001b[0m     0.12470    1.02802  0.99s\n",
      "     54     \u001b[36m0.12690\u001b[0m     \u001b[32m0.12337\u001b[0m    1.02863  0.97s\n",
      "     55     0.12777     \u001b[32m0.12260\u001b[0m    1.04216  0.96s\n",
      "     56     \u001b[36m0.12648\u001b[0m     0.12307    1.02772  0.99s\n",
      "     57     0.12698     0.12420    1.02232  0.99s\n",
      "     58     \u001b[36m0.12604\u001b[0m     0.12409    1.01575  0.98s\n",
      "     59     \u001b[36m0.12598\u001b[0m     0.12281    1.02581  0.99s\n",
      "     60     0.12635     \u001b[32m0.12227\u001b[0m    1.03334  0.99s\n",
      "     61     \u001b[36m0.12541\u001b[0m     \u001b[32m0.12145\u001b[0m    1.03263  1.01s\n",
      "     62     0.12549     \u001b[32m0.12133\u001b[0m    1.03430  0.96s\n",
      "     63     \u001b[36m0.12377\u001b[0m     0.12379    0.99985  0.99s\n",
      "     64     \u001b[36m0.12339\u001b[0m     \u001b[32m0.12020\u001b[0m    1.02653  0.96s\n",
      "     65     0.12444     \u001b[32m0.11933\u001b[0m    1.04276  1.02s\n",
      "     66     \u001b[36m0.12295\u001b[0m     0.12000    1.02457  0.98s\n",
      "     67     \u001b[36m0.12200\u001b[0m     0.12295    0.99231  0.99s\n",
      "     68     0.12279     0.12032    1.02055  0.98s\n",
      "     69     \u001b[36m0.12163\u001b[0m     0.11940    1.01864  1.03s\n",
      "     70     0.12260     0.12533    0.97822  1.02s\n",
      "     71     0.12227     0.11966    1.02186  0.99s\n",
      "     72     \u001b[36m0.12055\u001b[0m     0.12063    0.99928  1.00s\n",
      "     73     0.12195     0.12025    1.01414  1.00s\n",
      "     74     \u001b[36m0.12050\u001b[0m     0.11979    1.00599  1.01s\n",
      "     75     0.12189     0.12053    1.01130  0.95s\n",
      "     76     0.12163     0.12159    1.00032  1.00s\n",
      "     77     0.12060     \u001b[32m0.11904\u001b[0m    1.01306  0.98s\n",
      "     78     \u001b[36m0.11948\u001b[0m     0.11987    0.99670  1.03s\n",
      "     79     \u001b[36m0.11948\u001b[0m     0.12130    0.98495  1.02s\n",
      "     80     0.11953     0.12112    0.98690  1.03s\n",
      "     81     \u001b[36m0.11854\u001b[0m     \u001b[32m0.11846\u001b[0m    1.00066  1.00s\n",
      "     82     0.11985     0.12128    0.98821  1.00s\n",
      "     83     0.11938     0.12015    0.99362  1.00s\n",
      "     84     0.11901     \u001b[32m0.11786\u001b[0m    1.00979  1.00s\n",
      "     85     0.11864     0.11871    0.99945  0.99s\n",
      "     86     \u001b[36m0.11833\u001b[0m     0.12237    0.96704  0.97s\n",
      "     87     0.11971     0.12187    0.98226  0.99s\n",
      "     88     0.11852     0.11995    0.98808  0.97s\n",
      "     89     \u001b[36m0.11812\u001b[0m     \u001b[32m0.11739\u001b[0m    1.00629  0.98s\n",
      "     90     \u001b[36m0.11769\u001b[0m     0.12136    0.96970  1.02s\n",
      "     91     \u001b[36m0.11748\u001b[0m     0.11762    0.99877  0.98s\n",
      "     92     \u001b[36m0.11742\u001b[0m     \u001b[32m0.11732\u001b[0m    1.00083  0.96s\n",
      "     93     0.11810     \u001b[32m0.11701\u001b[0m    1.00930  1.02s\n",
      "     94     \u001b[36m0.11699\u001b[0m     0.11714    0.99876  0.99s\n",
      "     95     \u001b[36m0.11639\u001b[0m     0.11896    0.97842  0.99s\n",
      "     96     0.11645     \u001b[32m0.11674\u001b[0m    0.99754  1.00s\n",
      "     97     \u001b[36m0.11596\u001b[0m     0.11697    0.99136  1.01s\n",
      "     98     0.11730     0.11851    0.98975  1.03s\n",
      "     99     \u001b[36m0.11582\u001b[0m     0.11690    0.99082  1.01s\n",
      "    100     0.11655     0.11958    0.97465  0.99s\n",
      "    101     0.11676     0.11943    0.97757  1.01s\n",
      "    102     0.11626     \u001b[32m0.11505\u001b[0m    1.01048  1.04s\n",
      "    103     \u001b[36m0.11558\u001b[0m     0.11764    0.98251  1.02s\n",
      "    104     \u001b[36m0.11522\u001b[0m     0.11857    0.97175  0.99s\n",
      "    105     0.11561     0.11776    0.98179  0.95s\n",
      "    106     \u001b[36m0.11488\u001b[0m     0.11954    0.96103  0.95s\n",
      "    107     0.11558     0.11740    0.98454  1.02s\n",
      "    108     \u001b[36m0.11488\u001b[0m     0.11885    0.96654  0.98s\n",
      "    109     0.11576     0.11767    0.98377  0.98s\n",
      "    110     0.11500     0.12107    0.94988  1.02s\n",
      "    111     \u001b[36m0.11486\u001b[0m     0.11839    0.97018  0.97s\n",
      "    112     \u001b[36m0.11316\u001b[0m     0.11687    0.96826  1.03s\n",
      "    113     0.11381     0.11926    0.95433  1.07s\n",
      "    114     0.11361     0.11723    0.96907  1.06s\n",
      "    115     0.11343     0.11776    0.96322  1.03s\n",
      "    116     0.11552     \u001b[32m0.11369\u001b[0m    1.01603  1.05s\n",
      "    117     0.11396     0.11433    0.99679  1.03s\n",
      "    118     0.11395     0.11597    0.98257  1.00s\n",
      "    119     0.11374     0.11577    0.98251  1.03s\n",
      "    120     \u001b[36m0.11277\u001b[0m     0.11738    0.96078  1.02s\n",
      "    121     0.11310     0.11920    0.94881  1.03s\n",
      "    122     0.11300     0.11877    0.95145  1.01s\n",
      "    123     0.11329     0.11668    0.97094  1.02s\n",
      "    124     \u001b[36m0.11260\u001b[0m     0.11841    0.95089  1.03s\n",
      "    125     0.11341     0.11585    0.97893  1.02s\n",
      "    126     \u001b[36m0.11171\u001b[0m     0.11484    0.97273  1.02s\n",
      "    127     0.11351     0.11700    0.97011  0.99s\n",
      "    128     0.11280     0.11716    0.96278  1.01s\n",
      "    129     0.11308     0.11798    0.95844  1.06s\n",
      "    130     0.11367     0.11398    0.99728  1.06s\n",
      "    131     \u001b[36m0.11158\u001b[0m     0.11561    0.96519  1.04s\n",
      "    132     0.11268     0.11496    0.98015  1.05s\n",
      "    133     0.11210     0.12131    0.92408  1.03s\n",
      "    134     0.11251     0.11735    0.95873  1.02s\n",
      "    135     0.11274     0.11619    0.97032  1.05s\n",
      "    136     \u001b[36m0.11096\u001b[0m     0.11596    0.95687  1.05s\n",
      "    137     0.11203     0.11645    0.96203  1.05s\n",
      "    138     \u001b[36m0.11031\u001b[0m     0.11512    0.95822  1.01s\n",
      "    139     0.11060     0.11652    0.94917  1.03s\n",
      "    140     0.11125     0.11609    0.95827  1.06s\n",
      "    141     0.11052     0.11464    0.96401  1.05s\n",
      "    142     \u001b[36m0.11005\u001b[0m     0.11580    0.95035  1.06s\n",
      "    143     0.11075     0.11443    0.96782  1.03s\n",
      "    144     0.11095     0.11576    0.95845  1.04s\n",
      "    145     0.11049     0.11580    0.95415  1.01s\n",
      "    146     0.11095     0.11585    0.95767  1.04s\n",
      "    147     \u001b[36m0.10955\u001b[0m     0.11536    0.94963  1.03s\n",
      "    148     \u001b[36m0.10912\u001b[0m     0.11746    0.92902  1.01s\n",
      "    149     0.10989     0.11630    0.94496  1.04s\n",
      "    150     0.10926     0.11391    0.95915  1.01s\n",
      "    151     0.11045     0.11535    0.95752  1.03s\n",
      "    152     0.11003     \u001b[32m0.11206\u001b[0m    0.98186  1.03s\n",
      "    153     \u001b[36m0.10899\u001b[0m     0.11685    0.93272  1.02s\n",
      "    154     0.10944     0.11391    0.96072  1.03s\n",
      "    155     0.11043     0.11373    0.97094  1.05s\n",
      "    156     \u001b[36m0.10753\u001b[0m     0.11328    0.94923  0.99s\n",
      "    157     0.10845     0.11460    0.94635  1.03s\n",
      "    158     0.10888     0.11381    0.95663  1.03s\n",
      "    159     0.10923     0.11473    0.95213  0.98s\n",
      "    160     0.10915     0.11609    0.94025  1.03s\n",
      "    161     0.10851     0.11273    0.96263  1.06s\n",
      "    162     0.10951     0.11405    0.96020  1.02s\n",
      "    163     0.10843     \u001b[32m0.11108\u001b[0m    0.97614  1.03s\n",
      "    164     0.10973     0.11581    0.94751  0.97s\n",
      "    165     0.10840     0.11532    0.93997  0.95s\n",
      "    166     0.10760     0.11442    0.94040  0.97s\n",
      "    167     0.10827     0.11451    0.94551  1.06s\n",
      "    168     0.10835     0.11414    0.94935  1.06s\n",
      "    169     0.10859     0.11201    0.96946  1.02s\n",
      "    170     0.10902     0.11494    0.94842  1.02s\n",
      "    171     0.10857     0.11734    0.92525  1.03s\n",
      "    172     0.10774     0.11208    0.96128  1.00s\n",
      "    173     \u001b[36m0.10688\u001b[0m     0.11211    0.95338  1.01s\n",
      "    174     0.10828     0.11197    0.96708  0.99s\n",
      "    175     \u001b[36m0.10679\u001b[0m     0.11200    0.95348  1.00s\n",
      "    176     \u001b[36m0.10595\u001b[0m     0.11400    0.92939  1.03s\n",
      "    177     0.10752     0.11539    0.93176  0.99s\n",
      "    178     0.10761     0.11503    0.93551  1.00s\n",
      "    179     0.10723     0.11375    0.94270  0.97s\n",
      "    180     0.10692     \u001b[32m0.11051\u001b[0m    0.96753  0.99s\n",
      "    181     0.10649     0.11288    0.94340  0.97s\n",
      "    182     0.10721     0.11279    0.95059  0.99s\n",
      "    183     0.10621     0.11268    0.94256  0.93s\n",
      "    184     0.10715     \u001b[32m0.11014\u001b[0m    0.97286  0.98s\n",
      "    185     0.10763     0.11597    0.92815  1.00s\n",
      "    186     0.10646     0.11113    0.95798  0.99s\n",
      "    187     \u001b[36m0.10571\u001b[0m     0.11259    0.93887  0.98s\n",
      "    188     0.10663     0.11035    0.96630  0.99s\n",
      "    189     0.10690     0.11584    0.92281  1.02s\n",
      "    190     0.10591     \u001b[32m0.10976\u001b[0m    0.96493  0.96s\n",
      "    191     0.10585     0.11261    0.94000  0.98s\n",
      "    192     0.10585     0.11126    0.95139  1.00s\n",
      "    193     0.10613     0.11103    0.95585  1.00s\n",
      "    194     0.10579     0.11147    0.94907  0.96s\n",
      "    195     \u001b[36m0.10512\u001b[0m     0.11311    0.92938  0.97s\n",
      "    196     \u001b[36m0.10474\u001b[0m     \u001b[32m0.10893\u001b[0m    0.96151  0.98s\n",
      "    197     0.10597     0.11154    0.95009  1.02s\n",
      "    198     0.10478     0.11443    0.91568  1.01s\n",
      "    199     0.10507     \u001b[32m0.10838\u001b[0m    0.96942  1.00s\n",
      "    200     0.10494     \u001b[32m0.10622\u001b[0m    0.98792  0.95s\n",
      "    201     0.10511     0.10750    0.97778  1.01s\n",
      "    202     0.10557     0.11176    0.94459  1.01s\n",
      "    203     0.10561     0.10737    0.98363  0.99s\n",
      "    204     0.10492     0.11262    0.93158  0.95s\n",
      "    205     0.10570     0.10981    0.96253  1.01s\n",
      "    206     \u001b[36m0.10443\u001b[0m     0.11025    0.94722  0.99s\n",
      "    207     \u001b[36m0.10363\u001b[0m     0.11121    0.93176  0.97s\n",
      "    208     \u001b[36m0.10344\u001b[0m     0.10769    0.96058  1.03s\n",
      "    209     0.10348     0.11206    0.92339  1.01s\n",
      "    210     0.10390     0.10746    0.96690  1.01s\n",
      "    211     0.10425     0.11197    0.93108  1.01s\n",
      "    212     0.10444     0.10940    0.95464  1.01s\n",
      "    213     \u001b[36m0.10250\u001b[0m     0.10996    0.93210  0.98s\n",
      "    214     0.10436     \u001b[32m0.10621\u001b[0m    0.98261  0.99s\n",
      "    215     0.10444     0.10670    0.97880  1.01s\n",
      "    216     0.10376     0.10878    0.95382  1.01s\n",
      "    217     0.10292     0.10877    0.94623  0.96s\n",
      "    218     0.10280     0.11154    0.92168  1.00s\n",
      "    219     0.10380     0.10901    0.95222  0.98s\n",
      "    220     0.10293     0.11216    0.91771  1.06s\n",
      "    221     0.10298     0.10986    0.93739  0.96s\n",
      "    222     0.10271     0.10653    0.96412  0.97s\n",
      "    223     \u001b[36m0.10225\u001b[0m     0.10683    0.95719  0.99s\n",
      "    224     0.10250     0.10657    0.96184  1.01s\n",
      "    225     0.10240     0.10928    0.93701  0.97s\n",
      "    226     0.10238     0.10761    0.95144  0.94s\n",
      "    227     0.10350     0.10807    0.95775  0.96s\n",
      "    228     0.10256     0.11033    0.92961  1.01s\n",
      "    229     0.10380     0.10630    0.97646  0.98s\n",
      "    230     0.10242     0.10638    0.96271  0.97s\n",
      "    231     \u001b[36m0.10155\u001b[0m     0.10950    0.92739  0.98s\n",
      "    232     0.10157     \u001b[32m0.10538\u001b[0m    0.96379  1.00s\n",
      "    233     0.10265     \u001b[32m0.10456\u001b[0m    0.98171  0.93s\n",
      "    234     0.10197     0.10825    0.94198  0.96s\n",
      "    235     0.10185     0.11035    0.92298  0.97s\n",
      "    236     \u001b[36m0.10074\u001b[0m     \u001b[32m0.10382\u001b[0m    0.97028  1.01s\n",
      "    237     0.10109     0.10424    0.96972  0.99s\n",
      "    238     0.10148     0.10646    0.95319  1.00s\n",
      "    239     0.10180     0.10583    0.96194  0.99s\n",
      "    240     0.10093     0.10482    0.96285  0.96s\n",
      "    241     0.10145     0.10473    0.96869  1.04s\n",
      "    242     \u001b[36m0.10068\u001b[0m     0.10735    0.93785  1.03s\n",
      "    243     0.10118     0.10788    0.93787  1.06s\n",
      "    244     \u001b[36m0.10064\u001b[0m     0.10559    0.95310  1.07s\n",
      "    245     \u001b[36m0.10017\u001b[0m     0.10789    0.92839  1.06s\n",
      "    246     0.10028     0.10508    0.95436  1.03s\n",
      "    247     0.10072     0.10638    0.94686  1.06s\n",
      "    248     \u001b[36m0.09977\u001b[0m     0.10581    0.94296  1.05s\n",
      "    249     0.10024     0.10649    0.94130  1.02s\n",
      "    250     0.09996     \u001b[32m0.10352\u001b[0m    0.96565  1.01s\n",
      "    251     0.10110     0.10511    0.96189  0.97s\n",
      "    252     0.10046     0.10450    0.96140  0.94s\n",
      "    253     0.10068     0.10832    0.92952  0.93s\n",
      "    254     0.10054     0.10504    0.95720  0.94s\n",
      "    255     0.09982     0.10523    0.94856  0.93s\n",
      "    256     0.09980     0.10484    0.95194  0.91s\n",
      "    257     0.09986     0.10462    0.95453  0.97s\n",
      "    258     0.10058     0.10400    0.96706  0.89s\n",
      "    259     0.10037     0.10870    0.92334  1.00s\n",
      "    260     0.09984     \u001b[32m0.10322\u001b[0m    0.96724  0.95s\n",
      "    261     \u001b[36m0.09913\u001b[0m     \u001b[32m0.10308\u001b[0m    0.96174  0.96s\n",
      "    262     0.10060     \u001b[32m0.10171\u001b[0m    0.98908  0.90s\n",
      "    263     0.09970     0.10582    0.94219  0.93s\n",
      "    264     \u001b[36m0.09826\u001b[0m     0.10532    0.93290  0.91s\n",
      "    265     0.09868     \u001b[32m0.10117\u001b[0m    0.97534  0.96s\n",
      "    266     0.09968     0.10221    0.97525  0.95s\n",
      "    267     0.09987     0.10639    0.93874  0.92s\n",
      "    268     0.09916     0.10394    0.95396  1.00s\n",
      "    269     0.09835     0.10591    0.92854  0.96s\n",
      "    270     0.09913     \u001b[32m0.10116\u001b[0m    0.97996  0.91s\n",
      "    271     0.09883     0.10292    0.96023  0.93s\n",
      "    272     0.09916     0.10224    0.96988  0.93s\n",
      "    273     \u001b[36m0.09807\u001b[0m     0.10400    0.94300  1.00s\n",
      "    274     0.09904     0.10218    0.96922  0.89s\n",
      "    275     0.09828     0.10269    0.95709  0.92s\n",
      "    276     0.09859     0.10461    0.94249  0.97s\n",
      "    277     0.09853     0.10119    0.97371  0.91s\n",
      "    278     0.09871     0.10469    0.94282  0.97s\n",
      "    279     0.09817     \u001b[32m0.09997\u001b[0m    0.98195  0.94s\n",
      "    280     0.09852     0.10588    0.93044  0.93s\n",
      "    281     0.09874     0.10416    0.94801  0.96s\n",
      "    282     0.09820     0.10240    0.95901  0.93s\n",
      "    283     \u001b[36m0.09761\u001b[0m     0.10451    0.93393  0.93s\n",
      "    284     0.09811     0.10242    0.95797  0.92s\n",
      "    285     0.09774     0.10795    0.90539  0.94s\n",
      "    286     \u001b[36m0.09686\u001b[0m     0.10363    0.93472  0.93s\n",
      "    287     0.09808     0.10113    0.96976  0.92s\n",
      "    288     0.09780     0.10323    0.94740  0.99s\n",
      "    289     0.09785     0.10283    0.95156  0.99s\n",
      "    290     0.09739     0.10488    0.92865  0.93s\n",
      "    291     0.09732     0.10342    0.94102  0.92s\n",
      "    292     0.09731     \u001b[32m0.09986\u001b[0m    0.97454  0.97s\n",
      "    293     0.09694     0.10111    0.95882  0.93s\n",
      "    294     0.09787     0.10284    0.95169  1.00s\n",
      "    295     0.09799     0.10300    0.95140  0.96s\n",
      "    296     \u001b[36m0.09674\u001b[0m     0.10148    0.95327  0.95s\n",
      "    297     \u001b[36m0.09617\u001b[0m     0.10327    0.93126  0.98s\n",
      "    298     0.09708     0.10273    0.94501  0.93s\n",
      "    299     0.09646     0.10879    0.88667  0.97s\n",
      "    300     0.09668     0.10308    0.93792  0.92s\n",
      "    301     \u001b[36m0.09608\u001b[0m     0.10406    0.92329  0.92s\n",
      "    302     0.09638     0.10387    0.92788  0.93s\n",
      "    303     0.09776     0.10285    0.95054  0.89s\n",
      "    304     0.09699     0.10316    0.94020  0.94s\n",
      "    305     0.09726     0.10155    0.95773  0.89s\n",
      "    306     0.09697     0.10083    0.96172  0.95s\n",
      "    307     0.09682     0.10481    0.92379  0.93s\n",
      "    308     0.09659     0.10441    0.92511  0.93s\n",
      "    309     0.09623     0.10296    0.93464  0.97s\n",
      "    310     \u001b[36m0.09596\u001b[0m     0.10200    0.94082  0.94s\n",
      "    311     0.09689     0.10126    0.95684  0.97s\n",
      "    312     0.09629     0.10451    0.92135  1.03s\n",
      "    313     0.09603     0.10573    0.90824  1.00s\n",
      "    314     0.09639     0.10158    0.94887  0.96s\n",
      "    315     0.09605     0.10096    0.95133  0.96s\n",
      "    316     0.09646     0.10098    0.95526  0.99s\n",
      "    317     0.09631     0.10492    0.91799  0.96s\n",
      "    318     0.09646     \u001b[32m0.09944\u001b[0m    0.97000  0.93s\n",
      "    319     0.09672     0.10261    0.94256  0.95s\n",
      "    320     \u001b[36m0.09592\u001b[0m     0.10012    0.95810  0.94s\n",
      "    321     0.09607     0.10261    0.93626  0.97s\n",
      "    322     \u001b[36m0.09563\u001b[0m     0.10215    0.93626  0.94s\n",
      "    323     0.09589     0.10305    0.93048  0.93s\n",
      "    324     0.09697     \u001b[32m0.09894\u001b[0m    0.98004  0.91s\n",
      "    325     0.09691     \u001b[32m0.09844\u001b[0m    0.98445  0.93s\n",
      "    326     \u001b[36m0.09561\u001b[0m     0.10393    0.91992  0.95s\n",
      "    327     \u001b[36m0.09531\u001b[0m     0.10340    0.92174  0.93s\n",
      "    328     0.09651     0.09966    0.96834  0.97s\n",
      "    329     \u001b[36m0.09469\u001b[0m     \u001b[32m0.09796\u001b[0m    0.96661  0.94s\n",
      "    330     0.09566     0.09925    0.96388  0.98s\n",
      "    331     0.09530     0.10165    0.93757  0.95s\n",
      "    332     0.09523     0.09999    0.95242  0.93s\n",
      "    333     0.09539     0.10170    0.93793  0.96s\n",
      "    334     0.09531     0.10293    0.92599  0.95s\n",
      "    335     0.09508     0.10481    0.90721  0.93s\n",
      "    336     0.09595     0.10060    0.95386  0.96s\n",
      "    337     0.09618     0.10054    0.95669  0.96s\n",
      "    338     0.09515     0.10410    0.91404  0.96s\n",
      "    339     \u001b[36m0.09460\u001b[0m     0.09909    0.95469  0.92s\n",
      "    340     0.09471     0.10437    0.90750  0.97s\n",
      "    341     0.09535     0.10172    0.93741  0.92s\n",
      "    342     0.09570     0.10439    0.91681  0.98s\n",
      "    343     0.09462     0.10102    0.93666  0.93s\n",
      "    344     0.09469     0.10165    0.93151  0.93s\n",
      "    345     \u001b[36m0.09443\u001b[0m     0.09903    0.95349  0.94s\n",
      "    346     0.09476     0.10040    0.94386  0.98s\n",
      "    347     0.09474     0.10134    0.93486  1.00s\n",
      "    348     0.09522     0.10098    0.94296  0.96s\n",
      "    349     0.09446     0.10038    0.94102  0.95s\n",
      "    350     \u001b[36m0.09395\u001b[0m     0.10363    0.90661  0.94s\n",
      "    351     0.09569     0.10148    0.94297  0.94s\n",
      "    352     0.09556     0.10132    0.94317  0.90s\n",
      "    353     0.09405     0.10317    0.91162  0.96s\n",
      "    354     0.09453     0.10175    0.92905  0.92s\n",
      "    355     0.09532     0.10034    0.95001  0.89s\n",
      "    356     0.09478     0.09930    0.95449  0.99s\n",
      "    357     0.09486     0.10001    0.94851  0.93s\n",
      "    358     0.09420     0.10134    0.92959  0.92s\n",
      "    359     0.09400     0.10216    0.92011  0.98s\n",
      "    360     0.09426     \u001b[32m0.09697\u001b[0m    0.97211  0.99s\n",
      "    361     0.09493     0.10068    0.94292  0.94s\n",
      "    362     0.09516     0.10170    0.93569  0.98s\n",
      "    363     0.09529     0.10323    0.92303  0.92s\n",
      "    364     0.09455     0.09944    0.95080  0.96s\n",
      "    365     0.09540     0.10761    0.88656  0.92s\n",
      "    366     \u001b[36m0.09389\u001b[0m     0.09972    0.94150  0.92s\n",
      "    367     \u001b[36m0.09357\u001b[0m     0.09836    0.95131  0.91s\n",
      "    368     0.09409     0.10008    0.94016  0.94s\n",
      "    369     0.09458     0.10484    0.90217  0.93s\n",
      "    370     0.09455     0.10079    0.93809  0.97s\n",
      "    371     0.09465     0.09888    0.95723  0.95s\n",
      "    372     0.09443     0.09988    0.94535  0.94s\n",
      "    373     0.09447     0.10237    0.92287  0.95s\n",
      "    374     0.09406     0.09814    0.95844  0.94s\n",
      "    375     0.09409     0.09865    0.95377  0.91s\n",
      "    376     0.09432     0.09802    0.96222  0.97s\n",
      "    377     0.09428     0.09901    0.95224  0.92s\n",
      "    378     \u001b[36m0.09349\u001b[0m     0.10146    0.92147  0.92s\n",
      "    379     0.09407     0.09995    0.94117  0.90s\n",
      "    380     0.09430     0.09959    0.94687  0.93s\n",
      "    381     0.09457     0.09778    0.96717  0.92s\n",
      "    382     0.09409     0.09823    0.95790  0.96s\n",
      "    383     0.09407     0.09806    0.95930  0.95s\n",
      "    384     0.09356     0.10116    0.92487  0.91s\n",
      "    385     0.09482     0.09934    0.95446  0.91s\n",
      "    386     0.09415     0.10470    0.89924  0.98s\n",
      "    387     0.09367     0.10158    0.92215  0.93s\n",
      "    388     \u001b[36m0.09332\u001b[0m     0.10165    0.91810  0.95s\n",
      "    389     0.09463     0.10338    0.91541  0.96s\n",
      "    390     \u001b[36m0.09304\u001b[0m     0.10176    0.91423  0.97s\n",
      "    391     0.09351     0.10072    0.92840  0.95s\n",
      "    392     0.09307     0.10055    0.92560  1.00s\n",
      "    393     0.09387     0.09909    0.94737  0.92s\n",
      "    394     \u001b[36m0.09259\u001b[0m     0.09901    0.93508  0.94s\n",
      "    395     0.09308     0.09877    0.94238  0.94s\n",
      "    396     0.09386     0.09886    0.94943  1.01s\n",
      "    397     0.09349     0.09939    0.94065  0.98s\n",
      "    398     0.09374     0.10455    0.89662  0.96s\n",
      "    399     0.09367     0.10290    0.91039  0.95s\n",
      "    400     0.09328     0.09867    0.94544  0.94s\n",
      "    401     0.09310     0.10056    0.92582  0.89s\n",
      "    402     \u001b[36m0.09243\u001b[0m     0.09812    0.94200  1.01s\n",
      "    403     0.09423     0.10061    0.93667  0.95s\n",
      "    404     0.09252     0.10450    0.88538  0.97s\n",
      "    405     0.09292     0.10078    0.92200  0.98s\n",
      "    406     0.09344     0.10104    0.92479  0.93s\n",
      "    407     0.09277     0.09902    0.93689  0.97s\n",
      "    408     0.09343     0.10083    0.92657  0.93s\n",
      "    409     0.09275     0.10010    0.92658  0.91s\n",
      "    410     0.09267     0.10235    0.90546  0.92s\n",
      "    411     \u001b[36m0.09178\u001b[0m     0.09975    0.92005  0.91s\n",
      "    412     0.09370     0.10123    0.92564  0.93s\n",
      "    413     0.09249     0.10007    0.92431  0.96s\n",
      "    414     0.09211     0.10230    0.90033  0.95s\n",
      "    415     0.09219     0.10120    0.91091  0.96s\n",
      "    416     0.09253     0.09868    0.93768  0.94s\n",
      "    417     0.09289     0.10200    0.91067  0.94s\n",
      "    418     0.09254     0.10126    0.91386  0.91s\n",
      "    419     0.09321     0.10035    0.92881  0.94s\n",
      "    420     0.09263     0.10016    0.92484  0.92s\n",
      "    421     0.09252     0.09997    0.92547  0.93s\n",
      "    422     \u001b[36m0.09126\u001b[0m     0.10445    0.87367  0.98s\n",
      "    423     0.09223     0.10066    0.91620  0.95s\n",
      "    424     0.09229     0.10221    0.90296  0.97s\n",
      "    425     0.09266     0.10190    0.90931  0.93s\n",
      "    426     0.09257     0.10256    0.90262  0.95s\n",
      "    427     0.09271     0.09759    0.94999  0.90s\n",
      "    428     0.09244     0.10186    0.90756  0.98s\n",
      "    429     0.09242     0.09843    0.93892  1.02s\n",
      "    430     0.09238     0.10202    0.90550  0.93s\n",
      "    431     0.09227     0.09997    0.92303  0.93s\n",
      "    432     0.09237     0.09847    0.93804  0.98s\n",
      "    433     0.09281     0.10309    0.90031  0.92s\n",
      "    434     0.09210     0.10007    0.92030  0.97s\n",
      "    435     0.09264     0.10173    0.91067  0.94s\n",
      "    436     0.09252     0.09997    0.92546  0.93s\n",
      "    437     0.09173     0.10231    0.89656  0.89s\n",
      "    438     0.09193     0.10320    0.89083  0.96s\n",
      "    439     0.09259     0.10367    0.89306  0.94s\n",
      "    440     0.09251     0.10159    0.91069  0.92s\n",
      "    441     \u001b[36m0.09105\u001b[0m     0.10203    0.89235  0.92s\n",
      "    442     0.09220     0.10110    0.91194  0.97s\n",
      "    443     0.09185     0.10646    0.86270  0.92s\n",
      "    444     0.09126     0.09946    0.91754  0.97s\n",
      "    445     0.09138     0.10056    0.90873  0.95s\n",
      "    446     0.09269     0.10002    0.92665  0.96s\n",
      "    447     0.09183     0.09757    0.94122  0.93s\n",
      "    448     0.09231     0.10274    0.89850  0.97s\n",
      "    449     0.09141     0.10317    0.88608  0.94s\n",
      "    450     0.09151     \u001b[32m0.09667\u001b[0m    0.94654  1.01s\n",
      "    451     0.09150     0.10133    0.90302  0.93s\n",
      "    452     0.09137     0.10066    0.90773  0.99s\n",
      "    453     0.09153     0.10242    0.89368  0.93s\n",
      "    454     0.09178     0.10164    0.90299  0.93s\n",
      "    455     0.09176     0.10152    0.90389  0.94s\n",
      "    456     0.09237     0.10258    0.90050  0.96s\n",
      "    457     \u001b[36m0.09072\u001b[0m     0.09736    0.93182  0.94s\n",
      "    458     0.09179     0.10281    0.89288  0.97s\n",
      "    459     0.09124     0.10324    0.88375  0.94s\n",
      "    460     0.09097     0.10189    0.89282  0.98s\n",
      "    461     \u001b[36m0.09041\u001b[0m     0.09990    0.90501  0.93s\n",
      "    462     0.09223     0.10221    0.90231  0.97s\n",
      "    463     0.09129     0.09982    0.91460  0.96s\n",
      "    464     0.09080     0.09814    0.92526  1.00s\n",
      "    465     0.09103     0.10393    0.87594  0.93s\n",
      "    466     0.09072     0.10104    0.89784  0.96s\n",
      "    467     0.09136     0.10121    0.90265  0.99s\n",
      "    468     0.09097     0.09831    0.92530  0.93s\n",
      "    469     0.09266     0.09861    0.93960  1.01s\n",
      "    470     0.09097     0.10287    0.88429  0.96s\n",
      "    471     0.09179     0.10370    0.88514  0.94s\n",
      "    472     0.09159     0.10323    0.88728  0.96s\n",
      "    473     0.09108     0.10017    0.90923  0.96s\n",
      "    474     0.09140     0.10222    0.89411  0.96s\n",
      "    475     0.09118     0.10121    0.90095  0.90s\n",
      "    476     0.09152     0.09980    0.91705  0.90s\n",
      "    477     0.09079     0.10096    0.89926  0.92s\n",
      "    478     0.09077     0.10181    0.89155  0.93s\n",
      "    479     0.09046     0.10115    0.89431  0.93s\n",
      "    480     0.09054     \u001b[32m0.09667\u001b[0m    0.93658  0.93s\n",
      "    481     0.09122     0.10288    0.88670  0.97s\n",
      "    482     \u001b[36m0.09004\u001b[0m     0.09873    0.91201  0.98s\n",
      "    483     0.09020     0.10111    0.89209  0.91s\n",
      "    484     0.09161     0.10226    0.89587  0.93s\n",
      "    485     0.09012     0.10024    0.89904  0.91s\n",
      "    486     0.09062     0.10034    0.90306  0.95s\n",
      "    487     0.09154     0.10021    0.91345  0.92s\n",
      "    488     0.09150     0.10021    0.91311  0.89s\n",
      "    489     0.09056     0.10253    0.88324  0.94s\n",
      "    490     0.09175     0.10030    0.91477  0.98s\n",
      "    491     0.09105     0.10106    0.90102  0.96s\n",
      "    492     0.09170     0.10414    0.88048  0.92s\n",
      "    493     0.09022     0.09915    0.90993  0.96s\n",
      "    494     0.09076     0.09915    0.91538  0.93s\n",
      "    495     0.09108     0.10159    0.89657  0.98s\n",
      "    496     0.09159     0.10176    0.90008  0.97s\n",
      "    497     0.09163     0.09733    0.94144  0.92s\n",
      "    498     0.09028     0.09938    0.90845  0.93s\n",
      "    499     0.09039     0.10487    0.86192  0.96s\n",
      "    500     0.09093     0.10319    0.88119  0.96s\n",
      "    501     0.09044     0.10084    0.89681  0.90s\n",
      "    502     \u001b[36m0.08989\u001b[0m     0.09962    0.90233  0.97s\n",
      "    503     \u001b[36m0.08972\u001b[0m     0.10129    0.88576  0.93s\n",
      "    504     \u001b[36m0.08961\u001b[0m     0.10506    0.85300  0.92s\n",
      "    505     0.09084     0.10024    0.90624  0.94s\n",
      "    506     0.09070     0.10090    0.89897  1.10s\n",
      "    507     \u001b[36m0.08931\u001b[0m     0.10212    0.87457  0.94s\n",
      "    508     0.08954     0.10287    0.87041  0.98s\n",
      "    509     0.09112     0.09923    0.91832  0.96s\n",
      "    510     0.09012     0.09984    0.90265  0.96s\n",
      "    511     0.09110     0.10069    0.90478  0.93s\n",
      "    512     0.09088     0.10564    0.86031  0.91s\n",
      "    513     0.09015     0.10228    0.88145  0.94s\n",
      "    514     0.09053     0.09796    0.92408  0.92s\n",
      "    515     \u001b[36m0.08928\u001b[0m     0.10122    0.88205  0.97s\n",
      "    516     0.09065     0.10101    0.89745  0.99s\n",
      "    517     \u001b[36m0.08910\u001b[0m     0.10188    0.87459  0.94s\n",
      "    518     0.08997     0.10750    0.83701  0.96s\n",
      "    519     0.09070     0.10314    0.87940  0.95s\n",
      "    520     0.09025     0.10220    0.88307  0.92s\n",
      "    521     0.09048     0.10376    0.87202  0.95s\n",
      "    522     0.09017     0.10601    0.85061  0.93s\n",
      "    523     0.08980     0.10083    0.89066  1.00s\n",
      "    524     0.09059     0.10192    0.88882  0.93s\n",
      "    525     0.08964     0.09938    0.90198  0.99s\n",
      "    526     0.09041     0.09903    0.91300  0.92s\n",
      "    527     0.08960     0.10084    0.88852  1.00s\n",
      "    528     0.08998     0.10038    0.89635  0.93s\n",
      "    529     0.09071     0.10219    0.88761  0.94s\n",
      "    530     0.09014     0.10569    0.85291  0.94s\n",
      "    531     0.09020     0.10435    0.86435  0.96s\n",
      "    532     0.08976     0.10437    0.86000  0.95s\n",
      "    533     0.09052     0.10142    0.89246  0.94s\n",
      "    534     0.08943     0.10260    0.87166  0.95s\n",
      "    535     0.08947     0.10467    0.85481  1.00s\n",
      "    536     0.08918     0.09937    0.89748  0.97s\n",
      "    537     0.09044     0.10426    0.86742  1.00s\n",
      "    538     0.08942     0.09834    0.90935  0.96s\n",
      "    539     0.08989     0.09946    0.90381  0.98s\n",
      "    540     0.09018     0.10017    0.90029  0.99s\n",
      "    541     0.08969     0.09984    0.89831  0.95s\n",
      "    542     0.08953     0.09928    0.90181  1.04s\n",
      "    543     \u001b[36m0.08899\u001b[0m     0.10237    0.86928  1.04s\n",
      "    544     0.08992     0.10223    0.87953  1.06s\n",
      "    545     0.08974     0.10212    0.87871  1.04s\n",
      "    546     0.09005     0.10382    0.86734  1.04s\n",
      "    547     0.08901     0.10291    0.86493  0.98s\n",
      "    548     \u001b[36m0.08858\u001b[0m     0.10026    0.88349  0.96s\n",
      "    549     0.08907     0.10212    0.87229  0.93s\n",
      "    550     0.08972     0.10145    0.88437  0.95s\n",
      "    551     0.08977     0.10164    0.88317  0.96s\n",
      "    552     0.08961     0.10069    0.88996  0.96s\n",
      "    553     0.08947     0.10341    0.86520  1.07s\n",
      "    554     0.08905     0.10022    0.88850  1.12s\n",
      "    555     \u001b[36m0.08825\u001b[0m     0.10358    0.85201  1.07s\n",
      "    556     0.08964     0.10022    0.89440  1.10s\n",
      "    557     0.08925     0.09813    0.90955  1.06s\n",
      "    558     0.08828     0.10272    0.85947  1.10s\n",
      "    559     0.08928     0.10155    0.87912  1.14s\n",
      "    560     0.08987     0.10470    0.85836  1.12s\n",
      "    561     0.08851     0.10225    0.86559  1.10s\n",
      "    562     0.08831     0.10206    0.86529  1.10s\n",
      "    563     0.08973     0.10071    0.89096  1.06s\n",
      "    564     \u001b[36m0.08771\u001b[0m     0.10123    0.86644  1.03s\n",
      "    565     0.08927     0.10377    0.86024  1.07s\n",
      "    566     0.08903     0.09958    0.89414  1.08s\n",
      "    567     0.08897     0.10028    0.88724  1.05s\n",
      "    568     0.08906     0.09961    0.89405  1.04s\n",
      "    569     0.08896     0.10621    0.83758  1.05s\n",
      "    570     0.08974     0.09838    0.91222  1.02s\n",
      "    571     0.08874     0.10467    0.84781  1.05s\n",
      "    572     0.08803     0.10264    0.85769  1.08s\n",
      "    573     0.08932     0.10418    0.85741  1.02s\n",
      "    574     0.08818     0.10273    0.85836  1.07s\n",
      "    575     0.08915     0.09866    0.90360  1.04s\n",
      "    576     0.08897     0.10352    0.85952  1.02s\n",
      "    577     0.08878     0.10474    0.84762  1.03s\n",
      "    578     0.08915     0.10049    0.88723  1.05s\n",
      "    579     0.08920     0.10341    0.86259  1.02s\n",
      "    580     0.08892     0.10108    0.87971  1.04s\n",
      "    581     0.08906     0.09895    0.90001  1.00s\n",
      "    582     0.08911     0.10449    0.85282  1.01s\n",
      "    583     0.08872     0.10339    0.85812  1.03s\n",
      "    584     0.08802     0.10049    0.87584  1.02s\n",
      "    585     0.08838     0.10014    0.88260  1.19s\n",
      "    586     0.08879     0.10022    0.88593  1.18s\n",
      "    587     0.08843     0.10049    0.88003  1.04s\n",
      "    588     0.08906     0.10232    0.87039  1.06s\n",
      "    589     0.08876     0.10195    0.87063  1.05s\n",
      "    590     0.08899     0.10472    0.84976  1.04s\n",
      "    591     0.08880     0.10296    0.86245  1.02s\n",
      "    592     0.08962     0.10185    0.87988  1.07s\n",
      "    593     0.08868     0.10337    0.85796  1.12s\n",
      "    594     0.08943     0.09993    0.89493  1.02s\n",
      "    595     0.08919     0.10299    0.86603  1.10s\n",
      "    596     0.08891     0.10533    0.84410  1.11s\n",
      "    597     0.08826     0.10245    0.86155  1.06s\n",
      "    598     0.08851     0.10015    0.88376  1.08s\n",
      "    599     0.08921     0.10324    0.86409  1.07s\n",
      "    600     0.08829     0.10152    0.86966  1.06s\n",
      "    601     0.08917     0.10235    0.87128  1.00s\n",
      "    602     0.08901     0.10092    0.88202  0.99s\n",
      "    603     0.08977     0.09945    0.90266  1.03s\n",
      "    604     0.08874     0.10390    0.85402  1.23s\n",
      "    605     0.08821     0.10350    0.85222  1.02s\n",
      "    606     0.08828     0.10041    0.87924  1.08s\n",
      "    607     0.08897     0.10367    0.85821  1.00s\n",
      "    608     0.08900     0.09812    0.90700  1.03s\n",
      "    609     0.08843     0.10114    0.87429  1.03s\n",
      "    610     \u001b[36m0.08770\u001b[0m     0.10248    0.85574  0.97s\n",
      "    611     0.08871     0.10211    0.86877  1.00s\n",
      "    612     0.08790     0.09982    0.88065  1.00s\n",
      "    613     0.08831     0.10172    0.86817  1.02s\n",
      "    614     0.08800     0.09800    0.89791  1.01s\n",
      "    615     \u001b[36m0.08715\u001b[0m     \u001b[32m0.09626\u001b[0m    0.90536  1.04s\n",
      "    616     0.08847     0.10271    0.86142  1.01s\n",
      "    617     0.08822     0.10191    0.86563  0.99s\n",
      "    618     0.08795     0.10188    0.86331  0.98s\n",
      "    619     0.08891     0.10081    0.88199  1.02s\n",
      "    620     0.08793     0.10397    0.84569  1.01s\n",
      "    621     \u001b[36m0.08697\u001b[0m     0.10247    0.84873  1.03s\n",
      "    622     0.08846     0.09891    0.89437  1.01s\n",
      "    623     \u001b[36m0.08694\u001b[0m     0.10151    0.85649  1.00s\n",
      "    624     \u001b[36m0.08688\u001b[0m     0.10335    0.84068  0.99s\n",
      "    625     0.08817     0.10140    0.86954  1.07s\n",
      "    626     0.08705     0.10188    0.85447  1.00s\n",
      "    627     0.08770     0.10013    0.87588  1.03s\n",
      "    628     0.08852     0.10200    0.86788  0.95s\n",
      "    629     0.08774     0.10421    0.84192  1.05s\n",
      "    630     0.08901     0.10092    0.88202  1.05s\n",
      "    631     0.08720     0.10171    0.85739  1.02s\n",
      "    632     0.08781     0.10407    0.84374  1.01s\n",
      "    633     0.08777     0.09818    0.89401  1.01s\n",
      "    634     0.08847     0.10245    0.86354  0.99s\n",
      "    635     0.08771     0.10090    0.86922  1.01s\n",
      "    636     0.08875     0.10406    0.85288  1.03s\n",
      "    637     0.08906     0.10363    0.85943  1.05s\n",
      "    638     0.08773     0.10327    0.84960  1.03s\n",
      "    639     0.08828     0.09811    0.89981  0.97s\n",
      "    640     0.08781     0.10456    0.83981  1.04s\n",
      "    641     0.08800     0.10313    0.85333  1.03s\n",
      "    642     0.08812     0.09982    0.88283  0.98s\n",
      "    643     0.08747     0.10063    0.86923  0.95s\n",
      "    644     0.08779     0.10280    0.85398  1.00s\n",
      "    645     0.08777     0.10123    0.86704  1.00s\n",
      "    646     0.08696     0.10173    0.85480  1.07s\n",
      "    647     0.08765     0.10353    0.84657  1.00s\n",
      "    648     0.08793     0.10565    0.83234  1.00s\n",
      "    649     \u001b[36m0.08668\u001b[0m     0.09856    0.87947  1.00s\n",
      "    650     0.08753     0.10205    0.85771  1.09s\n",
      "    651     0.08830     0.10054    0.87828  1.04s\n",
      "    652     0.08785     0.09987    0.87972  0.98s\n",
      "    653     0.08804     0.10603    0.83030  1.08s\n",
      "    654     0.08718     0.10060    0.86667  1.02s\n",
      "    655     0.08799     0.10252    0.85825  0.98s\n",
      "    656     0.08699     0.09749    0.89232  1.01s\n",
      "    657     0.08764     0.10308    0.85028  0.99s\n",
      "    658     0.08738     0.10052    0.86933  1.00s\n",
      "    659     0.08739     0.09896    0.88305  1.04s\n",
      "    660     0.08708     0.10105    0.86179  0.94s\n",
      "    661     0.08688     0.09987    0.86999  0.99s\n",
      "    662     0.08733     0.09953    0.87741  0.97s\n",
      "    663     0.08727     0.10359    0.84252  1.00s\n",
      "    664     0.08744     0.10419    0.83925  1.03s\n",
      "    665     0.08733     0.10148    0.86051  1.01s\n",
      "    666     \u001b[36m0.08604\u001b[0m     0.10531    0.81703  1.03s\n",
      "    667     0.08741     0.10203    0.85672  0.96s\n",
      "    668     0.08670     0.09989    0.86788  0.98s\n",
      "    669     0.08680     0.10111    0.85847  1.00s\n",
      "    670     0.08640     0.10049    0.85981  1.02s\n",
      "    671     0.08792     0.10144    0.86667  1.01s\n",
      "    672     0.08757     0.09863    0.88787  1.01s\n",
      "    673     0.08658     0.10097    0.85748  1.00s\n",
      "    674     0.08627     0.10081    0.85580  1.07s\n",
      "    675     0.08742     0.10311    0.84789  0.99s\n",
      "    676     0.08695     0.10034    0.86663  0.99s\n",
      "    677     0.08729     0.10030    0.87027  1.00s\n",
      "    678     0.08698     0.09979    0.87158  0.97s\n",
      "    679     0.08763     0.10419    0.84104  1.03s\n",
      "    680     0.08683     0.09776    0.88819  0.99s\n",
      "    681     0.08716     0.10046    0.86757  1.02s\n",
      "    682     0.08685     0.09932    0.87439  1.01s\n",
      "    683     0.08608     0.10393    0.82818  0.98s\n",
      "    684     0.08644     0.10321    0.83750  0.96s\n",
      "    685     0.08715     0.09907    0.87972  1.04s\n",
      "    686     \u001b[36m0.08551\u001b[0m     0.10225    0.83632  1.05s\n",
      "    687     0.08725     0.10282    0.84851  1.10s\n",
      "    688     0.08678     0.09974    0.87001  1.04s\n",
      "    689     0.08710     0.09914    0.87857  1.03s\n",
      "    690     0.08749     0.10253    0.85335  1.00s\n",
      "    691     0.08692     0.10128    0.85817  0.96s\n",
      "    692     0.08702     0.10216    0.85187  0.99s\n",
      "    693     0.08728     0.10088    0.86511  0.92s\n",
      "    694     0.08759     0.09788    0.89491  0.95s\n",
      "    695     0.08704     0.10114    0.86065  0.98s\n",
      "    696     0.08679     0.09974    0.87014  0.97s\n",
      "    697     0.08682     0.10161    0.85440  0.95s\n",
      "    698     0.08715     0.09882    0.88194  0.96s\n",
      "    699     0.08727     0.10305    0.84691  0.96s\n",
      "    700     0.08714     0.09744    0.89432  0.93s\n",
      "    701     0.08557     0.10239    0.83571  1.01s\n",
      "    702     0.08652     0.09986    0.86649  0.91s\n",
      "    703     0.08719     0.10094    0.86378  0.98s\n",
      "    704     0.08740     0.10328    0.84627  0.97s\n",
      "    705     0.08631     0.10197    0.84642  1.00s\n",
      "    706     0.08728     0.09973    0.87517  0.96s\n",
      "    707     0.08669     0.10036    0.86387  0.94s\n",
      "    708     0.08637     0.10155    0.85056  0.98s\n",
      "    709     0.08627     0.09902    0.87117  0.96s\n",
      "    710     0.08700     0.10085    0.86271  1.01s\n",
      "    711     0.08719     0.10055    0.86710  1.01s\n",
      "    712     0.08622     0.09690    0.88985  0.97s\n",
      "    713     0.08650     0.10184    0.84939  0.93s\n",
      "    714     0.08630     0.09739    0.88617  0.97s\n",
      "    715     0.08622     \u001b[32m0.09599\u001b[0m    0.89823  1.01s\n",
      "    716     0.08647     0.10132    0.85343  0.99s\n",
      "    717     0.08663     0.09993    0.86694  0.98s\n",
      "    718     0.08653     0.09815    0.88166  0.94s\n",
      "    719     0.08615     0.09915    0.86884  0.93s\n",
      "    720     0.08651     0.09910    0.87295  0.98s\n",
      "    721     0.08601     0.10082    0.85310  1.04s\n",
      "    722     0.08686     0.10389    0.83613  0.98s\n",
      "    723     0.08682     0.10201    0.85108  0.96s\n",
      "    724     0.08601     0.10068    0.85434  0.95s\n",
      "    725     0.08698     0.10116    0.85979  0.97s\n",
      "    726     0.08703     0.09909    0.87833  0.98s\n",
      "    727     0.08749     0.10048    0.87069  0.94s\n",
      "    728     0.08641     0.10030    0.86154  0.96s\n",
      "    729     0.08563     0.10086    0.84892  0.95s\n",
      "    730     0.08631     0.10504    0.82162  1.00s\n",
      "    731     0.08637     0.10143    0.85158  0.99s\n",
      "    732     0.08683     0.09928    0.87460  0.99s\n",
      "    733     0.08744     0.10292    0.84957  0.95s\n",
      "    734     0.08627     0.10175    0.84783  0.93s\n",
      "    735     0.08644     0.10112    0.85484  0.94s\n",
      "    736     0.08635     0.10251    0.84238  0.96s\n",
      "    737     \u001b[36m0.08531\u001b[0m     0.09896    0.86211  0.97s\n",
      "    738     0.08641     0.09984    0.86546  0.98s\n",
      "    739     0.08580     0.10305    0.83252  1.00s\n",
      "    740     0.08678     0.09879    0.87846  0.96s\n",
      "    741     0.08639     0.10321    0.83710  0.98s\n",
      "    742     0.08605     0.09934    0.86625  0.97s\n",
      "    743     0.08633     0.09657    0.89395  0.98s\n",
      "    744     0.08619     0.10042    0.85835  0.97s\n",
      "    745     0.08742     0.10091    0.86626  0.99s\n",
      "    746     0.08671     0.09924    0.87372  0.98s\n",
      "    747     0.08562     0.10295    0.83169  0.99s\n",
      "    748     0.08585     0.10163    0.84478  0.92s\n",
      "    749     0.08630     0.10101    0.85440  0.94s\n",
      "    750     0.08541     0.09963    0.85726  0.97s\n",
      "    751     0.08563     0.10014    0.85507  0.95s\n",
      "    752     0.08611     0.10374    0.83006  0.99s\n",
      "    753     0.08654     0.09918    0.87258  0.96s\n",
      "    754     \u001b[36m0.08500\u001b[0m     0.10126    0.83947  0.91s\n",
      "    755     0.08572     0.10004    0.85687  0.97s\n",
      "    756     0.08571     0.09970    0.85967  0.92s\n",
      "    757     0.08520     0.10379    0.82090  0.92s\n",
      "    758     0.08559     0.09676    0.88458  0.93s\n",
      "    759     0.08507     0.10150    0.83815  0.99s\n",
      "    760     0.08715     0.10510    0.82919  0.93s\n",
      "    761     0.08613     0.09930    0.86735  0.96s\n",
      "    762     0.08553     0.10126    0.84465  1.01s\n",
      "    763     0.08548     0.10196    0.83835  0.96s\n",
      "    764     0.08607     0.09706    0.88669  1.01s\n",
      "    765     0.08565     0.09958    0.86010  0.97s\n",
      "    766     0.08552     0.10104    0.84633  1.01s\n",
      "    767     0.08513     0.10378    0.82033  0.98s\n",
      "    768     0.08588     0.09985    0.86011  0.94s\n",
      "    769     0.08677     0.10175    0.85279  0.97s\n",
      "    770     0.08563     0.10045    0.85242  0.98s\n",
      "    771     0.08613     0.09930    0.86730  0.96s\n",
      "    772     0.08512     0.09839    0.86510  0.97s\n",
      "    773     0.08514     0.09617    0.88524  0.96s\n",
      "    774     0.08574     0.09880    0.86777  0.96s\n",
      "    775     0.08599     0.09808    0.87667  0.94s\n",
      "    776     0.08519     0.10152    0.83908  0.96s\n",
      "    777     0.08573     0.09809    0.87396  0.95s\n",
      "    778     0.08578     0.10112    0.84836  0.98s\n",
      "    779     0.08541     0.09847    0.86734  1.00s\n",
      "    780     0.08591     0.09757    0.88049  0.95s\n",
      "    781     0.08640     0.09701    0.89069  0.97s\n",
      "    782     0.08521     0.09847    0.86530  0.99s\n",
      "    783     0.08629     0.09829    0.87786  0.95s\n",
      "    784     \u001b[36m0.08495\u001b[0m     0.09872    0.86054  0.94s\n",
      "    785     0.08591     0.09996    0.85939  0.92s\n",
      "    786     0.08562     0.10071    0.85009  0.97s\n",
      "    787     0.08581     \u001b[32m0.09537\u001b[0m    0.89980  0.92s\n",
      "    788     0.08659     0.10276    0.84269  1.01s\n",
      "    789     0.08548     0.09927    0.86109  0.97s\n",
      "    790     0.08555     0.10226    0.83662  0.99s\n",
      "    791     0.08578     0.09698    0.88443  0.99s\n",
      "    792     0.08544     0.09871    0.86560  0.97s\n",
      "    793     0.08498     0.09951    0.85404  0.99s\n",
      "    794     0.08566     0.10354    0.82735  1.00s\n",
      "    795     0.08541     0.09998    0.85425  1.01s\n",
      "    796     0.08529     0.10469    0.81470  0.94s\n",
      "    797     0.08512     0.10267    0.82908  0.95s\n",
      "    798     0.08513     0.10250    0.83051  0.97s\n",
      "    799     0.08573     0.09768    0.87768  0.93s\n",
      "    800     0.08593     0.10111    0.84980  0.94s\n",
      "    801     0.08504     0.10144    0.83834  1.01s\n",
      "    802     0.08563     0.10474    0.81756  1.03s\n",
      "    803     0.08689     0.10026    0.86665  1.03s\n",
      "    804     0.08505     0.09996    0.85086  0.97s\n",
      "    805     0.08532     0.09858    0.86553  0.99s\n",
      "    806     0.08521     0.09893    0.86137  0.99s\n",
      "    807     0.08510     0.10121    0.84085  1.01s\n",
      "    808     \u001b[36m0.08430\u001b[0m     0.10094    0.83510  0.95s\n",
      "    809     0.08466     0.10278    0.82367  0.97s\n",
      "    810     0.08582     0.10115    0.84849  1.01s\n",
      "    811     0.08491     0.10024    0.84707  1.01s\n",
      "    812     0.08487     0.10259    0.82733  0.96s\n",
      "    813     0.08530     0.10546    0.80883  0.95s\n",
      "    814     0.08510     0.09662    0.88074  0.99s\n",
      "    815     0.08554     0.10087    0.84797  0.97s\n",
      "    816     0.08526     0.10064    0.84716  1.04s\n",
      "    817     0.08562     0.09891    0.86556  1.04s\n",
      "    818     0.08569     0.09988    0.85793  0.93s\n",
      "    819     0.08508     0.09768    0.87098  0.95s\n",
      "    820     0.08544     0.09706    0.88024  0.93s\n",
      "    821     0.08445     0.10494    0.80474  0.95s\n",
      "    822     0.08455     0.09766    0.86577  0.93s\n",
      "    823     0.08552     0.09773    0.87505  0.99s\n",
      "    824     0.08568     0.10138    0.84520  0.94s\n",
      "    825     0.08515     0.10005    0.85107  0.94s\n",
      "    826     \u001b[36m0.08370\u001b[0m     0.09832    0.85134  0.92s\n",
      "    827     0.08523     0.09862    0.86420  1.00s\n",
      "    828     0.08557     0.09734    0.87912  1.00s\n",
      "    829     0.08566     0.09897    0.86554  1.01s\n",
      "    830     0.08616     0.09792    0.87993  0.99s\n",
      "    831     0.08485     0.09910    0.85616  0.95s\n",
      "    832     0.08585     0.09992    0.85925  0.97s\n",
      "    833     0.08476     0.09828    0.86242  0.98s\n",
      "    834     0.08509     0.10266    0.82892  0.98s\n",
      "    835     0.08465     0.09907    0.85439  0.97s\n",
      "    836     0.08601     0.10020    0.85832  0.95s\n",
      "    837     0.08454     0.09864    0.85708  0.98s\n",
      "    838     0.08415     0.10289    0.81785  1.06s\n",
      "    839     0.08426     0.10273    0.82017  1.03s\n",
      "    840     0.08488     0.10091    0.84112  0.97s\n",
      "    841     0.08492     0.10435    0.81381  0.98s\n",
      "    842     0.08505     0.10218    0.83237  0.98s\n",
      "    843     0.08537     0.09794    0.87171  0.95s\n",
      "    844     0.08496     0.09936    0.85504  1.01s\n",
      "    845     0.08422     0.09873    0.85311  0.92s\n",
      "    846     0.08493     0.10027    0.84697  0.98s\n",
      "    847     0.08424     0.09971    0.84479  1.00s\n",
      "    848     0.08415     0.10188    0.82605  1.01s\n",
      "    849     0.08523     0.10195    0.83604  0.98s\n",
      "    850     0.08539     0.09897    0.86279  0.94s\n",
      "    851     0.08442     0.10143    0.83229  0.96s\n",
      "    852     0.08390     0.10212    0.82162  1.00s\n",
      "    853     0.08550     0.09763    0.87575  0.94s\n",
      "    854     0.08439     0.10208    0.82667  1.04s\n",
      "    855     0.08483     0.09825    0.86342  0.97s\n",
      "    856     0.08526     0.09766    0.87306  0.96s\n",
      "    857     0.08437     0.10134    0.83252  0.94s\n",
      "    858     0.08485     0.09947    0.85303  0.95s\n",
      "    859     0.08484     0.09760    0.86925  0.99s\n",
      "    860     \u001b[36m0.08360\u001b[0m     0.09764    0.85622  1.01s\n",
      "    861     0.08373     0.09657    0.86703  0.98s\n",
      "    862     0.08489     0.09912    0.85651  1.06s\n",
      "    863     0.08495     0.09995    0.84998  0.92s\n",
      "    864     0.08436     0.10225    0.82503  0.94s\n",
      "    865     0.08438     0.09856    0.85612  0.99s\n",
      "    866     \u001b[36m0.08356\u001b[0m     0.10073    0.82960  0.96s\n",
      "    867     0.08415     0.09908    0.84931  1.00s\n",
      "    868     0.08491     0.09711    0.87439  0.98s\n",
      "    869     0.08511     0.10031    0.84848  0.97s\n",
      "    870     \u001b[36m0.08344\u001b[0m     0.09880    0.84454  0.94s\n",
      "    871     0.08425     0.10168    0.82865  0.97s\n",
      "    872     0.08453     0.09726    0.86915  0.98s\n",
      "    873     0.08437     0.09810    0.86005  0.92s\n",
      "    874     0.08385     0.10004    0.83810  0.92s\n",
      "    875     0.08470     0.09769    0.86705  0.96s\n",
      "    876     0.08380     0.10060    0.83302  0.98s\n",
      "    877     0.08472     0.10109    0.83806  1.03s\n",
      "    878     0.08429     0.10067    0.83731  0.98s\n",
      "    879     0.08473     0.10351    0.81857  0.93s\n",
      "    880     0.08535     0.10301    0.82856  0.95s\n",
      "    881     0.08481     0.10093    0.84026  0.94s\n",
      "    882     0.08388     0.10011    0.83782  1.03s\n",
      "    883     0.08400     0.09898    0.84862  0.96s\n",
      "    884     0.08457     0.10270    0.82344  0.96s\n",
      "    885     0.08394     0.10063    0.83412  1.10s\n",
      "    886     0.08417     0.09827    0.85653  1.01s\n",
      "    887     0.08430     0.10047    0.83900  0.93s\n",
      "    888     0.08497     0.09902    0.85814  0.95s\n",
      "    889     0.08522     0.09549    0.89242  0.93s\n",
      "    890     0.08382     0.09766    0.85823  0.99s\n",
      "    891     0.08431     0.09994    0.84365  0.97s\n",
      "    892     0.08405     0.09946    0.84507  1.00s\n",
      "    893     0.08448     0.09690    0.87184  0.95s\n",
      "    894     0.08393     0.09803    0.85611  0.93s\n",
      "    895     0.08442     0.09835    0.85842  1.05s\n",
      "    896     0.08443     0.09824    0.85943  1.02s\n",
      "    897     0.08409     0.10106    0.83210  1.00s\n",
      "    898     0.08348     0.10119    0.82500  0.98s\n",
      "    899     0.08425     0.10351    0.81397  1.00s\n",
      "    900     0.08459     0.09906    0.85389  0.99s\n",
      "    901     0.08528     0.09933    0.85856  0.97s\n",
      "    902     0.08385     0.09785    0.85693  0.99s\n",
      "    903     0.08396     0.09826    0.85453  0.95s\n",
      "    904     0.08360     0.10036    0.83292  0.99s\n",
      "    905     0.08481     0.09859    0.86017  0.99s\n",
      "    906     0.08413     0.10136    0.82997  0.95s\n",
      "    907     \u001b[36m0.08339\u001b[0m     0.09881    0.84398  0.93s\n",
      "    908     0.08394     0.09988    0.84034  0.95s\n",
      "    909     0.08449     0.10018    0.84335  1.00s\n",
      "    910     0.08440     0.09978    0.84587  0.97s\n",
      "    911     0.08524     0.09930    0.85837  0.99s\n",
      "    912     0.08423     0.10362    0.81287  1.02s\n",
      "    913     0.08465     0.10088    0.83913  0.92s\n",
      "    914     0.08425     0.09700    0.86856  0.95s\n",
      "    915     0.08357     0.09961    0.83894  0.99s\n",
      "    916     0.08359     0.10206    0.81897  1.00s\n",
      "    917     0.08369     0.09616    0.87030  0.94s\n",
      "    918     0.08384     0.10085    0.83128  0.93s\n",
      "    919     0.08453     0.09613    0.87928  1.01s\n",
      "    920     0.08356     0.10190    0.82002  0.97s\n",
      "    921     0.08389     0.10169    0.82495  0.98s\n",
      "    922     0.08398     0.09889    0.84919  0.95s\n",
      "    923     0.08383     0.09838    0.85212  1.00s\n",
      "    924     0.08477     0.10219    0.82951  0.96s\n",
      "    925     \u001b[36m0.08300\u001b[0m     0.10002    0.82985  0.93s\n",
      "    926     \u001b[36m0.08264\u001b[0m     0.09956    0.83011  0.96s\n",
      "    927     0.08374     0.09829    0.85204  0.94s\n",
      "    928     0.08358     0.09731    0.85894  0.94s\n",
      "    929     0.08408     0.09746    0.86276  0.96s\n",
      "    930     0.08404     0.09638    0.87189  0.98s\n",
      "    931     0.08345     0.09798    0.85172  0.96s\n",
      "    932     0.08350     0.10293    0.81126  0.96s\n",
      "    933     0.08414     0.09736    0.86422  0.95s\n",
      "    934     0.08395     0.09672    0.86800  1.01s\n",
      "    935     0.08417     0.09903    0.84994  1.01s\n",
      "    936     0.08407     0.10050    0.83648  0.97s\n",
      "    937     0.08370     0.10160    0.82382  0.95s\n",
      "    938     0.08471     0.10294    0.82292  1.00s\n",
      "    939     0.08393     0.10217    0.82143  0.96s\n",
      "    940     0.08387     0.09844    0.85199  0.93s\n",
      "    941     0.08344     0.10211    0.81710  0.93s\n",
      "    942     0.08394     0.10037    0.83633  0.96s\n",
      "    943     0.08408     0.09614    0.87453  1.00s\n",
      "    944     0.08494     0.10009    0.84859  0.96s\n",
      "    945     0.08401     0.10143    0.82827  0.96s\n",
      "    946     0.08349     0.09771    0.85451  0.97s\n",
      "    947     0.08345     0.09939    0.83966  0.97s\n",
      "    948     0.08485     0.10106    0.83961  0.94s\n",
      "    949     0.08436     0.10207    0.82650  1.00s\n",
      "    950     0.08472     0.09933    0.85289  0.96s\n",
      "    951     0.08414     0.10109    0.83229  0.97s\n",
      "    952     0.08395     0.10156    0.82659  0.95s\n",
      "    953     0.08367     0.09636    0.86829  1.02s\n",
      "    954     0.08306     0.09817    0.84606  0.92s\n",
      "    955     0.08392     0.10193    0.82337  0.97s\n",
      "    956     0.08392     0.10186    0.82385  0.94s\n",
      "    957     0.08439     0.10087    0.83665  0.99s\n",
      "    958     0.08366     0.10026    0.83449  0.98s\n",
      "    959     0.08357     0.09796    0.85310  0.98s\n",
      "    960     0.08298     0.10162    0.81660  0.94s\n",
      "    961     0.08487     0.10290    0.82472  0.99s\n",
      "    962     0.08340     0.09883    0.84390  0.97s\n",
      "    963     0.08409     0.10293    0.81705  0.95s\n",
      "    964     0.08400     0.10184    0.82488  0.97s\n",
      "    965     0.08357     0.09854    0.84807  0.95s\n",
      "    966     0.08385     0.10008    0.83779  0.99s\n",
      "    967     0.08373     0.10122    0.82719  0.97s\n",
      "    968     \u001b[36m0.08215\u001b[0m     0.10289    0.79838  0.97s\n",
      "    969     0.08372     0.09802    0.85411  0.97s\n",
      "    970     0.08296     0.10011    0.82874  0.99s\n",
      "    971     0.08351     0.09961    0.83834  0.97s\n",
      "    972     0.08289     0.10268    0.80723  0.91s\n",
      "    973     0.08358     0.10212    0.81843  0.94s\n",
      "    974     0.08309     0.10210    0.81388  0.99s\n",
      "    975     0.08316     0.09718    0.85579  0.96s\n",
      "    976     0.08298     0.09920    0.83645  0.97s\n",
      "    977     0.08414     0.10025    0.83933  1.02s\n",
      "    978     0.08382     0.10261    0.81689  0.97s\n",
      "    979     0.08308     0.09978    0.83262  0.98s\n",
      "    980     0.08345     0.09850    0.84724  1.04s\n",
      "    981     0.08373     0.09842    0.85076  1.03s\n",
      "    982     0.08385     0.10012    0.83745  0.93s\n",
      "    983     0.08335     0.10345    0.80570  0.93s\n",
      "    984     0.08218     0.09788    0.83960  0.92s\n",
      "    985     0.08347     0.09825    0.84950  0.97s\n",
      "    986     0.08283     0.09873    0.83896  0.93s\n",
      "    987     0.08348     0.09863    0.84641  0.91s\n",
      "    988     0.08372     0.10480    0.79882  0.98s\n",
      "    989     0.08397     0.10296    0.81557  0.97s\n",
      "    990     0.08287     0.10197    0.81271  0.92s\n",
      "    991     0.08316     0.09729    0.85471  0.98s\n",
      "    992     0.08367     0.09905    0.84472  0.98s\n",
      "    993     0.08353     0.09952    0.83933  0.97s\n",
      "    994     \u001b[36m0.08195\u001b[0m     0.10226    0.80139  0.95s\n",
      "    995     0.08198     0.10630    0.77124  0.97s\n",
      "    996     0.08395     0.09977    0.84142  1.00s\n",
      "    997     0.08317     0.10033    0.82895  0.95s\n",
      "    998     0.08315     0.09675    0.85943  0.94s\n",
      "    999     0.08341     0.10331    0.80739  1.01s\n",
      "   1000     0.08277     0.10118    0.81805  0.92s\n",
      "value\n",
      "   1001     0.08364     0.10044    0.83269  0.95s\n",
      "   1002     0.08346     0.10041    0.83121  0.98s\n",
      "   1003     0.08272     0.09895    0.83604  0.91s\n",
      "   1004     0.08285     0.10476    0.79085  0.96s\n",
      "   1005     0.08305     0.09772    0.84989  0.98s\n",
      "   1006     0.08378     0.10484    0.79909  0.96s\n",
      "   1007     0.08293     0.09918    0.83617  0.98s\n",
      "   1008     0.08381     0.10010    0.83723  0.95s\n",
      "   1009     0.08323     0.10197    0.81616  0.97s\n",
      "   1010     0.08291     0.10037    0.82606  0.97s\n",
      "   1011     0.08321     0.10056    0.82748  0.97s\n",
      "   1012     0.08278     0.10111    0.81875  1.00s\n",
      "   1013     0.08197     0.09846    0.83254  0.94s\n",
      "   1014     0.08230     0.10120    0.81325  0.96s\n",
      "   1015     \u001b[36m0.08188\u001b[0m     0.09808    0.83484  0.93s\n",
      "   1016     0.08276     0.10161    0.81450  0.96s\n",
      "   1017     0.08272     0.10201    0.81090  0.94s\n",
      "   1018     0.08273     0.09998    0.82745  1.02s\n",
      "   1019     0.08269     0.09903    0.83502  1.04s\n",
      "   1020     0.08262     0.09935    0.83160  0.97s\n",
      "   1021     0.08341     0.10018    0.83259  1.08s\n",
      "   1022     0.08259     0.10074    0.81986  1.00s\n",
      "   1023     0.08345     0.10102    0.82610  0.96s\n",
      "   1024     0.08332     0.09877    0.84358  0.94s\n",
      "   1025     0.08319     0.10093    0.82422  0.98s\n",
      "   1026     0.08354     0.10040    0.83205  0.94s\n",
      "   1027     0.08278     0.10275    0.80565  0.96s\n",
      "   1028     0.08273     0.10239    0.80803  0.97s\n",
      "   1029     0.08267     0.10263    0.80552  1.00s\n",
      "   1030     0.08353     0.09972    0.83762  1.03s\n",
      "   1031     0.08322     0.10284    0.80926  0.96s\n",
      "   1032     0.08230     0.09784    0.84115  0.98s\n",
      "   1033     0.08267     0.10027    0.82442  0.97s\n",
      "   1034     0.08288     0.09808    0.84498  1.00s\n",
      "   1035     0.08261     0.09911    0.83352  1.01s\n",
      "   1036     0.08195     0.09983    0.82090  0.97s\n",
      "   1037     0.08265     0.09974    0.82861  0.95s\n",
      "   1038     0.08278     0.09895    0.83659  0.96s\n",
      "   1039     0.08266     0.10545    0.78389  0.97s\n",
      "   1040     0.08306     0.10661    0.77916  0.97s\n",
      "   1041     0.08286     0.10054    0.82417  0.93s\n",
      "   1042     0.08204     0.10117    0.81083  0.93s\n",
      "   1043     0.08235     0.09988    0.82446  1.05s\n",
      "   1044     0.08266     0.10073    0.82063  1.09s\n",
      "   1045     0.08366     0.10469    0.79911  0.95s\n",
      "   1046     0.08288     0.10036    0.82580  0.98s\n",
      "   1047     0.08308     0.09877    0.84108  0.96s\n",
      "   1048     0.08315     0.10597    0.78472  1.12s\n",
      "   1049     0.08223     0.09661    0.85115  0.98s\n",
      "   1050     0.08274     0.09900    0.83570  0.98s\n",
      "   1051     0.08298     0.09638    0.86091  1.01s\n",
      "   1052     0.08281     0.09896    0.83688  1.02s\n",
      "   1053     0.08213     0.10299    0.79749  0.97s\n",
      "   1054     0.08227     0.09823    0.83757  0.96s\n",
      "   1055     0.08234     0.09951    0.82746  1.03s\n",
      "   1056     0.08264     0.10225    0.80819  1.01s\n",
      "   1057     \u001b[36m0.08167\u001b[0m     0.10186    0.80182  1.00s\n",
      "   1058     0.08241     0.10165    0.81078  1.00s\n",
      "   1059     0.08245     0.10200    0.80827  1.12s\n",
      "   1060     0.08220     0.09845    0.83496  1.06s\n",
      "   1061     0.08226     0.10431    0.78859  0.98s\n",
      "   1062     0.08237     0.10176    0.80939  0.96s\n",
      "   1063     0.08217     0.10148    0.80972  0.95s\n",
      "   1064     0.08323     0.10011    0.83138  1.09s\n",
      "   1065     0.08303     0.10028    0.82797  0.93s\n",
      "   1066     0.08236     0.10076    0.81738  0.95s\n",
      "   1067     0.08267     0.10481    0.78872  0.98s\n",
      "   1068     0.08197     0.09670    0.84759  0.99s\n",
      "   1069     0.08297     0.10255    0.80909  0.95s\n",
      "   1070     0.08253     0.10160    0.81234  1.01s\n",
      "   1071     0.08317     0.10098    0.82370  0.98s\n",
      "   1072     0.08244     0.10385    0.79383  1.05s\n",
      "   1073     0.08266     0.09996    0.82698  1.13s\n",
      "   1074     0.08302     0.10035    0.82729  1.07s\n",
      "   1075     0.08248     0.10130    0.81429  1.08s\n",
      "   1076     0.08190     0.09806    0.83521  1.09s\n",
      "   1077     0.08221     0.10054    0.81768  1.13s\n",
      "   1078     0.08288     0.10003    0.82860  1.08s\n",
      "   1079     0.08340     0.10467    0.79677  1.07s\n",
      "   1080     0.08232     0.10315    0.79808  1.09s\n",
      "   1081     0.08178     0.09813    0.83337  1.01s\n",
      "   1082     0.08278     0.10672    0.77567  0.93s\n",
      "   1083     0.08266     0.10226    0.80838  0.95s\n",
      "   1084     0.08267     0.10033    0.82399  0.94s\n",
      "   1085     0.08255     0.10185    0.81054  0.94s\n",
      "   1086     0.08280     0.10287    0.80492  0.92s\n",
      "   1087     0.08188     0.09781    0.83716  0.98s\n",
      "   1088     0.08248     0.09759    0.84521  0.98s\n",
      "   1089     0.08191     0.10149    0.80705  0.94s\n",
      "   1090     0.08279     0.09640    0.85884  0.93s\n",
      "   1091     0.08244     0.09745    0.84601  1.02s\n",
      "   1092     0.08236     0.10140    0.81225  0.97s\n",
      "   1093     \u001b[36m0.08154\u001b[0m     0.09991    0.81614  1.01s\n",
      "   1094     0.08292     0.09874    0.83981  0.93s\n",
      "   1095     0.08292     0.10174    0.81504  0.96s\n",
      "   1096     \u001b[36m0.08139\u001b[0m     0.10257    0.79349  0.98s\n",
      "   1097     0.08204     0.10106    0.81184  1.01s\n",
      "value\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-eabe72756c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'value'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print 'policy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     pol_net.fit(X,z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-fe3addbc593a>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mopen_xrdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxrdiag\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mordiag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mopen_ocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mocol\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mopen_orow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morow\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mopen_odiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0modiag\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdiag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mopen_ordiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mordiag\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrdiag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    print 'value'\n",
    "    net.fit(X_train,y_train) \n",
    "#     print 'policy'\n",
    "#     pol_net.fit(X,z)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 16180 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name    size\n",
      "---  ------  ------\n",
      "  0  in      1x6x7\n",
      "  1  conv    12x3x4\n",
      "  2  hid1    75\n",
      "  3  drop1   75\n",
      "  4  hid2    50\n",
      "  5  drop2   50\n",
      "  6  hid3    25\n",
      "  7  drop3   25\n",
      "  8  out     1\n",
      "\n",
      "  epoch    trn loss    val loss    trn/val  dur\n",
      "-------  ----------  ----------  ---------  -----\n",
      "      1     \u001b[36m0.25201\u001b[0m     \u001b[32m0.22446\u001b[0m    1.12272  0.65s\n",
      "      2     \u001b[36m0.23689\u001b[0m     \u001b[32m0.22347\u001b[0m    1.06007  0.64s\n",
      "      3     \u001b[36m0.23341\u001b[0m     \u001b[32m0.22282\u001b[0m    1.04756  0.59s\n",
      "      4     \u001b[36m0.23083\u001b[0m     \u001b[32m0.22236\u001b[0m    1.03810  0.59s\n",
      "      5     \u001b[36m0.23069\u001b[0m     \u001b[32m0.22205\u001b[0m    1.03892  0.60s\n",
      "      6     \u001b[36m0.22905\u001b[0m     \u001b[32m0.22171\u001b[0m    1.03312  0.58s\n",
      "      7     \u001b[36m0.22777\u001b[0m     \u001b[32m0.22136\u001b[0m    1.02897  0.58s\n",
      "      8     0.22789     \u001b[32m0.22114\u001b[0m    1.03053  0.58s\n",
      "      9     \u001b[36m0.22680\u001b[0m     \u001b[32m0.22080\u001b[0m    1.02717  0.56s\n",
      "     10     \u001b[36m0.22674\u001b[0m     \u001b[32m0.22047\u001b[0m    1.02847  0.58s\n",
      "     11     \u001b[36m0.22561\u001b[0m     \u001b[32m0.21999\u001b[0m    1.02552  0.58s\n",
      "     12     0.22611     \u001b[32m0.21945\u001b[0m    1.03035  0.59s\n",
      "     13     \u001b[36m0.22426\u001b[0m     \u001b[32m0.21878\u001b[0m    1.02503  0.58s\n",
      "     14     \u001b[36m0.22335\u001b[0m     \u001b[32m0.21792\u001b[0m    1.02491  0.58s\n",
      "     15     \u001b[36m0.22277\u001b[0m     \u001b[32m0.21719\u001b[0m    1.02567  0.59s\n",
      "     16     0.22364     \u001b[32m0.21646\u001b[0m    1.03320  0.56s\n",
      "     17     \u001b[36m0.22217\u001b[0m     \u001b[32m0.21535\u001b[0m    1.03169  0.57s\n",
      "     18     \u001b[36m0.22024\u001b[0m     \u001b[32m0.21425\u001b[0m    1.02796  0.59s\n",
      "     19     \u001b[36m0.22009\u001b[0m     \u001b[32m0.21302\u001b[0m    1.03318  0.56s\n",
      "     20     \u001b[36m0.21926\u001b[0m     \u001b[32m0.21165\u001b[0m    1.03594  0.59s\n",
      "     21     \u001b[36m0.21776\u001b[0m     \u001b[32m0.21010\u001b[0m    1.03643  0.59s\n",
      "     22     \u001b[36m0.21774\u001b[0m     \u001b[32m0.20858\u001b[0m    1.04393  0.60s\n",
      "     23     \u001b[36m0.21658\u001b[0m     \u001b[32m0.20690\u001b[0m    1.04677  0.61s\n",
      "     24     \u001b[36m0.21493\u001b[0m     \u001b[32m0.20503\u001b[0m    1.04826  0.61s\n",
      "     25     \u001b[36m0.21415\u001b[0m     \u001b[32m0.20356\u001b[0m    1.05201  0.61s\n",
      "     26     \u001b[36m0.21372\u001b[0m     \u001b[32m0.20197\u001b[0m    1.05820  0.60s\n",
      "     27     \u001b[36m0.21134\u001b[0m     \u001b[32m0.19961\u001b[0m    1.05877  0.64s\n",
      "     28     \u001b[36m0.20996\u001b[0m     \u001b[32m0.19780\u001b[0m    1.06148  0.60s\n",
      "     29     \u001b[36m0.20982\u001b[0m     \u001b[32m0.19591\u001b[0m    1.07103  0.61s\n",
      "     30     \u001b[36m0.20778\u001b[0m     \u001b[32m0.19383\u001b[0m    1.07196  0.60s\n",
      "     31     \u001b[36m0.20751\u001b[0m     \u001b[32m0.19205\u001b[0m    1.08051  0.59s\n",
      "     32     \u001b[36m0.20519\u001b[0m     \u001b[32m0.19031\u001b[0m    1.07819  0.64s\n",
      "     33     0.20542     \u001b[32m0.18841\u001b[0m    1.09032  0.60s\n",
      "     34     \u001b[36m0.20453\u001b[0m     \u001b[32m0.18688\u001b[0m    1.09442  0.61s\n",
      "     35     \u001b[36m0.20351\u001b[0m     \u001b[32m0.18541\u001b[0m    1.09761  0.60s\n",
      "     36     \u001b[36m0.20121\u001b[0m     \u001b[32m0.18411\u001b[0m    1.09289  0.57s\n",
      "     37     \u001b[36m0.19997\u001b[0m     \u001b[32m0.18276\u001b[0m    1.09413  0.59s\n",
      "     38     \u001b[36m0.19973\u001b[0m     \u001b[32m0.18142\u001b[0m    1.10094  0.59s\n",
      "     39     \u001b[36m0.19939\u001b[0m     \u001b[32m0.18042\u001b[0m    1.10513  0.59s\n",
      "     40     \u001b[36m0.19773\u001b[0m     \u001b[32m0.17924\u001b[0m    1.10319  0.58s\n",
      "     41     0.19808     \u001b[32m0.17850\u001b[0m    1.10973  0.59s\n",
      "     42     \u001b[36m0.19749\u001b[0m     \u001b[32m0.17795\u001b[0m    1.10978  0.59s\n",
      "     43     \u001b[36m0.19619\u001b[0m     \u001b[32m0.17712\u001b[0m    1.10771  0.59s\n",
      "     44     \u001b[36m0.19596\u001b[0m     \u001b[32m0.17639\u001b[0m    1.11095  0.60s\n",
      "     45     \u001b[36m0.19429\u001b[0m     \u001b[32m0.17566\u001b[0m    1.10607  0.61s\n",
      "     46     0.19480     \u001b[32m0.17519\u001b[0m    1.11199  0.60s\n",
      "     47     \u001b[36m0.19207\u001b[0m     \u001b[32m0.17433\u001b[0m    1.10176  0.58s\n",
      "     48     0.19233     \u001b[32m0.17349\u001b[0m    1.10856  0.58s\n",
      "     49     0.19235     \u001b[32m0.17291\u001b[0m    1.11242  0.60s\n",
      "     50     \u001b[36m0.18998\u001b[0m     \u001b[32m0.17235\u001b[0m    1.10231  0.59s\n",
      "     51     0.19080     \u001b[32m0.17208\u001b[0m    1.10875  0.59s\n",
      "     52     0.19082     \u001b[32m0.17161\u001b[0m    1.11193  0.60s\n",
      "     53     \u001b[36m0.18935\u001b[0m     \u001b[32m0.17121\u001b[0m    1.10598  0.59s\n",
      "     54     0.18950     \u001b[32m0.17069\u001b[0m    1.11018  0.59s\n",
      "     55     \u001b[36m0.18785\u001b[0m     \u001b[32m0.17004\u001b[0m    1.10479  0.61s\n",
      "     56     0.18864     \u001b[32m0.16951\u001b[0m    1.11286  0.60s\n",
      "     57     \u001b[36m0.18783\u001b[0m     \u001b[32m0.16934\u001b[0m    1.10921  0.58s\n",
      "     58     \u001b[36m0.18664\u001b[0m     \u001b[32m0.16883\u001b[0m    1.10553  0.59s\n",
      "     59     0.18726     \u001b[32m0.16854\u001b[0m    1.11106  0.60s\n",
      "     60     0.18680     \u001b[32m0.16819\u001b[0m    1.11061  0.59s\n",
      "     61     \u001b[36m0.18458\u001b[0m     \u001b[32m0.16761\u001b[0m    1.10124  0.59s\n",
      "     62     0.18682     \u001b[32m0.16760\u001b[0m    1.11464  0.62s\n",
      "     63     \u001b[36m0.18442\u001b[0m     \u001b[32m0.16715\u001b[0m    1.10333  0.61s\n",
      "     64     0.18504     \u001b[32m0.16675\u001b[0m    1.10965  0.60s\n",
      "     65     0.18601     \u001b[32m0.16655\u001b[0m    1.11683  0.68s\n",
      "     66     0.18498     \u001b[32m0.16639\u001b[0m    1.11167  0.60s\n",
      "     67     \u001b[36m0.18351\u001b[0m     \u001b[32m0.16583\u001b[0m    1.10667  0.60s\n",
      "     68     0.18423     \u001b[32m0.16560\u001b[0m    1.11248  0.58s\n",
      "     69     \u001b[36m0.18231\u001b[0m     \u001b[32m0.16519\u001b[0m    1.10358  0.61s\n",
      "     70     \u001b[36m0.18206\u001b[0m     \u001b[32m0.16471\u001b[0m    1.10532  0.61s\n",
      "     71     0.18344     \u001b[32m0.16471\u001b[0m    1.11372  0.61s\n",
      "     72     0.18356     \u001b[32m0.16439\u001b[0m    1.11666  0.65s\n",
      "     73     0.18307     \u001b[32m0.16426\u001b[0m    1.11453  0.68s\n",
      "     74     \u001b[36m0.18135\u001b[0m     \u001b[32m0.16381\u001b[0m    1.10711  0.57s\n",
      "     75     \u001b[36m0.18120\u001b[0m     \u001b[32m0.16359\u001b[0m    1.10760  0.58s\n",
      "     76     0.18204     0.16363    1.11250  0.58s\n",
      "     77     \u001b[36m0.18113\u001b[0m     \u001b[32m0.16355\u001b[0m    1.10753  0.57s\n",
      "     78     0.18117     \u001b[32m0.16332\u001b[0m    1.10929  0.57s\n",
      "     79     \u001b[36m0.17981\u001b[0m     \u001b[32m0.16288\u001b[0m    1.10396  0.57s\n",
      "     80     \u001b[36m0.17948\u001b[0m     \u001b[32m0.16260\u001b[0m    1.10376  0.59s\n",
      "     81     \u001b[36m0.17885\u001b[0m     \u001b[32m0.16234\u001b[0m    1.10165  0.56s\n",
      "     82     0.17957     \u001b[32m0.16209\u001b[0m    1.10783  0.57s\n",
      "     83     0.17979     \u001b[32m0.16203\u001b[0m    1.10961  0.56s\n",
      "     84     0.18010     \u001b[32m0.16198\u001b[0m    1.11189  0.58s\n",
      "     85     0.17941     \u001b[32m0.16189\u001b[0m    1.10822  0.53s\n",
      "     86     0.17911     \u001b[32m0.16163\u001b[0m    1.10813  0.55s\n",
      "     87     0.17888     \u001b[32m0.16149\u001b[0m    1.10769  0.57s\n",
      "     88     0.17912     \u001b[32m0.16125\u001b[0m    1.11084  0.58s\n",
      "     89     \u001b[36m0.17716\u001b[0m     \u001b[32m0.16105\u001b[0m    1.10000  0.66s\n",
      "     90     0.17886     \u001b[32m0.16085\u001b[0m    1.11197  0.66s\n",
      "     91     0.17809     \u001b[32m0.16069\u001b[0m    1.10826  0.64s\n",
      "     92     0.17747     \u001b[32m0.16063\u001b[0m    1.10489  0.65s\n",
      "     93     0.17788     \u001b[32m0.16056\u001b[0m    1.10782  0.57s\n",
      "     94     \u001b[36m0.17716\u001b[0m     \u001b[32m0.16036\u001b[0m    1.10476  0.58s\n",
      "     95     \u001b[36m0.17664\u001b[0m     \u001b[32m0.16027\u001b[0m    1.10218  0.57s\n",
      "     96     \u001b[36m0.17649\u001b[0m     \u001b[32m0.16018\u001b[0m    1.10181  0.65s\n",
      "     97     \u001b[36m0.17594\u001b[0m     \u001b[32m0.15997\u001b[0m    1.09987  0.59s\n",
      "     98     0.17650     \u001b[32m0.15991\u001b[0m    1.10369  0.62s\n",
      "     99     \u001b[36m0.17591\u001b[0m     \u001b[32m0.15983\u001b[0m    1.10059  0.71s\n",
      "    100     0.17644     \u001b[32m0.15968\u001b[0m    1.10497  0.62s\n",
      "    101     0.17653     \u001b[32m0.15962\u001b[0m    1.10593  0.81s\n",
      "    102     \u001b[36m0.17523\u001b[0m     \u001b[32m0.15953\u001b[0m    1.09841  0.63s\n",
      "    103     \u001b[36m0.17517\u001b[0m     \u001b[32m0.15925\u001b[0m    1.09998  0.71s\n",
      "    104     0.17617     0.15926    1.10618  0.61s\n",
      "    105     0.17611     \u001b[32m0.15923\u001b[0m    1.10602  0.61s\n",
      "    106     \u001b[36m0.17494\u001b[0m     \u001b[32m0.15909\u001b[0m    1.09964  0.65s\n",
      "    107     \u001b[36m0.17454\u001b[0m     \u001b[32m0.15896\u001b[0m    1.09804  0.62s\n",
      "    108     0.17476     \u001b[32m0.15877\u001b[0m    1.10068  0.59s\n",
      "    109     0.17492     \u001b[32m0.15871\u001b[0m    1.10214  0.60s\n",
      "    110     0.17525     0.15882    1.10348  0.59s\n",
      "    111     \u001b[36m0.17424\u001b[0m     \u001b[32m0.15846\u001b[0m    1.09959  0.57s\n",
      "    112     \u001b[36m0.17407\u001b[0m     \u001b[32m0.15845\u001b[0m    1.09857  0.56s\n",
      "    113     \u001b[36m0.17399\u001b[0m     \u001b[32m0.15833\u001b[0m    1.09889  0.57s\n",
      "    114     \u001b[36m0.17356\u001b[0m     \u001b[32m0.15832\u001b[0m    1.09623  0.57s\n",
      "    115     \u001b[36m0.17220\u001b[0m     \u001b[32m0.15799\u001b[0m    1.08996  0.60s\n",
      "    116     0.17290     \u001b[32m0.15795\u001b[0m    1.09464  0.57s\n",
      "    117     \u001b[36m0.17204\u001b[0m     \u001b[32m0.15783\u001b[0m    1.09003  0.61s\n",
      "    118     0.17275     \u001b[32m0.15775\u001b[0m    1.09509  0.57s\n",
      "    119     0.17263     \u001b[32m0.15767\u001b[0m    1.09483  0.54s\n",
      "    120     0.17308     \u001b[32m0.15762\u001b[0m    1.09806  0.57s\n",
      "    121     0.17290     \u001b[32m0.15762\u001b[0m    1.09696  0.58s\n",
      "    122     0.17334     \u001b[32m0.15757\u001b[0m    1.10012  0.56s\n",
      "    123     0.17301     \u001b[32m0.15751\u001b[0m    1.09838  0.55s\n",
      "    124     0.17261     \u001b[32m0.15728\u001b[0m    1.09744  0.53s\n",
      "    125     \u001b[36m0.17188\u001b[0m     \u001b[32m0.15719\u001b[0m    1.09345  0.55s\n",
      "    126     \u001b[36m0.17152\u001b[0m     0.15732    1.09026  0.62s\n",
      "    127     0.17220     0.15746    1.09365  0.55s\n",
      "    128     0.17159     0.15723    1.09131  0.56s\n",
      "    129     \u001b[36m0.17100\u001b[0m     \u001b[32m0.15713\u001b[0m    1.08827  0.58s\n",
      "    130     \u001b[36m0.17075\u001b[0m     \u001b[32m0.15701\u001b[0m    1.08746  0.55s\n",
      "    131     0.17100     \u001b[32m0.15692\u001b[0m    1.08970  0.57s\n",
      "    132     \u001b[36m0.17053\u001b[0m     \u001b[32m0.15691\u001b[0m    1.08676  0.57s\n",
      "    133     0.17124     \u001b[32m0.15690\u001b[0m    1.09139  0.57s\n",
      "    134     0.17108     \u001b[32m0.15688\u001b[0m    1.09049  0.54s\n",
      "    135     0.17206     \u001b[32m0.15677\u001b[0m    1.09750  0.55s\n",
      "    136     0.17181     \u001b[32m0.15672\u001b[0m    1.09629  0.59s\n",
      "    137     0.17102     \u001b[32m0.15671\u001b[0m    1.09134  0.57s\n",
      "    138     0.17082     \u001b[32m0.15654\u001b[0m    1.09128  0.56s\n",
      "    139     0.17083     \u001b[32m0.15652\u001b[0m    1.09137  0.56s\n",
      "    140     \u001b[36m0.17045\u001b[0m     \u001b[32m0.15636\u001b[0m    1.09008  0.59s\n",
      "    141     \u001b[36m0.16883\u001b[0m     \u001b[32m0.15614\u001b[0m    1.08130  0.55s\n",
      "    142     0.17024     0.15618    1.09005  0.60s\n",
      "    143     0.16996     0.15619    1.08820  0.60s\n",
      "    144     0.16925     \u001b[32m0.15597\u001b[0m    1.08515  0.56s\n",
      "    145     0.17018     0.15603    1.09070  0.55s\n",
      "    146     \u001b[36m0.16854\u001b[0m     \u001b[32m0.15592\u001b[0m    1.08094  0.56s\n",
      "    147     0.17044     \u001b[32m0.15589\u001b[0m    1.09333  0.56s\n",
      "    148     0.17017     \u001b[32m0.15589\u001b[0m    1.09161  0.56s\n",
      "    149     0.17088     0.15597    1.09560  0.56s\n",
      "    150     0.16940     \u001b[32m0.15585\u001b[0m    1.08695  0.58s\n",
      "    151     0.16982     \u001b[32m0.15585\u001b[0m    1.08965  0.58s\n",
      "    152     0.17027     0.15586    1.09243  0.55s\n",
      "    153     0.16866     \u001b[32m0.15560\u001b[0m    1.08396  0.57s\n",
      "    154     0.16942     \u001b[32m0.15547\u001b[0m    1.08970  0.57s\n",
      "    155     \u001b[36m0.16792\u001b[0m     0.15552    1.07968  0.57s\n",
      "    156     0.17049     0.15560    1.09567  0.54s\n",
      "    157     0.16897     \u001b[32m0.15539\u001b[0m    1.08734  0.59s\n",
      "    158     0.17003     0.15546    1.09372  0.59s\n",
      "    159     0.16882     0.15543    1.08613  0.55s\n",
      "    160     \u001b[36m0.16760\u001b[0m     \u001b[32m0.15539\u001b[0m    1.07857  0.59s\n",
      "    161     \u001b[36m0.16760\u001b[0m     \u001b[32m0.15518\u001b[0m    1.08002  0.56s\n",
      "    162     0.16908     \u001b[32m0.15505\u001b[0m    1.09044  0.58s\n",
      "    163     0.16806     \u001b[32m0.15499\u001b[0m    1.08434  0.57s\n",
      "    164     0.16834     0.15516    1.08494  0.59s\n",
      "    165     0.16953     0.15525    1.09195  0.56s\n",
      "    166     \u001b[36m0.16629\u001b[0m     \u001b[32m0.15499\u001b[0m    1.07291  0.55s\n",
      "    167     0.16840     \u001b[32m0.15492\u001b[0m    1.08697  0.56s\n",
      "    168     0.16803     \u001b[32m0.15478\u001b[0m    1.08558  0.58s\n",
      "    169     0.16775     \u001b[32m0.15463\u001b[0m    1.08486  0.57s\n",
      "    170     0.16712     0.15468    1.08040  0.60s\n",
      "    171     0.16820     \u001b[32m0.15461\u001b[0m    1.08790  0.58s\n",
      "    172     \u001b[36m0.16601\u001b[0m     \u001b[32m0.15445\u001b[0m    1.07489  0.59s\n",
      "    173     0.16787     \u001b[32m0.15437\u001b[0m    1.08746  0.56s\n",
      "    174     0.16633     \u001b[32m0.15436\u001b[0m    1.07756  0.58s\n",
      "    175     0.16702     0.15438    1.08187  0.56s\n",
      "    176     0.16761     \u001b[32m0.15430\u001b[0m    1.08626  0.58s\n",
      "    177     0.16747     0.15450    1.08391  0.59s\n",
      "    178     0.16694     0.15443    1.08103  0.57s\n",
      "    179     0.16773     0.15431    1.08699  0.58s\n",
      "    180     0.16758     \u001b[32m0.15423\u001b[0m    1.08652  0.55s\n",
      "    181     0.16760     \u001b[32m0.15422\u001b[0m    1.08681  0.56s\n",
      "    182     0.16671     0.15422    1.08099  0.61s\n",
      "    183     0.16724     \u001b[32m0.15415\u001b[0m    1.08492  0.58s\n",
      "    184     0.16616     \u001b[32m0.15405\u001b[0m    1.07863  0.56s\n",
      "    185     \u001b[36m0.16592\u001b[0m     \u001b[32m0.15391\u001b[0m    1.07801  0.56s\n",
      "    186     0.16694     0.15396    1.08432  0.57s\n",
      "    187     0.16628     \u001b[32m0.15388\u001b[0m    1.08059  0.56s\n",
      "    188     \u001b[36m0.16534\u001b[0m     \u001b[32m0.15379\u001b[0m    1.07509  0.57s\n",
      "    189     0.16626     \u001b[32m0.15360\u001b[0m    1.08243  0.58s\n",
      "    190     0.16607     \u001b[32m0.15358\u001b[0m    1.08130  0.55s\n",
      "    191     0.16557     \u001b[32m0.15353\u001b[0m    1.07843  0.55s\n",
      "    192     0.16628     \u001b[32m0.15352\u001b[0m    1.08310  0.57s\n",
      "    193     0.16701     0.15371    1.08653  0.58s\n",
      "    194     \u001b[36m0.16455\u001b[0m     0.15360    1.07133  0.59s\n",
      "    195     0.16613     0.15354    1.08201  0.56s\n",
      "    196     0.16603     \u001b[32m0.15351\u001b[0m    1.08155  0.57s\n",
      "    197     0.16561     0.15354    1.07863  0.55s\n",
      "    198     0.16578     0.15352    1.07984  0.56s\n",
      "    199     0.16624     \u001b[32m0.15344\u001b[0m    1.08340  0.57s\n",
      "    200     0.16510     \u001b[32m0.15323\u001b[0m    1.07747  0.57s\n",
      "    201     0.16475     \u001b[32m0.15303\u001b[0m    1.07660  0.56s\n",
      "    202     0.16491     \u001b[32m0.15302\u001b[0m    1.07765  0.57s\n",
      "    203     \u001b[36m0.16437\u001b[0m     0.15308    1.07370  0.58s\n",
      "    204     0.16594     0.15304    1.08435  0.58s\n",
      "    205     0.16593     \u001b[32m0.15294\u001b[0m    1.08490  0.58s\n",
      "    206     0.16508     \u001b[32m0.15280\u001b[0m    1.08034  0.58s\n",
      "    207     0.16527     0.15286    1.08117  0.60s\n",
      "    208     0.16580     \u001b[32m0.15271\u001b[0m    1.08571  0.60s\n",
      "    209     0.16478     0.15278    1.07853  0.59s\n",
      "    210     \u001b[36m0.16321\u001b[0m     \u001b[32m0.15253\u001b[0m    1.06996  0.59s\n",
      "    211     0.16371     0.15254    1.07328  0.58s\n",
      "    212     0.16477     \u001b[32m0.15248\u001b[0m    1.08062  0.57s\n",
      "    213     0.16405     0.15252    1.07564  0.61s\n",
      "    214     0.16441     \u001b[32m0.15231\u001b[0m    1.07946  0.56s\n",
      "    215     0.16382     \u001b[32m0.15228\u001b[0m    1.07574  0.56s\n",
      "    216     0.16384     0.15229    1.07587  0.58s\n",
      "    217     0.16449     \u001b[32m0.15225\u001b[0m    1.08039  0.57s\n",
      "    218     0.16420     \u001b[32m0.15215\u001b[0m    1.07921  0.59s\n",
      "    219     0.16359     \u001b[32m0.15211\u001b[0m    1.07546  0.58s\n",
      "    220     0.16556     0.15213    1.08828  0.58s\n",
      "    221     0.16379     \u001b[32m0.15197\u001b[0m    1.07775  0.58s\n",
      "    222     0.16425     \u001b[32m0.15196\u001b[0m    1.08087  0.59s\n",
      "    223     \u001b[36m0.16298\u001b[0m     \u001b[32m0.15190\u001b[0m    1.07290  0.64s\n",
      "    224     0.16390     0.15197    1.07849  0.67s\n",
      "    225     0.16353     \u001b[32m0.15185\u001b[0m    1.07693  0.67s\n",
      "    226     0.16330     \u001b[32m0.15175\u001b[0m    1.07609  0.61s\n",
      "    227     \u001b[36m0.16287\u001b[0m     \u001b[32m0.15163\u001b[0m    1.07411  0.61s\n",
      "    228     0.16301     \u001b[32m0.15148\u001b[0m    1.07618  0.64s\n",
      "    229     \u001b[36m0.16278\u001b[0m     \u001b[32m0.15131\u001b[0m    1.07583  0.67s\n",
      "    230     \u001b[36m0.16223\u001b[0m     \u001b[32m0.15119\u001b[0m    1.07301  0.59s\n",
      "    231     0.16228     0.15129    1.07261  0.59s\n",
      "    232     0.16317     0.15119    1.07923  0.59s\n",
      "    233     0.16295     \u001b[32m0.15117\u001b[0m    1.07796  0.71s\n",
      "    234     0.16264     \u001b[32m0.15115\u001b[0m    1.07601  0.60s\n",
      "    235     0.16282     \u001b[32m0.15098\u001b[0m    1.07843  0.69s\n",
      "    236     0.16320     0.15110    1.08009  0.67s\n",
      "    237     0.16226     0.15106    1.07415  0.63s\n",
      "    238     0.16365     \u001b[32m0.15097\u001b[0m    1.08402  0.58s\n",
      "    239     0.16234     \u001b[32m0.15081\u001b[0m    1.07647  0.57s\n",
      "    240     \u001b[36m0.16161\u001b[0m     \u001b[32m0.15072\u001b[0m    1.07222  0.55s\n",
      "    241     0.16279     0.15086    1.07910  0.62s\n",
      "    242     0.16214     0.15074    1.07563  0.59s\n",
      "    243     0.16196     \u001b[32m0.15069\u001b[0m    1.07482  0.59s\n",
      "    244     0.16237     \u001b[32m0.15053\u001b[0m    1.07868  0.57s\n",
      "    245     0.16241     \u001b[32m0.15039\u001b[0m    1.07990  0.58s\n",
      "    246     0.16292     0.15057    1.08197  0.58s\n",
      "    247     \u001b[36m0.16105\u001b[0m     0.15044    1.07056  0.58s\n",
      "    248     0.16154     \u001b[32m0.15027\u001b[0m    1.07499  0.59s\n",
      "    249     0.16214     \u001b[32m0.15025\u001b[0m    1.07912  0.55s\n",
      "    250     0.16171     \u001b[32m0.15005\u001b[0m    1.07768  0.58s\n",
      "    251     0.16361     0.15017    1.08948  0.59s\n",
      "    252     \u001b[36m0.16074\u001b[0m     0.15008    1.07104  0.57s\n",
      "    253     0.16200     0.15010    1.07927  0.59s\n",
      "    254     0.16213     \u001b[32m0.14998\u001b[0m    1.08104  0.68s\n",
      "    255     0.16211     0.15001    1.08064  0.61s\n",
      "    256     0.16141     \u001b[32m0.14997\u001b[0m    1.07626  0.61s\n",
      "    257     \u001b[36m0.16067\u001b[0m     \u001b[32m0.14974\u001b[0m    1.07298  0.60s\n",
      "    258     0.16147     0.14980    1.07788  0.62s\n",
      "    259     0.16159     0.14983    1.07851  0.62s\n",
      "    260     \u001b[36m0.16046\u001b[0m     0.14977    1.07140  0.61s\n",
      "    261     0.16056     \u001b[32m0.14967\u001b[0m    1.07281  0.61s\n",
      "    262     0.16164     0.14972    1.07964  0.59s\n",
      "    263     0.16079     \u001b[32m0.14946\u001b[0m    1.07586  0.62s\n",
      "    264     0.16060     \u001b[32m0.14939\u001b[0m    1.07500  0.59s\n",
      "    265     0.16176     0.14942    1.08258  0.58s\n",
      "    266     \u001b[36m0.15975\u001b[0m     \u001b[32m0.14938\u001b[0m    1.06944  0.62s\n",
      "    267     0.15996     \u001b[32m0.14930\u001b[0m    1.07141  0.61s\n",
      "    268     0.16013     \u001b[32m0.14922\u001b[0m    1.07307  0.57s\n",
      "    269     0.16046     \u001b[32m0.14918\u001b[0m    1.07562  0.62s\n",
      "    270     0.16049     \u001b[32m0.14911\u001b[0m    1.07631  0.57s\n",
      "    271     \u001b[36m0.15908\u001b[0m     \u001b[32m0.14896\u001b[0m    1.06792  0.59s\n",
      "    272     0.15979     0.14896    1.07267  0.61s\n",
      "    273     0.16032     \u001b[32m0.14891\u001b[0m    1.07661  0.60s\n",
      "    274     0.16048     0.14898    1.07719  0.60s\n",
      "    275     0.16099     0.14904    1.08017  0.56s\n",
      "    276     0.15978     \u001b[32m0.14891\u001b[0m    1.07304  0.58s\n",
      "    277     0.16045     \u001b[32m0.14884\u001b[0m    1.07801  0.60s\n",
      "    278     \u001b[36m0.15892\u001b[0m     \u001b[32m0.14864\u001b[0m    1.06919  0.62s\n",
      "    279     0.16017     0.14866    1.07743  0.65s\n",
      "    280     0.15988     \u001b[32m0.14849\u001b[0m    1.07667  0.60s\n",
      "    281     0.16022     \u001b[32m0.14841\u001b[0m    1.07954  0.59s\n",
      "    282     0.15932     0.14844    1.07329  0.57s\n",
      "    283     \u001b[36m0.15883\u001b[0m     \u001b[32m0.14838\u001b[0m    1.07044  0.58s\n",
      "    284     0.15895     \u001b[32m0.14831\u001b[0m    1.07177  0.61s\n",
      "    285     0.16001     0.14834    1.07866  0.61s\n",
      "    286     0.15967     \u001b[32m0.14828\u001b[0m    1.07678  0.55s\n",
      "    287     0.15891     \u001b[32m0.14815\u001b[0m    1.07268  0.56s\n",
      "    288     \u001b[36m0.15862\u001b[0m     \u001b[32m0.14807\u001b[0m    1.07126  0.61s\n",
      "    289     0.15863     \u001b[32m0.14796\u001b[0m    1.07213  0.59s\n",
      "    290     0.15948     0.14803    1.07734  0.59s\n",
      "    291     \u001b[36m0.15827\u001b[0m     \u001b[32m0.14789\u001b[0m    1.07023  0.58s\n",
      "    292     0.15832     0.14790    1.07047  0.59s\n",
      "    293     \u001b[36m0.15794\u001b[0m     \u001b[32m0.14763\u001b[0m    1.06984  0.60s\n",
      "    294     0.15936     0.14769    1.07896  0.58s\n",
      "    295     0.15917     0.14774    1.07736  0.68s\n",
      "    296     0.15815     \u001b[32m0.14759\u001b[0m    1.07154  0.66s\n",
      "    297     0.15890     \u001b[32m0.14757\u001b[0m    1.07678  0.64s\n",
      "    298     0.15904     0.14763    1.07732  0.63s\n",
      "    299     0.15819     \u001b[32m0.14747\u001b[0m    1.07263  0.69s\n",
      "    300     0.15980     \u001b[32m0.14739\u001b[0m    1.08418  0.66s\n",
      "    301     0.15821     \u001b[32m0.14739\u001b[0m    1.07345  0.58s\n",
      "    302     0.15880     \u001b[32m0.14728\u001b[0m    1.07820  0.63s\n",
      "    303     \u001b[36m0.15705\u001b[0m     \u001b[32m0.14716\u001b[0m    1.06717  0.67s\n",
      "    304     0.15904     \u001b[32m0.14715\u001b[0m    1.08080  0.66s\n",
      "    305     0.15903     \u001b[32m0.14711\u001b[0m    1.08106  0.61s\n",
      "    306     0.15870     \u001b[32m0.14706\u001b[0m    1.07912  0.57s\n",
      "    307     0.15952     0.14708    1.08457  0.55s\n",
      "    308     0.15835     0.14708    1.07664  0.60s\n",
      "    309     0.15735     \u001b[32m0.14694\u001b[0m    1.07084  0.56s\n",
      "    310     0.15740     \u001b[32m0.14682\u001b[0m    1.07205  0.60s\n",
      "    311     \u001b[36m0.15692\u001b[0m     \u001b[32m0.14680\u001b[0m    1.06890  0.57s\n",
      "    312     \u001b[36m0.15657\u001b[0m     \u001b[32m0.14672\u001b[0m    1.06715  0.58s\n",
      "    313     0.15851     0.14676    1.08008  0.62s\n",
      "    314     0.15798     \u001b[32m0.14669\u001b[0m    1.07696  0.60s\n",
      "    315     0.15784     \u001b[32m0.14656\u001b[0m    1.07699  0.62s\n",
      "    316     0.15798     0.14656    1.07795  0.65s\n",
      "    317     0.15685     0.14662    1.06975  0.58s\n",
      "    318     0.15736     \u001b[32m0.14651\u001b[0m    1.07406  0.58s\n",
      "    319     \u001b[36m0.15637\u001b[0m     \u001b[32m0.14640\u001b[0m    1.06809  0.60s\n",
      "    320     0.15744     0.14646    1.07497  0.61s\n",
      "    321     0.15722     \u001b[32m0.14634\u001b[0m    1.07433  0.65s\n",
      "    322     0.15765     \u001b[32m0.14628\u001b[0m    1.07777  0.61s\n",
      "    323     \u001b[36m0.15610\u001b[0m     \u001b[32m0.14616\u001b[0m    1.06798  0.63s\n",
      "    324     0.15645     \u001b[32m0.14615\u001b[0m    1.07048  0.69s\n",
      "    325     0.15736     \u001b[32m0.14611\u001b[0m    1.07695  0.92s\n",
      "    326     0.15649     \u001b[32m0.14605\u001b[0m    1.07152  1.01s\n",
      "    327     0.15679     \u001b[32m0.14592\u001b[0m    1.07451  0.67s\n",
      "    328     0.15621     \u001b[32m0.14588\u001b[0m    1.07086  0.65s\n",
      "    329     \u001b[36m0.15590\u001b[0m     \u001b[32m0.14578\u001b[0m    1.06939  0.63s\n",
      "    330     0.15718     0.14581    1.07798  0.64s\n",
      "    331     0.15656     \u001b[32m0.14568\u001b[0m    1.07468  0.63s\n",
      "    332     0.15641     0.14569    1.07358  0.60s\n",
      "    333     0.15679     0.14577    1.07554  0.67s\n",
      "    334     \u001b[36m0.15583\u001b[0m     \u001b[32m0.14561\u001b[0m    1.07015  0.63s\n",
      "    335     0.15634     \u001b[32m0.14547\u001b[0m    1.07469  0.60s\n",
      "    336     0.15609     0.14552    1.07266  0.59s\n",
      "    337     0.15594     0.14549    1.07185  0.61s\n",
      "    338     0.15748     0.14550    1.08232  0.62s\n",
      "    339     0.15641     0.14548    1.07515  0.61s\n",
      "    340     0.15653     \u001b[32m0.14535\u001b[0m    1.07692  0.61s\n",
      "    341     0.15629     0.14543    1.07468  0.62s\n",
      "    342     0.15678     \u001b[32m0.14526\u001b[0m    1.07930  0.58s\n",
      "    343     0.15672     \u001b[32m0.14525\u001b[0m    1.07901  0.60s\n",
      "    344     0.15655     0.14531    1.07736  0.61s\n",
      "    345     0.15583     \u001b[32m0.14516\u001b[0m    1.07351  0.60s\n",
      "    346     \u001b[36m0.15504\u001b[0m     \u001b[32m0.14499\u001b[0m    1.06933  0.59s\n",
      "    347     0.15508     \u001b[32m0.14499\u001b[0m    1.06962  0.59s\n",
      "    348     \u001b[36m0.15492\u001b[0m     0.14501    1.06834  0.59s\n",
      "    349     0.15659     \u001b[32m0.14498\u001b[0m    1.08004  0.60s\n",
      "    350     0.15581     0.14499    1.07467  0.60s\n",
      "    351     0.15507     \u001b[32m0.14491\u001b[0m    1.07013  0.59s\n",
      "    352     0.15501     \u001b[32m0.14470\u001b[0m    1.07123  0.59s\n",
      "    353     0.15609     0.14482    1.07781  0.62s\n",
      "    354     0.15614     0.14481    1.07825  0.59s\n",
      "    355     \u001b[36m0.15442\u001b[0m     \u001b[32m0.14461\u001b[0m    1.06782  0.58s\n",
      "    356     0.15539     \u001b[32m0.14448\u001b[0m    1.07553  0.59s\n",
      "    357     0.15449     0.14454    1.06884  0.60s\n",
      "    358     0.15511     0.14462    1.07250  0.59s\n",
      "    359     0.15461     \u001b[32m0.14439\u001b[0m    1.07078  0.61s\n",
      "    360     0.15635     0.14448    1.08216  0.58s\n",
      "    361     0.15482     \u001b[32m0.14430\u001b[0m    1.07293  0.60s\n",
      "    362     0.15443     \u001b[32m0.14427\u001b[0m    1.07043  0.62s\n",
      "    363     \u001b[36m0.15319\u001b[0m     \u001b[32m0.14414\u001b[0m    1.06282  0.59s\n",
      "    364     0.15441     0.14430    1.07005  0.63s\n",
      "    365     0.15557     0.14419    1.07896  0.62s\n",
      "    366     0.15516     \u001b[32m0.14411\u001b[0m    1.07666  0.59s\n",
      "    367     0.15528     0.14414    1.07731  0.62s\n",
      "    368     0.15487     \u001b[32m0.14402\u001b[0m    1.07529  0.59s\n",
      "    369     0.15470     0.14403    1.07404  0.60s\n",
      "    370     0.15549     0.14402    1.07963  0.62s\n",
      "    371     0.15518     0.14416    1.07647  0.60s\n",
      "    372     \u001b[36m0.15306\u001b[0m     \u001b[32m0.14394\u001b[0m    1.06337  0.61s\n",
      "    373     0.15460     \u001b[32m0.14386\u001b[0m    1.07469  0.61s\n",
      "    374     0.15447     \u001b[32m0.14378\u001b[0m    1.07435  0.59s\n",
      "    375     0.15453     0.14381    1.07456  0.59s\n",
      "    376     0.15339     \u001b[32m0.14364\u001b[0m    1.06782  0.60s\n",
      "    377     0.15467     \u001b[32m0.14361\u001b[0m    1.07700  0.61s\n",
      "    378     0.15398     \u001b[32m0.14351\u001b[0m    1.07295  0.60s\n",
      "    379     \u001b[36m0.15298\u001b[0m     \u001b[32m0.14344\u001b[0m    1.06649  0.58s\n",
      "    380     \u001b[36m0.15177\u001b[0m     \u001b[32m0.14325\u001b[0m    1.05949  0.60s\n",
      "    381     0.15467     0.14326    1.07963  0.61s\n",
      "    382     0.15256     \u001b[32m0.14321\u001b[0m    1.06529  0.61s\n",
      "    383     0.15399     0.14331    1.07456  0.58s\n",
      "    384     0.15349     0.14321    1.07179  0.59s\n",
      "    385     0.15433     \u001b[32m0.14315\u001b[0m    1.07809  0.62s\n",
      "    386     0.15397     \u001b[32m0.14311\u001b[0m    1.07590  0.61s\n",
      "    387     0.15302     \u001b[32m0.14298\u001b[0m    1.07017  0.58s\n",
      "    388     0.15228     \u001b[32m0.14289\u001b[0m    1.06573  0.60s\n",
      "    389     0.15327     0.14303    1.07156  0.63s\n",
      "    390     \u001b[36m0.15116\u001b[0m     \u001b[32m0.14288\u001b[0m    1.05798  0.62s\n",
      "    391     0.15139     \u001b[32m0.14278\u001b[0m    1.06027  0.57s\n",
      "    392     0.15253     0.14286    1.06767  0.61s\n",
      "    393     0.15247     \u001b[32m0.14260\u001b[0m    1.06918  0.60s\n",
      "    394     0.15266     \u001b[32m0.14260\u001b[0m    1.07057  0.59s\n",
      "    395     0.15371     0.14272    1.07705  0.60s\n",
      "    396     0.15310     \u001b[32m0.14241\u001b[0m    1.07509  0.59s\n",
      "    397     0.15217     \u001b[32m0.14239\u001b[0m    1.06865  0.61s\n",
      "    398     0.15239     \u001b[32m0.14239\u001b[0m    1.07021  0.58s\n",
      "    399     0.15310     \u001b[32m0.14235\u001b[0m    1.07549  0.59s\n",
      "    400     0.15256     \u001b[32m0.14233\u001b[0m    1.07185  0.61s\n",
      "    401     0.15228     \u001b[32m0.14228\u001b[0m    1.07027  0.62s\n",
      "    402     0.15270     \u001b[32m0.14222\u001b[0m    1.07372  0.61s\n",
      "    403     0.15345     0.14227    1.07862  0.60s\n",
      "    404     0.15277     0.14233    1.07330  0.58s\n",
      "    405     0.15119     \u001b[32m0.14212\u001b[0m    1.06385  0.59s\n",
      "    406     0.15204     \u001b[32m0.14205\u001b[0m    1.07036  0.62s\n",
      "    407     \u001b[36m0.15070\u001b[0m     \u001b[32m0.14189\u001b[0m    1.06209  0.60s\n",
      "    408     0.15094     0.14198    1.06314  0.62s\n",
      "    409     0.15265     0.14203    1.07480  0.60s\n",
      "    410     0.15188     \u001b[32m0.14188\u001b[0m    1.07050  0.61s\n",
      "    411     0.15225     \u001b[32m0.14179\u001b[0m    1.07375  0.59s\n",
      "    412     0.15149     0.14180    1.06830  0.58s\n",
      "    413     0.15157     \u001b[32m0.14167\u001b[0m    1.06989  0.59s\n",
      "    414     0.15173     \u001b[32m0.14159\u001b[0m    1.07161  0.60s\n",
      "    415     0.15096     0.14161    1.06608  0.59s\n",
      "    416     0.15099     \u001b[32m0.14151\u001b[0m    1.06698  0.60s\n",
      "    417     \u001b[36m0.14962\u001b[0m     \u001b[32m0.14144\u001b[0m    1.05782  0.62s\n",
      "    418     0.14982     \u001b[32m0.14135\u001b[0m    1.05991  0.61s\n",
      "    419     0.15134     0.14138    1.07044  0.62s\n",
      "    420     0.15083     \u001b[32m0.14130\u001b[0m    1.06739  0.60s\n",
      "    421     0.15080     \u001b[32m0.14123\u001b[0m    1.06780  0.62s\n",
      "    422     0.15116     0.14137    1.06918  0.60s\n",
      "    423     0.15125     0.14145    1.06925  0.60s\n",
      "    424     0.14968     \u001b[32m0.14119\u001b[0m    1.06012  0.60s\n",
      "    425     0.15040     0.14125    1.06475  0.60s\n",
      "    426     0.14997     \u001b[32m0.14109\u001b[0m    1.06292  0.62s\n",
      "    427     \u001b[36m0.14875\u001b[0m     \u001b[32m0.14094\u001b[0m    1.05545  0.61s\n",
      "    428     0.15032     0.14096    1.06645  0.63s\n",
      "    429     0.15069     0.14096    1.06903  0.66s\n",
      "    430     0.14989     0.14100    1.06304  0.65s\n",
      "    431     0.15026     \u001b[32m0.14081\u001b[0m    1.06716  0.62s\n",
      "    432     0.14995     \u001b[32m0.14078\u001b[0m    1.06513  0.61s\n",
      "    433     0.15123     0.14088    1.07345  0.63s\n",
      "    434     0.15075     0.14087    1.07016  0.59s\n",
      "    435     0.15097     \u001b[32m0.14076\u001b[0m    1.07256  0.58s\n",
      "    436     0.15033     \u001b[32m0.14061\u001b[0m    1.06912  0.61s\n",
      "    437     0.14950     \u001b[32m0.14044\u001b[0m    1.06451  0.60s\n",
      "    438     0.14932     0.14049    1.06284  0.59s\n",
      "    439     0.14993     0.14047    1.06740  0.57s\n",
      "    440     0.14954     0.14046    1.06471  0.59s\n",
      "    441     0.15100     \u001b[32m0.14028\u001b[0m    1.07640  0.60s\n",
      "    442     0.15057     0.14033    1.07298  0.62s\n",
      "    443     0.14925     \u001b[32m0.14023\u001b[0m    1.06433  0.59s\n",
      "    444     0.14999     0.14037    1.06850  0.61s\n",
      "    445     0.14913     \u001b[32m0.14022\u001b[0m    1.06357  0.60s\n",
      "    446     \u001b[36m0.14839\u001b[0m     0.14023    1.05824  0.60s\n",
      "    447     0.14842     0.14023    1.05840  0.59s\n",
      "    448     0.14942     \u001b[32m0.14020\u001b[0m    1.06578  0.59s\n",
      "    449     0.14850     \u001b[32m0.14011\u001b[0m    1.05989  0.61s\n",
      "    450     0.14940     \u001b[32m0.14006\u001b[0m    1.06670  0.61s\n",
      "    451     0.14855     \u001b[32m0.13990\u001b[0m    1.06183  0.59s\n",
      "    452     0.14850     0.14001    1.06066  0.60s\n",
      "    453     \u001b[36m0.14799\u001b[0m     \u001b[32m0.13990\u001b[0m    1.05782  0.60s\n",
      "    454     0.14980     \u001b[32m0.13988\u001b[0m    1.07092  0.60s\n",
      "    455     0.14944     \u001b[32m0.13988\u001b[0m    1.06834  0.59s\n",
      "    456     \u001b[36m0.14798\u001b[0m     \u001b[32m0.13971\u001b[0m    1.05923  0.61s\n",
      "    457     0.14880     \u001b[32m0.13966\u001b[0m    1.06542  0.60s\n",
      "    458     0.14907     \u001b[32m0.13965\u001b[0m    1.06744  0.62s\n",
      "    459     \u001b[36m0.14789\u001b[0m     0.13970    1.05863  0.60s\n",
      "    460     0.14879     0.13967    1.06524  0.60s\n",
      "    461     0.14817     \u001b[32m0.13959\u001b[0m    1.06151  0.61s\n",
      "    462     0.14924     0.13962    1.06895  0.60s\n",
      "    463     0.14846     0.13962    1.06331  0.61s\n",
      "    464     \u001b[36m0.14775\u001b[0m     0.13963    1.05814  0.60s\n",
      "    465     0.14838     \u001b[32m0.13955\u001b[0m    1.06322  0.60s\n",
      "    466     0.14848     \u001b[32m0.13947\u001b[0m    1.06465  0.59s\n",
      "    467     \u001b[36m0.14770\u001b[0m     \u001b[32m0.13929\u001b[0m    1.06036  0.54s\n",
      "    468     \u001b[36m0.14719\u001b[0m     \u001b[32m0.13923\u001b[0m    1.05719  0.56s\n",
      "    469     0.14753     0.13927    1.05927  0.59s\n",
      "    470     0.14800     0.13930    1.06246  0.55s\n",
      "    471     \u001b[36m0.14704\u001b[0m     \u001b[32m0.13909\u001b[0m    1.05712  0.54s\n",
      "    472     0.14771     \u001b[32m0.13901\u001b[0m    1.06258  0.56s\n",
      "    473     \u001b[36m0.14654\u001b[0m     \u001b[32m0.13897\u001b[0m    1.05447  0.54s\n",
      "    474     \u001b[36m0.14602\u001b[0m     \u001b[32m0.13873\u001b[0m    1.05253  0.58s\n",
      "    475     0.14710     0.13877    1.06001  0.59s\n",
      "    476     0.14815     0.13887    1.06686  0.60s\n",
      "    477     0.14609     0.13875    1.05291  0.57s\n",
      "    478     0.14698     0.13878    1.05910  0.63s\n",
      "    479     0.14800     \u001b[32m0.13872\u001b[0m    1.06690  0.62s\n",
      "    480     0.14763     0.13873    1.06421  0.61s\n",
      "    481     \u001b[36m0.14592\u001b[0m     \u001b[32m0.13871\u001b[0m    1.05204  0.59s\n",
      "    482     0.14723     \u001b[32m0.13856\u001b[0m    1.06258  0.62s\n",
      "    483     0.14728     0.13865    1.06226  0.61s\n",
      "    484     \u001b[36m0.14560\u001b[0m     \u001b[32m0.13836\u001b[0m    1.05233  0.65s\n",
      "    485     0.14693     0.13842    1.06147  0.59s\n",
      "    486     0.14732     \u001b[32m0.13830\u001b[0m    1.06518  0.62s\n",
      "    487     0.14606     0.13832    1.05594  0.59s\n",
      "    488     0.14655     \u001b[32m0.13830\u001b[0m    1.05963  0.63s\n",
      "    489     0.14682     0.13849    1.06014  0.62s\n",
      "    490     \u001b[36m0.14528\u001b[0m     0.13832    1.05034  0.64s\n",
      "    491     0.14609     \u001b[32m0.13822\u001b[0m    1.05695  0.63s\n",
      "    492     0.14602     \u001b[32m0.13812\u001b[0m    1.05721  0.67s\n",
      "    493     0.14595     \u001b[32m0.13810\u001b[0m    1.05683  0.71s\n",
      "    494     0.14669     0.13815    1.06185  0.63s\n",
      "    495     \u001b[36m0.14518\u001b[0m     \u001b[32m0.13801\u001b[0m    1.05199  0.70s\n",
      "    496     \u001b[36m0.14424\u001b[0m     \u001b[32m0.13799\u001b[0m    1.04526  0.62s\n",
      "    497     0.14502     \u001b[32m0.13784\u001b[0m    1.05209  0.61s\n",
      "    498     0.14488     0.13788    1.05076  0.62s\n",
      "    499     0.14587     \u001b[32m0.13778\u001b[0m    1.05870  0.60s\n",
      "    500     0.14549     0.13784    1.05553  0.61s\n",
      "    501     0.14585     \u001b[32m0.13768\u001b[0m    1.05928  0.60s\n",
      "    502     0.14599     \u001b[32m0.13766\u001b[0m    1.06056  0.59s\n",
      "    503     0.14547     \u001b[32m0.13762\u001b[0m    1.05705  0.62s\n",
      "    504     0.14625     \u001b[32m0.13761\u001b[0m    1.06283  0.61s\n",
      "    505     0.14485     0.13763    1.05243  0.62s\n",
      "    506     0.14452     \u001b[32m0.13748\u001b[0m    1.05123  0.62s\n",
      "    507     0.14492     0.13752    1.05381  0.63s\n",
      "    508     0.14488     \u001b[32m0.13746\u001b[0m    1.05401  0.60s\n",
      "    509     0.14494     \u001b[32m0.13724\u001b[0m    1.05609  0.61s\n",
      "    510     \u001b[36m0.14341\u001b[0m     \u001b[32m0.13723\u001b[0m    1.04503  0.62s\n",
      "    511     0.14513     \u001b[32m0.13707\u001b[0m    1.05880  0.60s\n",
      "    512     0.14546     0.13713    1.06076  0.60s\n",
      "    513     0.14422     0.13707    1.05217  0.62s\n",
      "    514     0.14699     0.13723    1.07112  0.60s\n",
      "    515     0.14542     0.13709    1.06076  0.59s\n",
      "    516     0.14487     \u001b[32m0.13704\u001b[0m    1.05716  0.59s\n",
      "    517     0.14468     \u001b[32m0.13699\u001b[0m    1.05610  0.60s\n",
      "    518     0.14459     \u001b[32m0.13692\u001b[0m    1.05604  0.60s\n",
      "    519     0.14430     0.13698    1.05338  0.62s\n",
      "    520     0.14479     0.13696    1.05721  0.73s\n",
      "    521     0.14398     \u001b[32m0.13688\u001b[0m    1.05192  0.71s\n",
      "    522     0.14417     0.13688    1.05327  0.86s\n",
      "    523     0.14381     0.13702    1.04955  0.70s\n",
      "    524     0.14415     \u001b[32m0.13684\u001b[0m    1.05347  0.67s\n",
      "    525     0.14350     \u001b[32m0.13670\u001b[0m    1.04980  0.69s\n",
      "    526     0.14444     \u001b[32m0.13660\u001b[0m    1.05735  0.69s\n",
      "    527     0.14455     0.13662    1.05803  0.69s\n",
      "    528     0.14415     \u001b[32m0.13657\u001b[0m    1.05547  0.69s\n",
      "    529     0.14347     \u001b[32m0.13651\u001b[0m    1.05099  0.66s\n",
      "    530     \u001b[36m0.14240\u001b[0m     \u001b[32m0.13646\u001b[0m    1.04349  0.64s\n",
      "    531     0.14406     0.13649    1.05549  0.67s\n",
      "    532     0.14423     0.13647    1.05687  0.66s\n",
      "    533     0.14346     \u001b[32m0.13624\u001b[0m    1.05295  0.66s\n",
      "    534     0.14378     0.13626    1.05519  0.67s\n",
      "    535     0.14432     0.13636    1.05836  0.66s\n",
      "    536     \u001b[36m0.14177\u001b[0m     \u001b[32m0.13614\u001b[0m    1.04136  0.65s\n",
      "    537     0.14403     0.13627    1.05698  0.67s\n",
      "    538     0.14343     0.13626    1.05260  0.66s\n",
      "    539     0.14421     0.13623    1.05858  0.68s\n",
      "    540     0.14381     \u001b[32m0.13600\u001b[0m    1.05742  0.69s\n",
      "    541     0.14312     \u001b[32m0.13596\u001b[0m    1.05269  0.78s\n",
      "    542     0.14304     0.13606    1.05132  0.73s\n",
      "    543     0.14295     \u001b[32m0.13584\u001b[0m    1.05232  0.71s\n",
      "    544     0.14208     \u001b[32m0.13582\u001b[0m    1.04611  0.68s\n",
      "    545     0.14288     0.13583    1.05197  0.70s\n",
      "    546     0.14284     \u001b[32m0.13576\u001b[0m    1.05214  0.68s\n",
      "    547     0.14249     \u001b[32m0.13569\u001b[0m    1.05011  0.67s\n",
      "    548     0.14259     0.13582    1.04989  0.70s\n",
      "    549     0.14330     \u001b[32m0.13566\u001b[0m    1.05631  0.67s\n",
      "    550     0.14249     \u001b[32m0.13555\u001b[0m    1.05123  0.65s\n",
      "    551     0.14401     0.13567    1.06150  0.68s\n",
      "    552     0.14310     0.13566    1.05483  0.66s\n",
      "    553     0.14203     0.13564    1.04714  0.69s\n",
      "    554     \u001b[36m0.14176\u001b[0m     \u001b[32m0.13548\u001b[0m    1.04636  0.66s\n",
      "    555     \u001b[36m0.14157\u001b[0m     0.13563    1.04378  0.67s\n",
      "    556     0.14298     \u001b[32m0.13547\u001b[0m    1.05544  0.65s\n",
      "    557     0.14167     \u001b[32m0.13536\u001b[0m    1.04665  0.65s\n",
      "    558     \u001b[36m0.14140\u001b[0m     \u001b[32m0.13530\u001b[0m    1.04515  0.67s\n",
      "    559     0.14188     0.13557    1.04654  0.70s\n",
      "    560     0.14294     0.13531    1.05640  0.68s\n",
      "    561     0.14213     0.13531    1.05045  0.67s\n",
      "    562     0.14318     0.13545    1.05708  0.70s\n",
      "    563     0.14188     0.13533    1.04836  0.71s\n",
      "    564     0.14291     \u001b[32m0.13529\u001b[0m    1.05631  0.68s\n",
      "    565     0.14151     \u001b[32m0.13529\u001b[0m    1.04595  0.68s\n",
      "    566     0.14151     \u001b[32m0.13529\u001b[0m    1.04596  0.68s\n",
      "    567     0.14151     \u001b[32m0.13525\u001b[0m    1.04630  0.69s\n",
      "    568     0.14195     \u001b[32m0.13511\u001b[0m    1.05061  0.67s\n",
      "    569     0.14158     0.13518    1.04740  0.67s\n",
      "    570     \u001b[36m0.14044\u001b[0m     \u001b[32m0.13494\u001b[0m    1.04069  0.66s\n",
      "    571     0.14190     \u001b[32m0.13481\u001b[0m    1.05263  0.65s\n",
      "    572     0.14047     \u001b[32m0.13476\u001b[0m    1.04238  0.67s\n",
      "    573     0.14182     \u001b[32m0.13471\u001b[0m    1.05276  0.66s\n",
      "    574     0.14110     0.13481    1.04664  0.68s\n",
      "    575     0.14158     0.13479    1.05038  0.68s\n",
      "    576     0.14244     0.13472    1.05732  0.67s\n",
      "    577     0.14204     \u001b[32m0.13463\u001b[0m    1.05501  0.66s\n",
      "    578     \u001b[36m0.13992\u001b[0m     \u001b[32m0.13455\u001b[0m    1.03991  0.65s\n",
      "    579     0.14033     \u001b[32m0.13451\u001b[0m    1.04331  0.68s\n",
      "    580     0.14048     \u001b[32m0.13449\u001b[0m    1.04454  0.66s\n",
      "    581     0.14007     0.13457    1.04093  0.68s\n",
      "    582     0.14039     0.13454    1.04350  0.72s\n",
      "    583     0.13992     0.13456    1.03984  0.74s\n",
      "    584     0.14130     0.13450    1.05057  0.71s\n",
      "    585     0.14113     0.13456    1.04882  0.74s\n",
      "    586     0.14123     0.13452    1.04984  0.64s\n",
      "    587     0.14069     \u001b[32m0.13442\u001b[0m    1.04666  0.66s\n",
      "    588     \u001b[36m0.13952\u001b[0m     \u001b[32m0.13427\u001b[0m    1.03916  0.64s\n",
      "    589     0.13974     \u001b[32m0.13423\u001b[0m    1.04106  0.66s\n",
      "    590     0.14000     \u001b[32m0.13418\u001b[0m    1.04338  0.71s\n",
      "    591     0.14034     \u001b[32m0.13416\u001b[0m    1.04609  0.67s\n",
      "    592     0.14034     \u001b[32m0.13403\u001b[0m    1.04712  0.67s\n",
      "    593     0.14027     0.13416    1.04557  0.67s\n",
      "    594     0.13963     0.13421    1.04045  0.66s\n",
      "    595     0.14089     0.13424    1.04954  0.66s\n",
      "    596     \u001b[36m0.13925\u001b[0m     0.13416    1.03794  0.71s\n",
      "    597     0.13930     0.13410    1.03877  0.67s\n",
      "    598     0.14052     0.13423    1.04687  0.64s\n",
      "    599     0.13927     \u001b[32m0.13402\u001b[0m    1.03919  0.71s\n",
      "    600     0.13995     \u001b[32m0.13399\u001b[0m    1.04445  0.72s\n",
      "    601     \u001b[36m0.13800\u001b[0m     \u001b[32m0.13394\u001b[0m    1.03027  0.68s\n",
      "    602     0.13940     \u001b[32m0.13386\u001b[0m    1.04136  0.72s\n",
      "    603     \u001b[36m0.13794\u001b[0m     \u001b[32m0.13381\u001b[0m    1.03081  0.72s\n",
      "    604     0.13843     \u001b[32m0.13379\u001b[0m    1.03468  0.72s\n",
      "    605     0.14017     \u001b[32m0.13374\u001b[0m    1.04804  0.62s\n",
      "    606     0.13912     \u001b[32m0.13369\u001b[0m    1.04062  0.62s\n",
      "    607     0.14036     \u001b[32m0.13354\u001b[0m    1.05111  0.62s\n",
      "    608     0.13970     0.13366    1.04515  0.72s\n",
      "    609     0.13819     \u001b[32m0.13351\u001b[0m    1.03510  0.70s\n",
      "    610     0.13849     0.13364    1.03630  0.74s\n",
      "    611     0.13936     0.13358    1.04330  0.69s\n",
      "    612     0.13829     \u001b[32m0.13347\u001b[0m    1.03612  0.71s\n",
      "    613     0.13921     0.13366    1.04155  0.64s\n",
      "    614     0.13871     0.13370    1.03740  0.67s\n",
      "    615     \u001b[36m0.13758\u001b[0m     \u001b[32m0.13346\u001b[0m    1.03091  0.71s\n",
      "    616     0.13880     \u001b[32m0.13338\u001b[0m    1.04059  0.69s\n",
      "    617     0.13768     \u001b[32m0.13328\u001b[0m    1.03304  0.68s\n",
      "    618     0.13890     0.13332    1.04188  0.70s\n",
      "    619     0.13813     \u001b[32m0.13323\u001b[0m    1.03683  0.66s\n",
      "    620     0.13817     0.13328    1.03668  0.61s\n",
      "    621     0.13870     \u001b[32m0.13309\u001b[0m    1.04211  0.61s\n",
      "    622     0.13835     0.13316    1.03895  0.63s\n",
      "    623     0.13771     0.13317    1.03406  0.60s\n",
      "    624     0.13829     \u001b[32m0.13303\u001b[0m    1.03950  0.63s\n",
      "    625     0.13937     \u001b[32m0.13303\u001b[0m    1.04769  0.60s\n",
      "    626     0.13803     0.13307    1.03729  0.61s\n",
      "    627     \u001b[36m0.13754\u001b[0m     \u001b[32m0.13294\u001b[0m    1.03454  0.61s\n",
      "    628     0.13766     0.13304    1.03474  0.62s\n",
      "    629     \u001b[36m0.13722\u001b[0m     \u001b[32m0.13293\u001b[0m    1.03231  0.61s\n",
      "    630     0.13867     \u001b[32m0.13291\u001b[0m    1.04329  0.61s\n",
      "    631     \u001b[36m0.13498\u001b[0m     0.13293    1.01542  0.59s\n",
      "    632     0.13745     0.13301    1.03332  0.63s\n",
      "    633     0.13755     \u001b[32m0.13288\u001b[0m    1.03515  0.60s\n",
      "    634     0.13728     0.13299    1.03230  0.62s\n",
      "    635     0.13892     \u001b[32m0.13277\u001b[0m    1.04637  0.62s\n",
      "    636     0.13720     \u001b[32m0.13269\u001b[0m    1.03393  0.61s\n",
      "    637     0.13748     0.13276    1.03551  0.61s\n",
      "    638     0.13630     0.13272    1.02697  0.59s\n",
      "    639     0.13765     0.13276    1.03680  0.61s\n",
      "    640     0.13824     0.13283    1.04071  0.61s\n",
      "    641     0.13748     \u001b[32m0.13258\u001b[0m    1.03699  0.61s\n",
      "    642     0.13747     \u001b[32m0.13257\u001b[0m    1.03695  0.64s\n",
      "    643     0.13710     \u001b[32m0.13243\u001b[0m    1.03521  0.60s\n",
      "    644     0.13763     \u001b[32m0.13224\u001b[0m    1.04076  0.59s\n",
      "    645     0.13637     0.13237    1.03021  0.60s\n",
      "    646     0.13832     0.13237    1.04493  0.61s\n",
      "    647     0.13592     \u001b[32m0.13223\u001b[0m    1.02792  0.61s\n",
      "    648     0.13750     \u001b[32m0.13210\u001b[0m    1.04090  0.64s\n",
      "    649     0.13593     0.13221    1.02814  0.61s\n",
      "    650     0.13579     0.13229    1.02649  0.62s\n",
      "    651     0.13648     0.13224    1.03209  0.62s\n",
      "    652     0.13730     0.13219    1.03862  0.62s\n",
      "    653     0.13662     \u001b[32m0.13198\u001b[0m    1.03516  0.61s\n",
      "    654     0.13643     0.13211    1.03274  0.60s\n",
      "    655     0.13624     0.13207    1.03155  0.63s\n",
      "    656     0.13711     0.13205    1.03837  0.62s\n",
      "    657     0.13585     \u001b[32m0.13198\u001b[0m    1.02931  0.61s\n",
      "    658     \u001b[36m0.13432\u001b[0m     0.13205    1.01720  0.62s\n",
      "    659     0.13622     0.13199    1.03203  0.62s\n",
      "    660     0.13658     \u001b[32m0.13193\u001b[0m    1.03523  0.61s\n",
      "    661     0.13657     \u001b[32m0.13189\u001b[0m    1.03543  0.61s\n",
      "    662     0.13563     0.13192    1.02814  0.62s\n",
      "    663     0.13602     0.13192    1.03103  0.62s\n",
      "    664     0.13576     \u001b[32m0.13185\u001b[0m    1.02965  0.60s\n",
      "    665     0.13539     \u001b[32m0.13163\u001b[0m    1.02854  0.59s\n",
      "    666     0.13565     \u001b[32m0.13163\u001b[0m    1.03053  0.60s\n",
      "    667     0.13582     0.13176    1.03081  0.61s\n",
      "    668     0.13558     0.13166    1.02973  0.60s\n",
      "    669     0.13555     \u001b[32m0.13155\u001b[0m    1.03042  0.59s\n",
      "    670     0.13491     \u001b[32m0.13151\u001b[0m    1.02584  0.62s\n",
      "    671     0.13681     0.13156    1.03987  0.61s\n",
      "    672     0.13505     \u001b[32m0.13144\u001b[0m    1.02750  0.62s\n",
      "    673     0.13659     \u001b[32m0.13143\u001b[0m    1.03927  0.59s\n",
      "    674     0.13503     0.13166    1.02559  0.61s\n",
      "    675     0.13574     0.13159    1.03150  0.64s\n",
      "    676     0.13523     \u001b[32m0.13141\u001b[0m    1.02906  0.60s\n",
      "    677     0.13485     \u001b[32m0.13136\u001b[0m    1.02653  0.62s\n",
      "    678     0.13467     \u001b[32m0.13134\u001b[0m    1.02539  0.61s\n",
      "    679     0.13462     0.13139    1.02457  0.62s\n",
      "    680     0.13527     \u001b[32m0.13128\u001b[0m    1.03044  0.61s\n",
      "    681     0.13500     0.13140    1.02739  0.60s\n",
      "    682     0.13530     0.13140    1.02963  0.61s\n",
      "    683     0.13534     \u001b[32m0.13120\u001b[0m    1.03156  0.64s\n",
      "    684     0.13433     0.13138    1.02248  0.61s\n",
      "    685     0.13545     \u001b[32m0.13115\u001b[0m    1.03278  0.61s\n",
      "    686     0.13461     \u001b[32m0.13113\u001b[0m    1.02657  0.59s\n",
      "    687     0.13595     0.13122    1.03601  0.62s\n",
      "    688     \u001b[36m0.13380\u001b[0m     0.13125    1.01942  0.62s\n",
      "    689     0.13406     0.13116    1.02212  0.61s\n",
      "    690     0.13542     0.13115    1.03257  0.63s\n",
      "    691     0.13529     \u001b[32m0.13107\u001b[0m    1.03221  0.61s\n",
      "    692     0.13543     \u001b[32m0.13087\u001b[0m    1.03485  0.61s\n",
      "    693     0.13547     0.13089    1.03500  0.63s\n",
      "    694     0.13401     0.13103    1.02272  0.61s\n",
      "    695     0.13515     \u001b[32m0.13068\u001b[0m    1.03419  0.62s\n",
      "    696     0.13469     0.13095    1.02858  0.60s\n",
      "    697     \u001b[36m0.13309\u001b[0m     0.13086    1.01708  0.62s\n",
      "    698     0.13514     0.13084    1.03287  0.60s\n",
      "    699     0.13489     0.13087    1.03072  0.60s\n",
      "    700     0.13406     0.13076    1.02518  0.62s\n",
      "    701     0.13460     \u001b[32m0.13062\u001b[0m    1.03047  0.61s\n",
      "    702     0.13476     \u001b[32m0.13055\u001b[0m    1.03222  0.61s\n",
      "    703     0.13441     \u001b[32m0.13050\u001b[0m    1.02993  0.60s\n",
      "    704     0.13367     0.13056    1.02377  0.58s\n",
      "    705     0.13424     \u001b[32m0.13040\u001b[0m    1.02948  0.60s\n",
      "    706     0.13424     0.13043    1.02920  0.58s\n",
      "    707     0.13471     0.13041    1.03296  0.62s\n",
      "    708     0.13510     0.13042    1.03592  0.60s\n",
      "    709     0.13384     0.13048    1.02577  0.60s\n",
      "    710     0.13350     0.13053    1.02272  0.62s\n",
      "    711     0.13480     0.13058    1.03236  0.59s\n",
      "    712     0.13469     0.13055    1.03165  0.62s\n",
      "    713     0.13386     0.13061    1.02493  0.60s\n",
      "    714     0.13487     0.13047    1.03368  0.60s\n",
      "    715     0.13314     0.13052    1.02011  0.62s\n",
      "    716     0.13475     \u001b[32m0.13039\u001b[0m    1.03340  0.61s\n",
      "    717     0.13356     0.13056    1.02299  0.63s\n",
      "    718     \u001b[36m0.13308\u001b[0m     \u001b[32m0.13037\u001b[0m    1.02083  0.59s\n",
      "    719     0.13328     \u001b[32m0.13021\u001b[0m    1.02359  0.60s\n",
      "    720     0.13346     0.13025    1.02464  0.60s\n",
      "    721     0.13355     0.13026    1.02524  0.60s\n",
      "    722     \u001b[36m0.13206\u001b[0m     \u001b[32m0.13019\u001b[0m    1.01431  0.61s\n",
      "    723     0.13322     \u001b[32m0.13014\u001b[0m    1.02371  0.60s\n",
      "    724     0.13457     0.13028    1.03296  0.60s\n",
      "    725     0.13304     0.13024    1.02149  0.65s\n",
      "    726     0.13217     0.13015    1.01552  0.60s\n",
      "    727     \u001b[36m0.13080\u001b[0m     \u001b[32m0.13013\u001b[0m    1.00512  0.60s\n",
      "    728     0.13390     0.13031    1.02752  0.61s\n",
      "    729     0.13234     \u001b[32m0.13007\u001b[0m    1.01749  0.61s\n",
      "    730     0.13235     0.13009    1.01741  0.59s\n",
      "    731     0.13286     \u001b[32m0.12998\u001b[0m    1.02215  0.60s\n",
      "    732     0.13266     0.13004    1.02018  0.63s\n",
      "    733     0.13198     0.13014    1.01416  0.62s\n",
      "    734     0.13298     0.13002    1.02279  0.61s\n",
      "    735     0.13243     \u001b[32m0.12990\u001b[0m    1.01947  0.63s\n",
      "    736     0.13247     \u001b[32m0.12987\u001b[0m    1.02004  0.63s\n",
      "    737     0.13355     0.12993    1.02782  0.63s\n",
      "    738     0.13281     \u001b[32m0.12980\u001b[0m    1.02324  0.63s\n",
      "    739     0.13202     \u001b[32m0.12970\u001b[0m    1.01783  0.64s\n",
      "    740     0.13355     0.13010    1.02656  0.62s\n",
      "    741     0.13254     \u001b[32m0.12964\u001b[0m    1.02235  0.61s\n",
      "    742     0.13274     0.12980    1.02271  0.61s\n",
      "    743     0.13223     0.12970    1.01953  0.61s\n",
      "    744     0.13272     \u001b[32m0.12953\u001b[0m    1.02460  0.63s\n",
      "    745     0.13286     0.12961    1.02512  0.60s\n",
      "    746     0.13281     0.12972    1.02384  0.60s\n",
      "    747     0.13099     0.12971    1.00986  0.62s\n",
      "    748     0.13215     \u001b[32m0.12951\u001b[0m    1.02034  0.63s\n",
      "    749     \u001b[36m0.13072\u001b[0m     0.12977    1.00737  0.60s\n",
      "    750     0.13314     0.12974    1.02620  0.59s\n",
      "    751     0.13181     0.12967    1.01652  0.61s\n",
      "    752     \u001b[36m0.13032\u001b[0m     0.12964    1.00526  0.63s\n",
      "    753     0.13217     0.12957    1.02010  0.63s\n",
      "    754     0.13170     \u001b[32m0.12944\u001b[0m    1.01748  0.62s\n",
      "    755     0.13259     0.12963    1.02281  0.61s\n",
      "    756     0.13079     \u001b[32m0.12941\u001b[0m    1.01061  0.60s\n",
      "    757     0.13210     0.12945    1.02045  0.61s\n",
      "    758     0.13115     0.12959    1.01206  0.62s\n",
      "    759     0.13270     \u001b[32m0.12939\u001b[0m    1.02553  0.62s\n",
      "    760     0.13206     \u001b[32m0.12921\u001b[0m    1.02208  0.62s\n",
      "    761     0.13210     0.12942    1.02076  0.61s\n",
      "    762     \u001b[36m0.13030\u001b[0m     0.12934    1.00741  0.62s\n",
      "    763     0.13158     \u001b[32m0.12920\u001b[0m    1.01840  0.60s\n",
      "    764     0.13174     0.12931    1.01884  0.58s\n",
      "    765     0.13238     0.12936    1.02335  0.59s\n",
      "    766     0.13155     0.12934    1.01706  0.66s\n",
      "    767     0.13158     0.12937    1.01708  0.60s\n",
      "    768     0.13106     0.12935    1.01323  0.61s\n",
      "    769     \u001b[36m0.13021\u001b[0m     0.12929    1.00709  0.61s\n",
      "    770     0.13106     0.12925    1.01400  0.61s\n",
      "    771     0.13195     \u001b[32m0.12905\u001b[0m    1.02245  0.61s\n",
      "    772     0.13149     0.12905    1.01890  0.63s\n",
      "    773     0.13111     \u001b[32m0.12888\u001b[0m    1.01735  0.65s\n",
      "    774     0.13092     \u001b[32m0.12887\u001b[0m    1.01591  0.68s\n",
      "    775     0.13064     \u001b[32m0.12879\u001b[0m    1.01436  0.66s\n",
      "    776     0.13183     0.12897    1.02215  0.65s\n",
      "    777     0.13149     0.12943    1.01594  0.68s\n",
      "    778     0.13114     0.12894    1.01705  0.66s\n",
      "    779     0.13103     0.12888    1.01670  0.64s\n",
      "    780     0.13065     0.12888    1.01378  0.63s\n",
      "    781     0.13029     \u001b[32m0.12867\u001b[0m    1.01255  0.61s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=None,\n",
       "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x0000000009F7B080>,\n",
       "     batch_iterator_train=<nolearn.lasagne.base.BatchIterator object at 0x0000000009F7BD68>,\n",
       "     check_input=True, conv_filter_size=(4, 4),\n",
       "     conv_nonlinearity=<function rectify at 0x000000000971D908>,\n",
       "     conv_num_filters=12, custom_scores=None, drop1_p=0.4, drop2_p=0.4,\n",
       "     drop3_p=0.4,\n",
       "     hid1_nonlinearity=<function rectify at 0x000000000971D908>,\n",
       "     hid1_num_units=75,\n",
       "     hid2_nonlinearity=<function rectify at 0x000000000971D908>,\n",
       "     hid2_num_units=50,\n",
       "     hid3_nonlinearity=<function rectify at 0x000000000971D908>,\n",
       "     hid3_num_units=25, in_shape=(None, 1, 6, 7),\n",
       "     layers=[('in', <class 'lasagne.layers.input.InputLayer'>), ('conv', <class 'lasagne.layers.conv.Conv2DLayer'>), ('hid1', <class 'lasagne.layers.dense.DenseLayer'>), ('drop1', <class 'lasagne.layers.noise.DropoutLayer'>), ('hid2', <class 'lasagne.layers.dense.DenseLayer'>), ('drop2', <class 'lasagne.layers.noise.DropoutLayer'>), ('hid3', <class 'lasagne.layers.dense.DenseLayer'>), ('drop3', <class 'lasagne.layers.noise.DropoutLayer'>), ('out', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=None, max_epochs=1000, more_params={},\n",
       "     objective=<function objective at 0x0000000009C37908>,\n",
       "     objective_loss_function=<function squared_error at 0x000000000995E518>,\n",
       "     on_batch_finished=[],\n",
       "     on_epoch_finished=[<nolearn.lasagne.handlers.PrintLog instance at 0x000000000BDA76C8>],\n",
       "     on_training_finished=[],\n",
       "     on_training_started=[<nolearn.lasagne.handlers.PrintLayerInfo instance at 0x000000000BDA7388>],\n",
       "     out_nonlinearity=<function tanh at 0x000000000971D898>,\n",
       "     out_num_units=1, regression=True, scores_train=[], scores_valid=[],\n",
       "     train_split=<nolearn.lasagne.base.TrainSplit object at 0x0000000009C2E978>,\n",
       "     update=<function nesterov_momentum at 0x000000000995EC18>,\n",
       "     update_learning_rate=0.0001, use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(float64, matrix))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn.save_params_to('gen6_conv.pkl')\n",
    "pnn.save_params_to('gen6_pol_conv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load parameters to layer 'conv' because shapes did not match: 12x7x4x4 vs 12x5x4x4.\n",
      "Loaded parameters to layer 'conv' (shape 12).\n",
      "Loaded parameters to layer 'hid1' (shape 144x75).\n",
      "Loaded parameters to layer 'hid1' (shape 75).\n",
      "Loaded parameters to layer 'hid2' (shape 75x50).\n",
      "Loaded parameters to layer 'hid2' (shape 50).\n",
      "Loaded parameters to layer 'hid3' (shape 50x25).\n",
      "Loaded parameters to layer 'hid3' (shape 25).\n",
      "Loaded parameters to layer 'out' (shape 25x1).\n",
      "Loaded parameters to layer 'out' (shape 1).\n"
     ]
    }
   ],
   "source": [
    "nn.load_params_from('gen6_conv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "game = cccc.Board()\n",
    "TREE_CACHE = {}\n",
    "t0 = 'error'\n",
    "tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,40)\n",
    "EPSILON = 0.1\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 1)\n",
    "for _ in range(20):\n",
    "    print _ , max(node_score(tree).values())\n",
    "    MCTS(tree,game,cccc.Board,dur = 1,leaf_branch=5,policy = pass_policy,net=net,rollout_policy = roll_policy)\n",
    "\n",
    "\n",
    "scores = node_score(tree)\n",
    "print 'current move\\n'\n",
    "for move in tree.actions:\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(move,tree.Vr[move],tree.N[move],scores[move])\n",
    "\n",
    "print '\\nprincipal variation\\n'\n",
    "for move in principal(tree):\n",
    "    print 'move: {}, win-loss: {:5d}, games played: {:5d}, score: {:+.3f}'.format(*move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in BoardExtractor().transform(X[0:100])[:,6,:,:]:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05966295]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.predict(-game.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = cccc.Board()\n",
    "for move in [3,2,3]:\n",
    "    game.update_move(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13475316,  0.1366703 ,  0.14872099,  0.14872099,  0.14455979,\n",
       "        0.14131726,  0.14525752])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_to_policy(net,game.player*game.board,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "3\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.]]\n",
      "2\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "for i in range(20):\n",
    "    count +=1\n",
    "    print game.board*game.player\n",
    "    print policy_to_index(net_to_policy(net,game.player*game.board,0.0))\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "move 6: eval: loss in  9 runs: 14076 principal branch: \u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m1\u001b[34m4\u001b[31m6\u001b[34m5\u001b[31m2\u001b[34m6\u001b[31m0\u001b[34m6\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m4\u001b[31m\u001b[30m\n",
      "move 1: eval: loss in  9 runs:  5750 principal branch: \u001b[34m1\u001b[31m2\u001b[34m6\u001b[31m5\u001b[34m6\u001b[31m0\u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m6\u001b[34m4\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m4\u001b[31m\u001b[30m\n",
      "move 2: eval: loss in  9 runs:  5137 principal branch: \u001b[34m2\u001b[31m0\u001b[34m6\u001b[31m5\u001b[34m1\u001b[31m4\u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m6\u001b[31m6\u001b[34m4\u001b[31m\u001b[30m\n",
      "move 4: eval: loss in  9 runs:  3870 principal branch: \u001b[34m4\u001b[31m1\u001b[34m6\u001b[31m5\u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m6\u001b[34m2\u001b[31m0\u001b[34m6\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m4\u001b[31m\u001b[30m\n",
      "move 5: eval: loss in  9 runs:  1703 principal branch: \u001b[34m5\u001b[31m1\u001b[34m0\u001b[31m6\u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m2\u001b[34m6\u001b[31m6\u001b[34m4\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m4\u001b[31m\u001b[30m\n",
      "move 0: eval: loss in  9 runs:   660 principal branch: \u001b[34m0\u001b[31m2\u001b[34m5\u001b[31m1\u001b[34m6\u001b[31m6\u001b[34m6\u001b[31m6\u001b[34m4\u001b[31m1\u001b[34m1\u001b[31m1\u001b[34m6\u001b[31m1\u001b[34m6\u001b[31m1\u001b[34m4\u001b[31m\u001b[30m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD7CAYAAABXAEBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC4hJREFUeJzt3W+IHIUZx/HfL7kmRK2+qEXFkN1KscVC8Q/oi1S6VtSg\noG9tBcEXvmqJtCBtJHAeBNJ3IrRvipqqaCsNBH1hJYG46Z0FTTWp0UQs2L3T1gQLokig0fj0xU7C\nNbfXnWtmn5nsfj+wZPcyzD7ZvftmZnZv1hEhAMiyqu4BAEwWogMgFdEBkIroAEhFdACkIjoAUjUq\nOrY32X7H9ru2f96AeR63fcz2m3XPcort9bb32n7b9iHbmxsw01rbr9o+UMw0XfdMp9heZfsN2y/U\nPcsptnu2/1o8Xq/VPY8k2b7I9h9sHym+t24Y2X015X06tldJelfSzZL+KWm/pLsj4p0aZ/qepM8k\nPRUR361rjsVsXyrp0og4aPsCSa9LuqvOx6mY67yIOG57taRXJG2OiNp/oGz/VNJ1ki6MiDvrnkeS\nbL8n6bqI+LjuWU6x/VtJ+yJih+0pSedFxKejuK8mbelcL+lvETEfEZ9L+r2ku+ocKCLmJDXmG0OS\nIuJoRBwsrn8m6Yiky+udSoqI48XVtZKmJNX+v5nt9ZJul/RY3bOcwWrQz57tCyXdGBE7JCkivhhV\ncKQG/cPV/8F5f9HtD9SAH6Yms92WdLWkV+ud5PRuzAFJRyXtiYj9dc8k6RFJD6oBATxDSNpje7/t\n++seRtI3JP3L9o5iV/Q3tteN6s6aFB2sQLFrtVPSA8UWT60i4suIuEbSekk32L6qznls3yHpWLFV\n6OLSFBsj4lr1t8J+XOzG12lK0rWSfl3MdVzSL0Z1Z02Kzj8kbVh0e33xNZyh2OfeKenpiHi+7nkW\nKzbLX5a0qeZRNkq6szh+8jtJN9l+quaZJEkR8WHx50eSdql/aKFOH0h6PyL+UtzeqX6ERqJJ0dkv\n6Zu2W7bXSLpbUhNecWja/5KS9ISkwxHxaN2DSJLti21fVFxfJ+kWSbUe2I6IhyJiQ0Rcof730t6I\nuLfOmaT+AfdiK1W2z5d0q6S36pwpIo5Jet/2lcWXbpZ0eFT3NzWqFa9URJy0/RNJu9WP4eMRcaTO\nmWw/K6kj6Wu2FyRNnzrYVuNMGyXdI+lQcQwlJD0UES/VONZlkp4sXoFcJem5iHixxnma7BJJu2yH\n+j9/z0TE7ppnkqTNkp6x/RVJ70m6b1R31JiXzAFMhibtXgGYAEQHQCqiAyAV0QGQiugASFXZS+bF\nS4AAIEmKiIHvb6v0fTpbY8tZr2Pfw7P6/sM3VjBNdZo4k1TtXNu8ppL1SF3139p09rbGiUrW08Tn\nb9xn2ubty/4du1cAUhEdAKkaF51WZ8PwhZI1cSapqXO16x5giSY+TpM8U2W/BmE7qjimg3pUd0yn\nOlUd00G+bd6+7IHkxm3pABhvRAdAKqIDIBXRAZCK6ABIRXQApCI6AFIRHQCpSkWnaZ8xDuDcNTQ6\nxRn+fyXpNknfkfRD298e9WAAxlOZLZ3GfcY4gHNXmejwGeMAKlPpSbz2PTx7+nqrs0HtTqvK1QNo\nqF53XvPdhVLLlolO6c8Yb9qZ0ADkaHda/7WRMTszt+yyZXavmvoZ4wDOQUO3dJr4GeMAzl2ljulE\nxEuSvjXiWQBMAN6RDCAV0QGQiugASEV0AKQiOgBSER0AqYgOgFREB0AqogMgFdEBkIroAEhFdACk\nIjoAUlV65sDV3l7l6s7aydhS9wgDNe1x6puue4BzQjOfu+Z+rw/Clg6AVEQHQCqiAyAV0QGQiugA\nSEV0AKQiOgBSER0AqYgOgFREB0AqogMgFdEBkIroAEhFdACkGhod24/bPmb7zYyBAIy3Mls6OyTd\nNupBAEyGodGJiDlJHyfMAmACcEwHQKpKT1faXXS9XVwAjL9ed17z3YVSy1YanU6VKwNwzmh3Wmp3\nWqdvz87MLbts2d0rFxcAOCtlXjJ/VtKfJV1pe8H2faMfC8C4Grp7FRE/yhgEwGTg1SsAqYgOgFRE\nB0AqogMgFdEBkIroAEhFdACkIjoAUhEdAKmIDoBURAdAKqIDIBXRAZCK6ABI5YioZkV2SNOVrKsq\nW+NE3SMMtM1r6h5hiWnN1D3CEidjS90jLNHE505q3vf6Nm9XRAw88R9bOgBSER0AqYgOgFREB0Aq\nogMgFdEBkIroAEhFdACkIjoAUhEdAKmIDoBURAdAKqIDINXQ6Nheb3uv7bdtH7K9OWMwAONpqsQy\nX0j6WUQctH2BpNdt746Id0Y8G4AxNHRLJyKORsTB4vpnko5IunzUgwEYTys6pmO7LelqSa+OYhgA\n4690dIpdq52SHii2eABgxcoc05HtKfWD83REPL/8kt1F19vFBcC463XnNd9dKLVsqehIekLS4Yh4\n9H8v1im5OgDjpN1pqd1pnb49OzO37LJlXjLfKOkeST+wfcD2G7Y3VTEogMkzdEsnIl6RtDphFgAT\ngHckA0hFdACkIjoAUhEdAKmIDoBURAdAKqIDIBXRAZCK6ABIRXQApCI6AFIRHQCpiA6AVEQHQKqy\nJ/EqZVozVa7urJ3UlrpHGKhpjxOQiS0dAKmIDoBURAdAKqIDIBXRAZCK6ABIRXQApCI6AFIRHQCp\niA6AVEQHQCqiAyAV0QGQauhvmdteK+lPktYUy++MCH5NGsD/ZWh0IuLftm+KiOO2V0t6xfYfI+K1\nhPkAjJlSu1cRcby4ulb9UMXIJgIw1kpFx/Yq2wckHZW0JyL2j3YsAOOq7JbOlxFxjaT1km6wfdVo\nxwIwrlZ0utKI+NT2y5I2STp85t93F11vFxcA46/Xndd8d6HUsmVevbpY0ucR8YntdZJukfTLQct2\nVjAkgPHR7rTU7rRO356dmVt22TJbOpdJetL2KvV3x56LiBfPdkgAk6nMS+aHJF2bMAuACcA7kgGk\nIjoAUhEdAKmIDoBURAdAKqIDIBXRAZCK6ABIRXQApCI6AFIRHQCpiA6AVEQHQCqiAyDVis4ciPE1\no+m6R1hiq07UPcIS02rmpy+d1Ja6RyiNLR0AqYgOgFREB0AqogMgFdEBkIroAEhFdACkIjoAUhEd\nAKmIDoBURAdAKqIDIBXRAZCK6ABIVTo6tlfZfsP2C6McCMB4W8mWzgOSDo9qEACToVR0bK+XdLuk\nx0Y7DoBxV3ZL5xFJD0qKEc4CYAIMPV2p7TskHYuIg7Y7krzcst1F19vFBcD463XnNd9dKLVsmXMk\nb5R0p+3bJa2T9FXbT0XEvWcu2FnJlADGRrvTUrvTOn17dmZu2WWH7l5FxEMRsSEirpB0t6S9g4ID\nAGXwPh0AqVb0ETQRsU/SvhHNAmACsKUDIBXRAZCK6ABIRXQApCI6AFIRHQCpiA6AVEQHQCqiAyAV\n0QGQiugASEV0AKQiOgBSER0AqRxRzWmPbYc0Xcm6qrI1TtQ9wkDbvKbuEZaY1kzdIyxxMrbUPcIS\nTXzupOZ9r2/zdkXEwFMbs6UDIBXRAZCK6ABIRXQApCI6AFIRHQCpiA6AVEQHQCqiAyAV0QGQiugA\nSEV0AKQiOgBSTZVZyHZP0ieSvpT0eURcP8qhAIyvUtFRPzadiPh4lMMAGH9ld6+8gmUBYFllQxKS\n9tjeb/v+UQ4EYLyV3b3aGBEf2v66+vE5EhFzSxfrLrreLi4Axl2vO6/57kKpZUtFJyI+LP78yPYu\nSddLGhCdTtkZAYyRdqeldqd1+vbszIA8FIbuXtk+z/YFxfXzJd0q6a2zHxPAJCqzpXOJpF39E69r\nStIzEbF7tGMBGFdDoxMRf5d0dcIsACYAL4MDSEV0AKQiOgBSER0AqYgOgFREB0AqogMgFdEBkIro\nAEhFdACkamB0enUPsESvO1/3CMvo1T3AEr26Bxigmc9fr+4Blsh6nIhOCWXPE5KvV/cAS/TqHmCA\nZj5/vboHWCLrcWpgdACMM6IDIJUjopoV9c+3AwCSpIjwoK9XFh0AKIPdKwCpiA6AVEQHQCqiAyAV\n0QGQ6j/oxq5gZ5ynhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe88acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = cccc.Board()\n",
    "t0 = 'error'\n",
    "t1=time.clock()\n",
    "t2=time.clock()\n",
    "t3=time.clock()\n",
    "EPSILON = 0.1\n",
    "for move in  [3,3,3,5,5,2,3,5,2,5,2,0,5,3,0,2,0,0,2,3,0]:\n",
    "    game.update_move(move)\n",
    "if board_to_cache(game.board) in TREE_CACHE:\n",
    "    tree = TREE_CACHE[board_to_cache(game.board)]\n",
    "else:\n",
    "    tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,leaf_branch=5)\n",
    "for _ in range(1000):\n",
    "    display.clear_output(wait=True)\n",
    "    MCTS(tree,game,cccc.Board,dur = 0.25,leaf_branch=5,mix=0.9999)\n",
    "\n",
    "    print print_eval(tree)\n",
    "    if not any([val[0] == 0.5 for val in tree.R.values()]):\n",
    "        break\n",
    "board_to_paint(game.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "move 1: eval:  win in  1 runs:     2 principal branch: \u001b[31m1\u001b[34m\u001b[30m\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD7CAYAAABXAEBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVCK6AAoRXQAlCI6AEr9D+SaYxztS0E8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa5866d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'__________________________________________'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-494-ff967e99e6f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mplayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MCnetAB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mboard_to_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMCAB_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboard_to_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMCTS_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcccc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoard\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpass_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mleaf_branch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMCAB_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '__________________________________________'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAD7CAYAAABXAEBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVCK6AAoRXQAlCI6AEr9D+SaYxztS0E8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa5866d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t0 = 'error'\n",
    "game = cccc.Board()\n",
    "t1=time.clock()\n",
    "t2=time.clock()\n",
    "t3=time.clock()\n",
    "MC_cache = {}\n",
    "AB_cache = {}\n",
    "net_cache = {}\n",
    "MCAB_cache = {}\n",
    "MCABroll_cache = {}\n",
    "EPSILON = 0.1\n",
    "time_per_move = 5\n",
    "update_freq = 0.25\n",
    "ax = plt.gca()\n",
    "win_d = {1:'win',0:'tie',-1:'loss'}\n",
    "\n",
    "pass_policy = lambda x: net_to_policy(net,x,temp = 0.25)\n",
    "\n",
    "score = 0\n",
    "games = 0\n",
    "\n",
    "for i in range(100):\n",
    "    game = cccc.Board()\n",
    "    tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,leaf_branch=5,cache = MC_cache)\n",
    "    players = {1:'MCnetAB',-1:'MCnet'}\n",
    "\n",
    "    while game.game_over() == False:\n",
    "        if players[game.player] == 'AB':\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "            move_score_depth = alpha_beta_descend(game,cache = AB_cache,dur = time_per_move)\n",
    "            print 'move: {}, score: {}, depth: {}'.format(move_score_depth[0][0],move_score_depth[0][1][0],move_score_depth[1])\n",
    "\n",
    "            game.update_move(move_score_depth[0][0])\n",
    "            ax = board_to_plot(ax,game.board)\n",
    "            display.display(plt.gcf())\n",
    "            continue\n",
    "        if players[game.player] == 'MC':\n",
    "            if board_to_cache(game.board) in MC_cache:\n",
    "                tree = MC_cache[board_to_cache(game.board)]\n",
    "            else:\n",
    "                tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,leaf_branch=5,cache = MC_cache)\n",
    "\n",
    "            for _ in range(int(time_per_move / update_freq)):\n",
    "                display.clear_output(wait=True)\n",
    "                MCTS(tree,game,cccc.Board,dur = update_freq,leaf_branch=5,mix = 0.9999)\n",
    "    #             ax = board_to_plot(ax,game.board)\n",
    "    #             display.display(plt.gcf())\n",
    "                if 'AB' in players.values():\n",
    "                    print 'move: {}, score: {}, depth: {}'.format(move_score_depth[0][0],move_score_depth[0][1][0],move_score_depth[1])\n",
    "                print print_eval(tree)\n",
    "\n",
    "    #         board_to_paint(game.board)\n",
    "            game.update_move(principal(tree)[0][0])\n",
    "            continue\n",
    "        if players[game.player] == 'MCnet':\n",
    "            if board_to_cache(game.board) in net_cache:\n",
    "                tree = net_cache[board_to_cache(game.board)]\n",
    "            else:\n",
    "                tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,policy = pass_policy,leaf_branch=5,cache = net_cache)\n",
    "\n",
    "            for _ in range(int(time_per_move / update_freq)):\n",
    "                display.clear_output(wait=True)\n",
    "                MCTS(tree,game,cccc.Board,dur = update_freq,leaf_branch=5,policy = pass_policy,net = net, mix = 0.5)\n",
    "    #             ax = board_to_plot(ax,game.board)\n",
    "    #             display.display(plt.gcf())\n",
    "                if 'AB' in players.values():\n",
    "                    print 'move: {}, score: {}, depth: {}'.format(move_score_depth[0][0],move_score_depth[0][1][0],move_score_depth[1])\n",
    "                print print_eval(tree)\n",
    "\n",
    "    #         board_to_paint(game.board)\n",
    "            game.update_move(principal(tree)[0][0])\n",
    "            continue\n",
    "\n",
    "        if players[game.player] == 'MCnetAB':\n",
    "            if board_to_cache(game.board) in MCAB_cache:\n",
    "                tree = net_cache[board_to_cache(game.board)]\n",
    "            else:\n",
    "                tree = MCTS_node(cccc.Board,np.copy(game.board),game.player,policy = pass_policy,leaf_branch=5,cache = MCAB_cache)\n",
    "\n",
    "            for _ in range(int(time_per_move / update_freq)):\n",
    "                display.clear_output(wait=True)\n",
    "                MCTS(tree,\n",
    "                     game,cccc.Board,\n",
    "                     dur = update_freq,\n",
    "                     leaf_branch=5,\n",
    "                     policy = pass_policy,\n",
    "                     net = net,\n",
    "                     mix = 0.5,\n",
    "                     rollout_policy= alpha_beta_rollout(2,MCABroll_cache))\n",
    "    #             ax = board_to_plot(ax,game.board)\n",
    "    #             display.display(plt.gcf())\n",
    "                if 'AB' in players.values():\n",
    "                    print 'move: {}, score: {}, depth: {}'.format(move_score_depth[0][0],move_score_depth[0][1][0],move_score_depth[1])\n",
    "                print print_eval(tree)\n",
    "\n",
    "    #         board_to_paint(game.board)\n",
    "            game.update_move(principal(tree)[0][0])\n",
    "            continue\n",
    "    ax = board_to_plot(ax,game.board)\n",
    "    display.display(plt.gcf())\n",
    "    score += game.result\n",
    "    games +=1\n",
    "print 'score: {}, games: {}'.format(score,games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.legal_moves()[policy_to_index(alpha_beta_rollout(2,MCABroll_cache)(np.zeros((6,7))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, (0, 0))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta(game,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game = cccc.Board(np.zeros((6,7)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MCTS_node instance at 0x000000002C4AF0C8>"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta(game,depth = 2,cache = MCAB_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
